{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"taxi.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNdiaaowjJo2OXkLegt6a33"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iWsOgJbSD2jl","executionInfo":{"status":"ok","timestamp":1653632635663,"user_tz":-480,"elapsed":901,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}},"outputId":"fb47a2fa-9067-4042-91c4-7d51d47974f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","|\u001b[43m \u001b[0m: | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[34;1mB\u001b[0m: |\n","+---------+\n","\n"]}],"source":["import gym\n","\n","env = gym.make(\"Taxi-v3\").env\n","env.render()"]},{"cell_type":"code","source":["env.reset() # reset environment to a new, random state\n","env.render()\n","\n","print(\"Action Space {}\".format(env.action_space))\n","print(\"State Space {}\".format(env.observation_space))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vW45M5HEV_t","executionInfo":{"status":"ok","timestamp":1653632635664,"user_tz":-480,"elapsed":40,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}},"outputId":"44ff5867-2077-401f-d7f4-0e32364f335b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[34;1mY\u001b[0m| :\u001b[43m \u001b[0m|B: |\n","+---------+\n","\n","Action Space Discrete(6)\n","State Space Discrete(500)\n"]}]},{"cell_type":"code","source":["state = env.encode(3, 1, 2, 0) # (taxi row, taxi column, passenger index, destination index)\n","print(\"State:\", state)\n","\n","env.s = state\n","env.render()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1LOjtvMsEf69","executionInfo":{"status":"ok","timestamp":1653632635665,"user_tz":-480,"elapsed":32,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}},"outputId":"9cd443cc-75f9-45c2-84cb-fe9b852a4b79"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["State: 328\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| |\u001b[43m \u001b[0m: | : |\n","|\u001b[34;1mY\u001b[0m| : |B: |\n","+---------+\n","\n"]}]},{"cell_type":"code","source":["env.P[328]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R39wTMWvEmn5","executionInfo":{"status":"ok","timestamp":1653632635665,"user_tz":-480,"elapsed":26,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}},"outputId":"33c8037d-b2ae-478c-8c07-7a74e323a0a4"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: [(1.0, 428, -1, False)],\n"," 1: [(1.0, 228, -1, False)],\n"," 2: [(1.0, 348, -1, False)],\n"," 3: [(1.0, 328, -1, False)],\n"," 4: [(1.0, 328, -10, False)],\n"," 5: [(1.0, 328, -10, False)]}"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import numpy as np\n","q_table = np.zeros([env.observation_space.n, env.action_space.n])"],"metadata":{"id":"_q-DiVMaErQt","executionInfo":{"status":"ok","timestamp":1653632635666,"user_tz":-480,"elapsed":21,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["%%time\n","\"\"\"Training the agent\"\"\"\n","\n","import random\n","from IPython.display import clear_output\n","\n","# Hyperparameters\n","alpha = 0.1\n","gamma = 0.6\n","epsilon = 0.1\n","\n","# For plotting metrics\n","all_epochs = []\n","all_penalties = []\n","\n","for i in range(1, 100001):\n","    state = env.reset()\n","\n","    epochs, penalties, reward, = 0, 0, 0\n","    done = False\n","    \n","    while not done:\n","        if random.uniform(0, 1) < epsilon:\n","            action = env.action_space.sample() # Explore action space\n","        else:\n","            action = np.argmax(q_table[state]) # Exploit learned values\n","\n","        next_state, reward, done, info = env.step(action) \n","        \n","        old_value = q_table[state, action]\n","        next_max = np.max(q_table[next_state])\n","        \n","        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n","        q_table[state, action] = new_value\n","\n","        if reward == -10:\n","            penalties += 1\n","\n","        state = next_state\n","        epochs += 1\n","        \n","    if i % 100 == 0:\n","        clear_output(wait=True)\n","        print(f\"Episode: {i}\")\n","\n","print(\"Training finished.\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kbEZ1TGuFA3r","executionInfo":{"status":"ok","timestamp":1653632696957,"user_tz":-480,"elapsed":61310,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}},"outputId":"3c3edb7f-3df5-414f-e6ca-fa4f37d7d230"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode: 100000\n","Training finished.\n","\n","CPU times: user 57.7 s, sys: 7.9 s, total: 1min 5s\n","Wall time: 1min 1s\n"]}]},{"cell_type":"code","source":["q_table[328]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6zKQSGnbHajt","executionInfo":{"status":"ok","timestamp":1653632696958,"user_tz":-480,"elapsed":26,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}},"outputId":"830423f0-66ca-4243-ce69-c00a8e74ae26"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ -2.40092101,  -2.27325184,  -2.39733908,  -2.35444636,\n","       -10.8092949 , -10.91065279])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["\"\"\"Evaluate agent's performance after Q-learning\"\"\"\n","\n","total_epochs, total_penalties = 0, 0\n","episodes = 100\n","\n","for _ in range(episodes):\n","    state = env.reset()\n","    epochs, penalties, reward = 0, 0, 0\n","    \n","    done = False\n","    \n","    while not done:\n","        action = np.argmax(q_table[state])\n","        state, reward, done, info = env.step(action)\n","\n","        if reward == -10:\n","            penalties += 1\n","\n","        epochs += 1\n","\n","    total_penalties += penalties\n","    total_epochs += epochs\n","\n","print(f\"Results after {episodes} episodes:\")\n","print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n","print(f\"Average penalties per episode: {total_penalties / episodes}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cnkd8wGGHa8T","executionInfo":{"status":"ok","timestamp":1653632696959,"user_tz":-480,"elapsed":16,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}},"outputId":"a8c2ad35-aedb-46ad-f910-4486dafac6a4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Results after 100 episodes:\n","Average timesteps per episode: 13.4\n","Average penalties per episode: 0.0\n"]}]},{"cell_type":"code","source":["frames = [] # for animation\n","\n","for _ in range(1):\n","    state = env.reset()\n","    done = False\n","    G = 0  \n","    while not done:\n","        action = np.argmax(q_table[state])\n","        state, reward, done, info = env.step(action)\n","        G += reward\n","        # Put each rendered frame into dict for animation\n","        frames.append({\n","            'frame': env.render(mode='ansi'),\n","            'state': state,\n","            'action': action,\n","            'reward': reward,\n","            'accureword': G\n","            }\n","        )"],"metadata":{"id":"NJCNaZjcHlNa","executionInfo":{"status":"ok","timestamp":1653632696960,"user_tz":-480,"elapsed":14,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from IPython.display import clear_output\n","from time import sleep\n","\n","def print_frames(frames):\n","    for i, frame in enumerate(frames):\n","        clear_output(wait=True)\n","        print(frame['frame'])\n","        print(f\"Timestep: {i + 1}\")\n","        print(f\"State: {frame['state']}\")\n","        print(f\"Action: {frame['action']}\")\n","        print(f\"Reward: {frame['reward']}\")\n","        print(f\"Accureword: {frame['accureword']}\")\n","        sleep(2)\n","        \n","print_frames(frames)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xPBkvAt5I_e3","executionInfo":{"status":"ok","timestamp":1653632723156,"user_tz":-480,"elapsed":26210,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}},"outputId":"8f648621-5f71-4e2d-b588-5ace2b8f0a78"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[35m\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m\u001b[0m: |\n","+---------+\n","  (Dropoff)\n","\n","Timestep: 13\n","State: 475\n","Action: 5\n","Reward: 20\n","Accureword: 8\n"]}]}]}