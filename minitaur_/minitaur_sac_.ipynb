{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"minitaur_sac_.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNula1xijCUZFnn2zxK/pnj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PfiV0nkxzT6P","executionInfo":{"status":"ok","timestamp":1654737120944,"user_tz":-480,"elapsed":27627,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}},"outputId":"e7a56c2a-9636-4fcd-bf22-13fed6008c6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pybullet in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ptan in /usr/local/lib/python3.7/dist-packages (0.7)\n","Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from ptan) (0.17.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ptan) (1.21.6)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from ptan) (4.1.2.30)\n","Requirement already satisfied: atari-py in /usr/local/lib/python3.7/dist-packages (from ptan) (0.2.9)\n","Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.7/dist-packages (from ptan) (1.7.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->ptan) (0.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->ptan) (4.2.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->ptan) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py->ptan) (1.15.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->ptan) (1.3.0)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->ptan) (1.5.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->ptan) (1.4.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5.1)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n","Mounted at ./mount\n"]}],"source":["!pip install pybullet\n","!pip install ptan\n","!pip install tensorboardX\n","\n","from google.colab import drive\n","drive.mount('./mount')"]},{"cell_type":"code","source":["import ptan\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.distributions as distr\n","\n","HID_SIZE = 64\n","\n","\n","class ModelActor(nn.Module):\n","    def __init__(self, obs_size, act_size):\n","        super(ModelActor, self).__init__()\n","\n","        self.base = nn.Sequential(\n","            nn.Linear(obs_size, HID_SIZE),\n","            nn.ReLU(),\n","            nn.Linear(HID_SIZE, HID_SIZE),\n","            nn.ReLU(),\n","        )\n","        self.mu = nn.Sequential(\n","            nn.Linear(HID_SIZE, act_size),\n","        )\n","        self.var = nn.Sequential(\n","            nn.Linear(HID_SIZE, act_size),\n","            nn.Softplus(),\n","        )\n","\n","    def forward(self, x):\n","        base_out = self.base(x)\n","        act_dist = distr.Normal(self.mu(base_out), self.var(base_out))\n","        normal_sample = act_dist.rsample()\n","        acts_v = torch.tanh(normal_sample)\n","        log_prob = act_dist.log_prob(normal_sample)\n","        log_prob -= torch.log(1-acts_v.pow(2) + 1e-7)\n","        return acts_v, log_prob\n","\n","\n","class ModelCritic(nn.Module):\n","    def __init__(self, obs_size):\n","        super(ModelCritic, self).__init__()\n","\n","        self.value = nn.Sequential(\n","            nn.Linear(obs_size, HID_SIZE),\n","            nn.ReLU(),\n","            nn.Linear(HID_SIZE, HID_SIZE),\n","            nn.ReLU(),\n","            nn.Linear(HID_SIZE, 1),\n","        )\n","\n","    def forward(self, x):\n","        return self.value(x)\n","\n","\n","class ModelSACTwinQ(nn.Module):\n","    def __init__(self, obs_size, act_size):\n","        super(ModelSACTwinQ, self).__init__()\n","\n","        self.q1 = nn.Sequential(\n","            nn.Linear(obs_size + act_size, HID_SIZE),\n","            nn.ReLU(),\n","            nn.Linear(HID_SIZE, HID_SIZE),\n","            nn.ReLU(),\n","            nn.Linear(HID_SIZE, 1),\n","        )\n","\n","        self.q2 = nn.Sequential(\n","            nn.Linear(obs_size + act_size, HID_SIZE),\n","            nn.ReLU(),\n","            nn.Linear(HID_SIZE, HID_SIZE),\n","            nn.ReLU(),\n","            nn.Linear(HID_SIZE, 1),\n","        )\n","\n","    def forward(self, obs, act):\n","        x = torch.cat([obs, act], dim=1)\n","        return self.q1(x), self.q2(x)\n","\n","\n","class AgentA2C(ptan.agent.BaseAgent):\n","    def __init__(self, net, device=\"cpu\"):\n","        self.net = net\n","        self.device = device\n","\n","    def __call__(self, states, agent_states):\n","        states_v = ptan.agent.float32_preprocessor(states)\n","        states_v = states_v.to(self.device)\n","\n","        actions, _ = self.net(states_v)\n","        actions = actions.data.cpu().numpy()\n","\n","        return actions, agent_states\n","\n","\n","class AlphaAdapt:\n","    def __init__(self, target_entropy, INIA_ENTROPY_ALPHA, LR_ALPHA):\n","        self.target_entropy = target_entropy\n","        self.log_alpha = torch.tensor(np.log(INIA_ENTROPY_ALPHA), dtype=torch.float)\n","        self.log_alpha.requires_grad = True\n","        self.log_alpha_optimizer = torch.optim.Adam([self.log_alpha], lr=LR_ALPHA)\n","\n","    def train(self, entropy):\n","        self.log_alpha_optimizer.zero_grad()\n","        alpha_loss = torch.mean(\n","            (entropy - self.target_entropy).detach() * self.log_alpha.exp())\n","        alpha_loss.backward()\n","        self.log_alpha_optimizer.step()  \n","\n","\n","def test_net(net, env, count=10, device=\"cpu\"):\n","    rewards = 0.0\n","    steps = 0\n","    for _ in range(count):\n","        obs = env.reset()\n","        while True:\n","            obs_v = ptan.agent.float32_preprocessor([obs])\n","            obs_v = obs_v.to(device)\n","\n","            actions, _ = net(obs_v)\n","            actions = actions.data.cpu().numpy().squeeze()\n","\n","            obs, reward, done, _ = env.step(actions)\n","\n","            rewards += reward\n","            steps += 1\n","            if done:\n","                break\n","    return rewards / count, steps / count\n","\n","\n","def unpack_batch_a2c(batch, net, last_val_gamma, device=\"cpu\"):\n","    \"\"\"\n","    Convert batch into training tensors\n","    :param batch:\n","    :param net:\n","    :return: states variable, actions tensor, reference values variable\n","    \"\"\"\n","    states = []\n","    actions = []\n","    rewards = []\n","    not_done_idx = []\n","    last_states = []\n","    for idx, exp in enumerate(batch):\n","        states.append(exp.state)\n","        actions.append(exp.action)\n","        rewards.append(exp.reward)\n","        if exp.last_state is not None:\n","            not_done_idx.append(idx)\n","            last_states.append(exp.last_state)\n","    states_v = ptan.agent.float32_preprocessor(states).to(device)\n","    actions_v = torch.FloatTensor(actions).to(device)\n","\n","    # handle rewards\n","    rewards_np = np.array(rewards, dtype=np.float32)\n","    if not_done_idx:\n","        last_states_v = ptan.agent.float32_preprocessor(last_states).to(device)\n","        last_vals_v = net(last_states_v)\n","        last_vals_np = last_vals_v.data.cpu().numpy()[:, 0]\n","        rewards_np[not_done_idx] += last_val_gamma * last_vals_np\n","\n","    ref_vals_v = torch.FloatTensor(rewards_np).to(device)\n","    return states_v, actions_v, ref_vals_v\n","\n","\n","@torch.no_grad()\n","def unpack_batch_sac(batch, val_net, twinq_net, policy_net,\n","                     gamma: float, ent_alpha: float,\n","                     device=\"cpu\"):\n","    \"\"\"\n","    Unpack Soft Actor-Critic batch\n","    \"\"\"\n","    states_v, actions_v, ref_q_v = \\\n","        unpack_batch_a2c(batch, val_net, gamma, device)\n","\n","    # references for the critic network\n","    acts_v, log_prob = policy_net(states_v)\n","    q1_v, q2_v = twinq_net(states_v, acts_v)\n","    # element-wise minimum\n","    ref_vals_v = torch.min(q1_v, q2_v).squeeze() - \\\n","                 ent_alpha * log_prob.sum(dim=1)\n","    return states_v, actions_v, ref_vals_v, ref_q_v"],"metadata":{"id":"b7ZH2au-zxbu","executionInfo":{"status":"ok","timestamp":1654737138695,"user_tz":-480,"elapsed":1121,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# cuda or not\n","import torch\n","\n","if torch.cuda.is_available():\n","  torch.set_default_tensor_type(torch.cuda.FloatTensor)\n","  print(\"using cuda:\",torch.cuda.get_device_name(0))\n","  pass\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uaB5-Pcn4oX_","executionInfo":{"status":"ok","timestamp":1654737214483,"user_tz":-480,"elapsed":319,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}},"outputId":"977dd0d8-c910-40cd-dbe1-adb55c934e2f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["using cuda: Tesla P100-PCIE-16GB\n"]},{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import os\n","import ptan\n","import gym\n","import math\n","import time\n","import pybullet_envs\n","# import argparse\n","from tensorboardX import SummaryWriter\n","import numpy as np\n","\n","# from lib import model, common, test_net\n","\n","import torch\n","import torch.optim as optim\n","import torch.distributions as distrib\n","import torch.nn.functional as F\n","\n","\n","ENV_ID = \"MinitaurBulletEnv-v0\"\n","GAMMA = 0.99\n","BATCH_SIZE = 64\n","LR_ACTS = 1e-4\n","LR_VALS = 1e-4\n","LR_ALPHA = 1e-4\n","REPLAY_SIZE = 100000\n","REPLAY_INITIAL = 10000\n","INIA_ENTROPY_ALPHA = 1e-2\n","\n","TEST_ITERS = 10000\n","\n","\n","save_path = os.path.join('mount/My Drive/Colab Notebooks/minitaur_', '05_22060616_SAC')\n","os.makedirs(save_path, exist_ok=True)\n","\n","env = gym.make(ENV_ID)\n","test_env = gym.make(ENV_ID)\n","\n","act_net = ModelActor(\n","    env.observation_space.shape[0],\n","    env.action_space.shape[0]).to(device)\n","crt_net = ModelCritic(\n","    env.observation_space.shape[0]\n",").to(device)\n","twinq_net = ModelSACTwinQ(\n","    env.observation_space.shape[0],\n","    env.action_space.shape[0]).to(device)\n","print(act_net)\n","print(crt_net)\n","print(twinq_net)\n","\n","tgt_crt_net = ptan.agent.TargetNet(crt_net)\n","\n","writer = SummaryWriter(comment=\"-sac_\")\n","agent = AgentA2C(act_net, device=device)\n","exp_source = ptan.experience.ExperienceSourceFirstLast(\n","    env, agent, gamma=GAMMA, steps_count=1)\n","buffer = ptan.experience.ExperienceReplayBuffer(\n","    exp_source, buffer_size=REPLAY_SIZE)\n","act_opt = optim.Adam(act_net.parameters(), lr=LR_ACTS)\n","crt_opt = optim.Adam(crt_net.parameters(), lr=LR_VALS)\n","twinq_opt = optim.Adam(twinq_net.parameters(), lr=LR_VALS)\n","\n","alpha_optim = AlphaAdapt(torch.tensor(-env.action_space.shape[0], dtype=torch.float), INIA_ENTROPY_ALPHA, LR_ALPHA)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7PrkhOfc4q8J","executionInfo":{"status":"ok","timestamp":1654737221018,"user_tz":-480,"elapsed":3664,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}},"outputId":"d535f8cc-d828-4dde-ce3a-53ae49e50979"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["current_dir=/usr/local/lib/python3.7/dist-packages/pybullet_envs/bullet\n","urdf_root=/usr/local/lib/python3.7/dist-packages/pybullet_data\n","urdf_root=/usr/local/lib/python3.7/dist-packages/pybullet_data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n","  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"]},{"output_type":"stream","name":"stdout","text":["ModelActor(\n","  (base): Sequential(\n","    (0): Linear(in_features=28, out_features=64, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=64, out_features=64, bias=True)\n","    (3): ReLU()\n","  )\n","  (mu): Sequential(\n","    (0): Linear(in_features=64, out_features=8, bias=True)\n","  )\n","  (var): Sequential(\n","    (0): Linear(in_features=64, out_features=8, bias=True)\n","    (1): Softplus(beta=1, threshold=20)\n","  )\n",")\n","ModelCritic(\n","  (value): Sequential(\n","    (0): Linear(in_features=28, out_features=64, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=64, out_features=64, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=64, out_features=1, bias=True)\n","  )\n",")\n","ModelSACTwinQ(\n","  (q1): Sequential(\n","    (0): Linear(in_features=36, out_features=64, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=64, out_features=64, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=64, out_features=1, bias=True)\n","  )\n","  (q2): Sequential(\n","    (0): Linear(in_features=36, out_features=64, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=64, out_features=64, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=64, out_features=1, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["frame_idx = 0\n","best_reward = None\n","with ptan.common.utils.RewardTracker(writer) as tracker:\n","    with ptan.common.utils.TBMeanTracker(\n","            writer, batch_size=10) as tb_tracker:\n","        while True:\n","            frame_idx += 1\n","            buffer.populate(1)\n","            rewards_steps = exp_source.pop_rewards_steps()\n","            if rewards_steps:\n","                rewards, steps = zip(*rewards_steps)\n","                tb_tracker.track(\"episode_steps\", steps[0], frame_idx)\n","                tracker.reward(rewards[0], frame_idx)\n","\n","            if len(buffer) < REPLAY_INITIAL:\n","                continue\n","\n","            batch = buffer.sample(BATCH_SIZE)\n","            states_v, actions_v, ref_vals_v, ref_q_v = \\\n","                unpack_batch_sac(\n","                    batch, tgt_crt_net.target_model,\n","                    twinq_net, act_net, GAMMA,\n","                    alpha_optim.log_alpha.exp(), device)\n","\n","            tb_tracker.track(\"ref_v\", ref_vals_v.mean(), frame_idx)\n","            tb_tracker.track(\"ref_q\", ref_q_v.mean(), frame_idx)\n","\n","            ####\n","\n","            # Critic\n","            crt_opt.zero_grad()\n","            val_v = crt_net(states_v)\n","            v_loss_v = F.mse_loss(val_v.squeeze(),\n","                                  ref_vals_v.detach())\n","            v_loss_v.backward()\n","            crt_opt.step()\n","            tb_tracker.track(\"loss_v\", v_loss_v, frame_idx)\n","\n","            # train TwinQ\n","            twinq_opt.zero_grad()\n","            q1_v, q2_v = twinq_net(states_v, actions_v)\n","            q1_loss_v = F.mse_loss(q1_v.squeeze(),\n","                                    ref_q_v.detach())\n","            q2_loss_v = F.mse_loss(q2_v.squeeze(),\n","                                    ref_q_v.detach())\n","            q_loss_v = q1_loss_v + q2_loss_v\n","            q_loss_v.backward()\n","            twinq_opt.step()\n","            tb_tracker.track(\"loss_q1\", q1_loss_v, frame_idx)\n","            tb_tracker.track(\"loss_q2\", q2_loss_v, frame_idx)\n","\n","            # Actor\n","            acts_v, log_prob = act_net(states_v)\n","            q1_v, q2_v = twinq_net(states_v, acts_v)\n","            entropy = -log_prob.sum(dim=1)\n","            LLLL = torch.min(q1_v, q2_v).squeeze() + alpha_optim.log_alpha.exp() * entropy\n","            act_opt.zero_grad()\n","            act_loss = -LLLL.mean()\n","            act_loss.backward()\n","            act_opt.step()\n","            tb_tracker.track(\"loss_act\", act_loss, frame_idx)\n","\n","            alpha_optim.train(entropy)\n","\n","            tgt_crt_net.alpha_sync(alpha=1 - 1e-3)\n","\n","            if frame_idx % TEST_ITERS == 0:\n","\n","                print('EEEE', entropy.mean())\n","                print('QQQQQQQQQQQQ', -q1_v.mean())\n","                print('AAAAAAAAAAAAAAAAAAAA', alpha_optim.log_alpha.exp())\n","\n","                ts = time.time()\n","                rewards, steps = test_net(act_net, test_env, device=device)\n","                print(\"Test done in %.2f sec, reward %.3f, steps %d\" % (\n","                    time.time() - ts, rewards, steps))\n","                writer.add_scalar(\"test_reward\", rewards, frame_idx)\n","                writer.add_scalar(\"test_steps\", steps, frame_idx)\n","                if best_reward is None or best_reward < rewards:\n","                    if best_reward is not None:\n","                        print(\"Best reward updated: %.3f -> %.3f\" % (best_reward, rewards))\n","                        name = \"best_%+.3f_%d.dat\" % (rewards, frame_idx)\n","                        fname = os.path.join(save_path, name)\n","                        torch.save(act_net.state_dict(), fname)\n","                    best_reward = rewards\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rDyFuj7C6YkN","outputId":"8143afbf-32c5-42cd-9685-5f5065cab07d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n","109394: done 1096 episodes, mean reward 0.117, speed 48.26 f/s\n","109446: done 1097 episodes, mean reward 0.117, speed 49.97 f/s\n","109500: done 1098 episodes, mean reward 0.119, speed 50.35 f/s\n","109594: done 1100 episodes, mean reward 0.120, speed 49.97 f/s\n","109670: done 1102 episodes, mean reward 0.122, speed 48.11 f/s\n","109778: done 1104 episodes, mean reward 0.124, speed 50.06 f/s\n","109834: done 1105 episodes, mean reward 0.125, speed 50.93 f/s\n","109902: done 1107 episodes, mean reward 0.127, speed 47.03 f/s\n","109985: done 1109 episodes, mean reward 0.127, speed 49.27 f/s\n","EEEE tensor(-7.9255, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.1229, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(6.1858e-05, grad_fn=<ExpBackward>)\n","Test done in 15.86 sec, reward 0.099, steps 233\n","110023: done 1110 episodes, mean reward 0.128, speed 2.28 f/s\n","110117: done 1112 episodes, mean reward 0.133, speed 49.49 f/s\n","110168: done 1113 episodes, mean reward 0.133, speed 49.78 f/s\n","110349: done 1114 episodes, mean reward 0.134, speed 55.64 f/s\n","110429: done 1116 episodes, mean reward 0.137, speed 48.32 f/s\n","110480: done 1117 episodes, mean reward 0.139, speed 49.96 f/s\n","110559: done 1119 episodes, mean reward 0.141, speed 48.19 f/s\n","110638: done 1121 episodes, mean reward 0.142, speed 48.12 f/s\n","110896: done 1123 episodes, mean reward 0.141, speed 54.90 f/s\n","111003: done 1125 episodes, mean reward 0.144, speed 50.46 f/s\n","111054: done 1126 episodes, mean reward 0.145, speed 49.92 f/s\n","111140: done 1128 episodes, mean reward 0.148, speed 48.80 f/s\n","111221: done 1130 episodes, mean reward 0.149, speed 48.94 f/s\n","112172: done 1131 episodes, mean reward 0.144, speed 56.13 f/s\n","112226: done 1132 episodes, mean reward 0.146, speed 50.17 f/s\n","112301: done 1134 episodes, mean reward 0.148, speed 48.09 f/s\n","112354: done 1135 episodes, mean reward 0.151, speed 51.37 f/s\n","112432: done 1137 episodes, mean reward 0.153, speed 48.95 f/s\n","112487: done 1138 episodes, mean reward 0.153, speed 51.65 f/s\n","112586: done 1140 episodes, mean reward 0.157, speed 50.57 f/s\n","112640: done 1141 episodes, mean reward 0.158, speed 50.79 f/s\n","112696: done 1142 episodes, mean reward 0.161, speed 51.24 f/s\n","112768: done 1144 episodes, mean reward 0.172, speed 48.54 f/s\n","112874: done 1146 episodes, mean reward 0.175, speed 51.44 f/s\n","113164: done 1147 episodes, mean reward 0.174, speed 56.44 f/s\n","113309: done 1149 episodes, mean reward 0.175, speed 51.92 f/s\n","113365: done 1150 episodes, mean reward 0.176, speed 50.88 f/s\n","113430: done 1152 episodes, mean reward 0.177, speed 47.68 f/s\n","113495: done 1154 episodes, mean reward 0.176, speed 47.03 f/s\n","113571: done 1156 episodes, mean reward 0.176, speed 48.41 f/s\n","113662: done 1158 episodes, mean reward 0.178, speed 49.99 f/s\n","114060: done 1160 episodes, mean reward 0.177, speed 54.68 f/s\n","114416: done 1161 episodes, mean reward 0.175, speed 54.43 f/s\n","114489: done 1163 episodes, mean reward 0.175, speed 48.15 f/s\n","114556: done 1165 episodes, mean reward 0.175, speed 45.19 f/s\n","114628: done 1167 episodes, mean reward 0.173, speed 46.98 f/s\n","114704: done 1169 episodes, mean reward 0.172, speed 48.18 f/s\n","114780: done 1171 episodes, mean reward 0.173, speed 47.94 f/s\n","114849: done 1173 episodes, mean reward 0.171, speed 46.47 f/s\n","114923: done 1175 episodes, mean reward 0.173, speed 47.64 f/s\n","114982: done 1176 episodes, mean reward 0.173, speed 51.68 f/s\n","115034: done 1177 episodes, mean reward 0.175, speed 50.22 f/s\n","115116: done 1179 episodes, mean reward 0.186, speed 48.98 f/s\n","115210: done 1181 episodes, mean reward 0.186, speed 49.73 f/s\n","115266: done 1182 episodes, mean reward 0.188, speed 50.94 f/s\n","115369: done 1184 episodes, mean reward 0.188, speed 50.61 f/s\n","115458: done 1186 episodes, mean reward 0.187, speed 49.17 f/s\n","115509: done 1187 episodes, mean reward 0.187, speed 49.95 f/s\n","115590: done 1189 episodes, mean reward 0.187, speed 48.40 f/s\n","115685: done 1191 episodes, mean reward 0.188, speed 49.61 f/s\n","115781: done 1193 episodes, mean reward 0.189, speed 50.07 f/s\n","115847: done 1195 episodes, mean reward 0.190, speed 46.66 f/s\n","116692: done 1197 episodes, mean reward 0.185, speed 56.63 f/s\n","116792: done 1199 episodes, mean reward 0.185, speed 51.17 f/s\n","117211: done 1200 episodes, mean reward 0.182, speed 56.11 f/s\n","117299: done 1202 episodes, mean reward 0.181, speed 49.77 f/s\n","117364: done 1204 episodes, mean reward 0.180, speed 46.49 f/s\n","117799: done 1205 episodes, mean reward 0.178, speed 56.64 f/s\n","117863: done 1207 episodes, mean reward 0.177, speed 47.15 f/s\n","117931: done 1209 episodes, mean reward 0.177, speed 47.90 f/s\n","117992: done 1211 episodes, mean reward 0.176, speed 46.46 f/s\n","118539: done 1212 episodes, mean reward 0.172, speed 54.83 f/s\n","118599: done 1214 episodes, mean reward 0.171, speed 45.91 f/s\n","118661: done 1216 episodes, mean reward 0.169, speed 46.24 f/s\n","118736: done 1218 episodes, mean reward 0.168, speed 48.21 f/s\n","118816: done 1220 episodes, mean reward 0.170, speed 48.69 f/s\n","118890: done 1222 episodes, mean reward 0.169, speed 48.64 f/s\n","118955: done 1224 episodes, mean reward 0.170, speed 46.68 f/s\n","119023: done 1226 episodes, mean reward 0.168, speed 47.17 f/s\n","119089: done 1228 episodes, mean reward 0.167, speed 47.64 f/s\n","119151: done 1230 episodes, mean reward 0.166, speed 46.79 f/s\n","119203: done 1231 episodes, mean reward 0.173, speed 50.16 f/s\n","119273: done 1233 episodes, mean reward 0.172, speed 47.97 f/s\n","119338: done 1235 episodes, mean reward 0.171, speed 47.44 f/s\n","119405: done 1237 episodes, mean reward 0.170, speed 47.23 f/s\n","119479: done 1239 episodes, mean reward 0.170, speed 48.18 f/s\n","119558: done 1241 episodes, mean reward 0.170, speed 48.19 f/s\n","119899: done 1242 episodes, mean reward 0.167, speed 55.71 f/s\n","119958: done 1243 episodes, mean reward 0.168, speed 51.06 f/s\n","EEEE tensor(-8.7408, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.1019, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(8.4825e-05, grad_fn=<ExpBackward>)\n","Test done in 3.74 sec, reward 0.159, steps 40\n","120054: done 1245 episodes, mean reward 0.167, speed 16.94 f/s\n","120117: done 1247 episodes, mean reward 0.166, speed 46.40 f/s\n","120173: done 1249 episodes, mean reward 0.164, speed 46.15 f/s\n","120237: done 1251 episodes, mean reward 0.163, speed 47.06 f/s\n","120305: done 1253 episodes, mean reward 0.163, speed 47.06 f/s\n","120371: done 1255 episodes, mean reward 0.163, speed 47.40 f/s\n","120436: done 1257 episodes, mean reward 0.163, speed 47.35 f/s\n","120512: done 1259 episodes, mean reward 0.162, speed 48.17 f/s\n","120586: done 1261 episodes, mean reward 0.165, speed 47.20 f/s\n","120650: done 1263 episodes, mean reward 0.165, speed 46.17 f/s\n","120727: done 1265 episodes, mean reward 0.167, speed 48.42 f/s\n","120789: done 1267 episodes, mean reward 0.167, speed 45.14 f/s\n","120850: done 1269 episodes, mean reward 0.166, speed 44.88 f/s\n","120962: done 1270 episodes, mean reward 0.166, speed 54.26 f/s\n","121031: done 1272 episodes, mean reward 0.166, speed 45.86 f/s\n","121098: done 1274 episodes, mean reward 0.166, speed 46.64 f/s\n","121159: done 1276 episodes, mean reward 0.164, speed 47.04 f/s\n","121217: done 1278 episodes, mean reward 0.163, speed 45.82 f/s\n","121273: done 1280 episodes, mean reward 0.160, speed 45.52 f/s\n","121331: done 1282 episodes, mean reward 0.158, speed 46.21 f/s\n","121391: done 1284 episodes, mean reward 0.156, speed 45.59 f/s\n","121451: done 1286 episodes, mean reward 0.156, speed 46.22 f/s\n","121504: done 1288 episodes, mean reward 0.154, speed 43.10 f/s\n","121567: done 1290 episodes, mean reward 0.153, speed 45.79 f/s\n","121623: done 1291 episodes, mean reward 0.152, speed 50.20 f/s\n","121682: done 1292 episodes, mean reward 0.152, speed 51.26 f/s\n","121741: done 1294 episodes, mean reward 0.151, speed 45.20 f/s\n","121821: done 1296 episodes, mean reward 0.152, speed 48.30 f/s\n","121882: done 1298 episodes, mean reward 0.158, speed 46.33 f/s\n","121936: done 1300 episodes, mean reward 0.159, speed 44.48 f/s\n","122005: done 1302 episodes, mean reward 0.159, speed 46.84 f/s\n","122077: done 1304 episodes, mean reward 0.160, speed 46.68 f/s\n","122139: done 1306 episodes, mean reward 0.162, speed 45.83 f/s\n","122208: done 1308 episodes, mean reward 0.163, speed 47.03 f/s\n","122270: done 1310 episodes, mean reward 0.163, speed 46.12 f/s\n","122323: done 1311 episodes, mean reward 0.164, speed 49.91 f/s\n","122405: done 1312 episodes, mean reward 0.167, speed 50.52 f/s\n","122457: done 1313 episodes, mean reward 0.168, speed 50.08 f/s\n","122520: done 1315 episodes, mean reward 0.170, speed 45.03 f/s\n","122590: done 1316 episodes, mean reward 0.170, speed 51.93 f/s\n","122716: done 1317 episodes, mean reward 0.170, speed 53.86 f/s\n","122775: done 1319 episodes, mean reward 0.169, speed 45.66 f/s\n","122852: done 1321 episodes, mean reward 0.171, speed 48.42 f/s\n","122931: done 1323 episodes, mean reward 0.171, speed 48.17 f/s\n","122999: done 1325 episodes, mean reward 0.171, speed 47.24 f/s\n","123073: done 1327 episodes, mean reward 0.172, speed 48.07 f/s\n","123133: done 1329 episodes, mean reward 0.171, speed 45.69 f/s\n","123241: done 1330 episodes, mean reward 0.173, speed 53.36 f/s\n","123319: done 1332 episodes, mean reward 0.173, speed 47.88 f/s\n","123447: done 1333 episodes, mean reward 0.173, speed 52.51 f/s\n","123502: done 1335 episodes, mean reward 0.172, speed 44.76 f/s\n","123572: done 1337 episodes, mean reward 0.173, speed 46.44 f/s\n","123636: done 1339 episodes, mean reward 0.172, speed 45.82 f/s\n","123751: done 1341 episodes, mean reward 0.173, speed 49.95 f/s\n","123827: done 1342 episodes, mean reward 0.175, speed 52.72 f/s\n","123879: done 1344 episodes, mean reward 0.174, speed 43.54 f/s\n","124016: done 1346 episodes, mean reward 0.173, speed 51.04 f/s\n","124135: done 1347 episodes, mean reward 0.174, speed 53.80 f/s\n","124214: done 1349 episodes, mean reward 0.177, speed 48.29 f/s\n","124281: done 1351 episodes, mean reward 0.176, speed 46.61 f/s\n","124339: done 1353 episodes, mean reward 0.177, speed 46.01 f/s\n","124403: done 1355 episodes, mean reward 0.177, speed 46.76 f/s\n","124455: done 1357 episodes, mean reward 0.176, speed 44.52 f/s\n","124524: done 1359 episodes, mean reward 0.177, speed 47.05 f/s\n","124604: done 1361 episodes, mean reward 0.178, speed 49.15 f/s\n","124673: done 1363 episodes, mean reward 0.178, speed 46.33 f/s\n","124740: done 1365 episodes, mean reward 0.177, speed 47.54 f/s\n","124796: done 1367 episodes, mean reward 0.177, speed 44.60 f/s\n","124853: done 1369 episodes, mean reward 0.176, speed 44.81 f/s\n","124914: done 1371 episodes, mean reward 0.175, speed 46.88 f/s\n","124982: done 1373 episodes, mean reward 0.175, speed 46.71 f/s\n","125054: done 1375 episodes, mean reward 0.176, speed 47.26 f/s\n","125130: done 1377 episodes, mean reward 0.177, speed 47.99 f/s\n","125215: done 1379 episodes, mean reward 0.181, speed 49.67 f/s\n","125269: done 1380 episodes, mean reward 0.183, speed 51.35 f/s\n","125327: done 1382 episodes, mean reward 0.183, speed 45.88 f/s\n","125463: done 1384 episodes, mean reward 0.183, speed 51.14 f/s\n","125581: done 1385 episodes, mean reward 0.183, speed 52.34 f/s\n","125646: done 1387 episodes, mean reward 0.183, speed 45.88 f/s\n","125734: done 1389 episodes, mean reward 0.183, speed 49.54 f/s\n","125786: done 1390 episodes, mean reward 0.185, speed 51.52 f/s\n","125846: done 1392 episodes, mean reward 0.183, speed 45.28 f/s\n","125936: done 1394 episodes, mean reward 0.185, speed 49.99 f/s\n","126007: done 1396 episodes, mean reward 0.185, speed 47.75 f/s\n","126105: done 1397 episodes, mean reward 0.186, speed 53.80 f/s\n","126165: done 1399 episodes, mean reward 0.185, speed 45.45 f/s\n","126223: done 1401 episodes, mean reward 0.185, speed 46.05 f/s\n","126318: done 1403 episodes, mean reward 0.187, speed 50.05 f/s\n","126376: done 1405 episodes, mean reward 0.184, speed 44.00 f/s\n","126436: done 1407 episodes, mean reward 0.184, speed 45.81 f/s\n","126555: done 1409 episodes, mean reward 0.184, speed 50.89 f/s\n","126713: done 1411 episodes, mean reward 0.182, speed 51.82 f/s\n","126797: done 1413 episodes, mean reward 0.180, speed 48.58 f/s\n","126969: done 1415 episodes, mean reward 0.178, speed 52.65 f/s\n","127058: done 1416 episodes, mean reward 0.179, speed 52.91 f/s\n","127117: done 1418 episodes, mean reward 0.178, speed 44.69 f/s\n","127187: done 1420 episodes, mean reward 0.177, speed 47.61 f/s\n","127278: done 1421 episodes, mean reward 0.176, speed 53.36 f/s\n","127372: done 1423 episodes, mean reward 0.178, speed 50.11 f/s\n","127505: done 1424 episodes, mean reward 0.178, speed 54.54 f/s\n","127583: done 1426 episodes, mean reward 0.179, speed 48.85 f/s\n","127671: done 1428 episodes, mean reward 0.181, speed 49.60 f/s\n","127749: done 1430 episodes, mean reward 0.180, speed 48.93 f/s\n","127853: done 1432 episodes, mean reward 0.179, speed 49.20 f/s\n","127949: done 1434 episodes, mean reward 0.179, speed 50.59 f/s\n","128036: done 1436 episodes, mean reward 0.181, speed 49.47 f/s\n","128119: done 1438 episodes, mean reward 0.182, speed 49.20 f/s\n","128203: done 1440 episodes, mean reward 0.183, speed 49.16 f/s\n","128288: done 1442 episodes, mean reward 0.184, speed 48.92 f/s\n","128368: done 1444 episodes, mean reward 0.186, speed 48.70 f/s\n","128458: done 1446 episodes, mean reward 0.188, speed 49.29 f/s\n","128547: done 1448 episodes, mean reward 0.188, speed 49.82 f/s\n","128642: done 1450 episodes, mean reward 0.191, speed 50.06 f/s\n","128721: done 1452 episodes, mean reward 0.192, speed 47.67 f/s\n","128817: done 1454 episodes, mean reward 0.195, speed 51.18 f/s\n","128886: done 1456 episodes, mean reward 0.197, speed 47.29 f/s\n","128974: done 1458 episodes, mean reward 0.198, speed 49.90 f/s\n","129119: done 1460 episodes, mean reward 0.197, speed 52.45 f/s\n","129200: done 1462 episodes, mean reward 0.198, speed 48.93 f/s\n","129270: done 1464 episodes, mean reward 0.199, speed 47.90 f/s\n","129341: done 1466 episodes, mean reward 0.199, speed 47.56 f/s\n","129411: done 1467 episodes, mean reward 0.200, speed 50.86 f/s\n","129493: done 1469 episodes, mean reward 0.203, speed 47.44 f/s\n","129574: done 1471 episodes, mean reward 0.205, speed 48.82 f/s\n","129647: done 1473 episodes, mean reward 0.205, speed 47.79 f/s\n","129743: done 1475 episodes, mean reward 0.207, speed 50.18 f/s\n","129825: done 1477 episodes, mean reward 0.209, speed 48.50 f/s\n","129920: done 1478 episodes, mean reward 0.208, speed 53.16 f/s\n","EEEE tensor(-8.6591, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0990, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(8.2207e-05, grad_fn=<ExpBackward>)\n","Test done in 3.73 sec, reward 0.252, steps 41\n","Best reward updated: 0.184 -> 0.252\n","130006: done 1480 episodes, mean reward 0.207, speed 15.57 f/s\n","130055: done 1481 episodes, mean reward 0.208, speed 48.90 f/s\n","130163: done 1483 episodes, mean reward 0.213, speed 50.29 f/s\n","130255: done 1485 episodes, mean reward 0.214, speed 49.80 f/s\n","130335: done 1487 episodes, mean reward 0.216, speed 49.45 f/s\n","130428: done 1489 episodes, mean reward 0.217, speed 49.78 f/s\n","130534: done 1491 episodes, mean reward 0.218, speed 50.30 f/s\n","130632: done 1493 episodes, mean reward 0.220, speed 50.38 f/s\n","130697: done 1495 episodes, mean reward 0.218, speed 47.39 f/s\n","130790: done 1497 episodes, mean reward 0.220, speed 49.89 f/s\n","130879: done 1498 episodes, mean reward 0.222, speed 51.93 f/s\n","130943: done 1499 episodes, mean reward 0.224, speed 50.88 f/s\n","131025: done 1501 episodes, mean reward 0.224, speed 49.21 f/s\n","131115: done 1503 episodes, mean reward 0.224, speed 49.46 f/s\n","131195: done 1505 episodes, mean reward 0.226, speed 48.63 f/s\n","131291: done 1507 episodes, mean reward 0.229, speed 49.80 f/s\n","131400: done 1509 episodes, mean reward 0.231, speed 50.90 f/s\n","131504: done 1511 episodes, mean reward 0.235, speed 51.32 f/s\n","131597: done 1513 episodes, mean reward 0.236, speed 50.79 f/s\n","131662: done 1514 episodes, mean reward 0.238, speed 51.08 f/s\n","131754: done 1516 episodes, mean reward 0.240, speed 50.31 f/s\n","131841: done 1518 episodes, mean reward 0.242, speed 50.24 f/s\n","131936: done 1520 episodes, mean reward 0.244, speed 50.95 f/s\n","131996: done 1521 episodes, mean reward 0.245, speed 52.45 f/s\n","132092: done 1523 episodes, mean reward 0.244, speed 50.86 f/s\n","132194: done 1525 episodes, mean reward 0.244, speed 50.69 f/s\n","132280: done 1527 episodes, mean reward 0.243, speed 50.12 f/s\n","132379: done 1529 episodes, mean reward 0.243, speed 50.53 f/s\n","132490: done 1531 episodes, mean reward 0.245, speed 51.36 f/s\n","132630: done 1533 episodes, mean reward 0.245, speed 53.38 f/s\n","132724: done 1535 episodes, mean reward 0.245, speed 50.27 f/s\n","132780: done 1536 episodes, mean reward 0.244, speed 51.26 f/s\n","132869: done 1538 episodes, mean reward 0.245, speed 50.62 f/s\n","132966: done 1540 episodes, mean reward 0.245, speed 50.91 f/s\n","133056: done 1542 episodes, mean reward 0.243, speed 50.25 f/s\n","133134: done 1544 episodes, mean reward 0.242, speed 49.82 f/s\n","133251: done 1545 episodes, mean reward 0.241, speed 54.48 f/s\n","133304: done 1546 episodes, mean reward 0.240, speed 49.83 f/s\n","133407: done 1547 episodes, mean reward 0.240, speed 53.55 f/s\n","133466: done 1548 episodes, mean reward 0.239, speed 51.86 f/s\n","133529: done 1549 episodes, mean reward 0.238, speed 52.88 f/s\n","133621: done 1551 episodes, mean reward 0.240, speed 50.82 f/s\n","133710: done 1553 episodes, mean reward 0.239, speed 50.11 f/s\n","133807: done 1555 episodes, mean reward 0.237, speed 50.91 f/s\n","133980: done 1556 episodes, mean reward 0.237, speed 54.88 f/s\n","134092: done 1558 episodes, mean reward 0.236, speed 50.97 f/s\n","134174: done 1560 episodes, mean reward 0.237, speed 48.43 f/s\n","134287: done 1562 episodes, mean reward 0.236, speed 50.88 f/s\n","134425: done 1564 episodes, mean reward 0.237, speed 52.15 f/s\n","134533: done 1566 episodes, mean reward 0.238, speed 50.94 f/s\n","134627: done 1568 episodes, mean reward 0.239, speed 50.36 f/s\n","134722: done 1570 episodes, mean reward 0.238, speed 50.69 f/s\n","134811: done 1572 episodes, mean reward 0.239, speed 50.64 f/s\n","134902: done 1574 episodes, mean reward 0.240, speed 50.91 f/s\n","134993: done 1576 episodes, mean reward 0.240, speed 49.77 f/s\n","135258: done 1578 episodes, mean reward 0.242, speed 55.52 f/s\n","135353: done 1580 episodes, mean reward 0.242, speed 51.43 f/s\n","135461: done 1582 episodes, mean reward 0.240, speed 51.85 f/s\n","135547: done 1584 episodes, mean reward 0.238, speed 49.78 f/s\n","135629: done 1586 episodes, mean reward 0.236, speed 49.70 f/s\n","135727: done 1587 episodes, mean reward 0.238, speed 53.55 f/s\n","135840: done 1589 episodes, mean reward 0.239, speed 50.36 f/s\n","135931: done 1591 episodes, mean reward 0.239, speed 49.84 f/s\n","136021: done 1593 episodes, mean reward 0.238, speed 49.24 f/s\n","136114: done 1595 episodes, mean reward 0.239, speed 49.94 f/s\n","136199: done 1597 episodes, mean reward 0.236, speed 50.03 f/s\n","136330: done 1599 episodes, mean reward 0.234, speed 52.35 f/s\n","136482: done 1601 episodes, mean reward 0.234, speed 53.01 f/s\n","136564: done 1602 episodes, mean reward 0.234, speed 53.48 f/s\n","136710: done 1603 episodes, mean reward 0.234, speed 55.73 f/s\n","136872: done 1604 episodes, mean reward 0.235, speed 56.24 f/s\n","136978: done 1606 episodes, mean reward 0.235, speed 51.06 f/s\n","137069: done 1608 episodes, mean reward 0.235, speed 49.76 f/s\n","137158: done 1610 episodes, mean reward 0.235, speed 48.67 f/s\n","137211: done 1611 episodes, mean reward 0.234, speed 50.80 f/s\n","137279: done 1612 episodes, mean reward 0.234, speed 52.05 f/s\n","137443: done 1613 episodes, mean reward 0.234, speed 55.42 f/s\n","137534: done 1615 episodes, mean reward 0.234, speed 48.60 f/s\n","137619: done 1617 episodes, mean reward 0.234, speed 49.60 f/s\n","137671: done 1618 episodes, mean reward 0.234, speed 50.61 f/s\n","137809: done 1620 episodes, mean reward 0.235, speed 52.37 f/s\n","138270: done 1622 episodes, mean reward 0.235, speed 55.55 f/s\n","138376: done 1624 episodes, mean reward 0.236, speed 50.64 f/s\n","138499: done 1626 episodes, mean reward 0.236, speed 51.09 f/s\n","138557: done 1627 episodes, mean reward 0.236, speed 50.84 f/s\n","138667: done 1629 episodes, mean reward 0.237, speed 51.14 f/s\n","138957: done 1630 episodes, mean reward 0.237, speed 56.66 f/s\n","139136: done 1631 episodes, mean reward 0.238, speed 56.15 f/s\n","139229: done 1633 episodes, mean reward 0.239, speed 50.58 f/s\n","139289: done 1634 episodes, mean reward 0.239, speed 51.96 f/s\n","139592: done 1636 episodes, mean reward 0.240, speed 55.28 f/s\n","139678: done 1638 episodes, mean reward 0.240, speed 49.86 f/s\n","139832: done 1639 episodes, mean reward 0.240, speed 52.36 f/s\n","139914: done 1640 episodes, mean reward 0.240, speed 53.03 f/s\n","139996: done 1642 episodes, mean reward 0.240, speed 49.64 f/s\n","EEEE tensor(-8.2627, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0845, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0001, grad_fn=<ExpBackward>)\n","Test done in 6.70 sec, reward 0.248, steps 91\n","140042: done 1643 episodes, mean reward 0.241, speed 6.02 f/s\n","140192: done 1644 episodes, mean reward 0.240, speed 55.14 f/s\n","140488: done 1646 episodes, mean reward 0.242, speed 55.48 f/s\n","140580: done 1648 episodes, mean reward 0.243, speed 49.99 f/s\n","140641: done 1649 episodes, mean reward 0.244, speed 52.06 f/s\n","140874: done 1651 episodes, mean reward 0.244, speed 54.59 f/s\n","141042: done 1652 episodes, mean reward 0.244, speed 55.52 f/s\n","141304: done 1653 episodes, mean reward 0.243, speed 56.31 f/s\n","141365: done 1654 episodes, mean reward 0.245, speed 51.34 f/s\n","141450: done 1656 episodes, mean reward 0.245, speed 49.90 f/s\n","141587: done 1657 episodes, mean reward 0.244, speed 53.78 f/s\n","141681: done 1658 episodes, mean reward 0.245, speed 53.60 f/s\n","141863: done 1660 episodes, mean reward 0.245, speed 53.67 f/s\n","142071: done 1661 episodes, mean reward 0.245, speed 56.07 f/s\n","142195: done 1662 episodes, mean reward 0.245, speed 53.73 f/s\n","142340: done 1663 episodes, mean reward 0.244, speed 54.71 f/s\n","142414: done 1664 episodes, mean reward 0.245, speed 52.16 f/s\n","142572: done 1665 episodes, mean reward 0.244, speed 55.19 f/s\n","142635: done 1666 episodes, mean reward 0.244, speed 51.21 f/s\n","142830: done 1668 episodes, mean reward 0.244, speed 54.29 f/s\n","142919: done 1670 episodes, mean reward 0.243, speed 49.55 f/s\n","143058: done 1671 episodes, mean reward 0.242, speed 54.80 f/s\n","143121: done 1672 episodes, mean reward 0.240, speed 51.54 f/s\n","143205: done 1673 episodes, mean reward 0.240, speed 52.63 f/s\n","143291: done 1675 episodes, mean reward 0.239, speed 50.23 f/s\n","143375: done 1677 episodes, mean reward 0.237, speed 49.69 f/s\n","143452: done 1679 episodes, mean reward 0.234, speed 49.12 f/s\n","143660: done 1680 episodes, mean reward 0.235, speed 55.64 f/s\n","143746: done 1682 episodes, mean reward 0.234, speed 49.65 f/s\n","143799: done 1683 episodes, mean reward 0.234, speed 50.36 f/s\n","144049: done 1684 episodes, mean reward 0.233, speed 56.60 f/s\n","144129: done 1685 episodes, mean reward 0.233, speed 53.39 f/s\n","144383: done 1686 episodes, mean reward 0.232, speed 56.54 f/s\n","144466: done 1687 episodes, mean reward 0.231, speed 53.64 f/s\n","144645: done 1688 episodes, mean reward 0.231, speed 55.21 f/s\n","144733: done 1690 episodes, mean reward 0.231, speed 50.73 f/s\n","144821: done 1692 episodes, mean reward 0.231, speed 50.29 f/s\n","144918: done 1694 episodes, mean reward 0.233, speed 50.48 f/s\n","145049: done 1695 episodes, mean reward 0.234, speed 55.63 f/s\n","145132: done 1697 episodes, mean reward 0.235, speed 49.99 f/s\n","145220: done 1699 episodes, mean reward 0.236, speed 50.13 f/s\n","145295: done 1700 episodes, mean reward 0.237, speed 53.73 f/s\n","145367: done 1701 episodes, mean reward 0.237, speed 52.99 f/s\n","145444: done 1702 episodes, mean reward 0.239, speed 52.90 f/s\n","145524: done 1703 episodes, mean reward 0.239, speed 54.23 f/s\n","145608: done 1705 episodes, mean reward 0.239, speed 50.14 f/s\n","145689: done 1707 episodes, mean reward 0.238, speed 49.76 f/s\n","145941: done 1708 episodes, mean reward 0.238, speed 56.58 f/s\n","146026: done 1710 episodes, mean reward 0.236, speed 50.13 f/s\n","146112: done 1712 episodes, mean reward 0.237, speed 50.11 f/s\n","146168: done 1713 episodes, mean reward 0.237, speed 50.95 f/s\n","146336: done 1714 episodes, mean reward 0.236, speed 55.65 f/s\n","146485: done 1716 episodes, mean reward 0.236, speed 52.95 f/s\n","146662: done 1718 episodes, mean reward 0.236, speed 53.91 f/s\n","146747: done 1720 episodes, mean reward 0.235, speed 49.46 f/s\n","146887: done 1721 episodes, mean reward 0.233, speed 55.22 f/s\n","146969: done 1723 episodes, mean reward 0.233, speed 49.71 f/s\n","147058: done 1725 episodes, mean reward 0.233, speed 50.66 f/s\n","147225: done 1726 episodes, mean reward 0.233, speed 56.36 f/s\n","147377: done 1727 episodes, mean reward 0.233, speed 56.16 f/s\n","147567: done 1729 episodes, mean reward 0.232, speed 54.83 f/s\n","147714: done 1731 episodes, mean reward 0.231, speed 53.45 f/s\n","147765: done 1732 episodes, mean reward 0.232, speed 50.84 f/s\n","147844: done 1734 episodes, mean reward 0.232, speed 49.30 f/s\n","147931: done 1735 episodes, mean reward 0.231, speed 52.98 f/s\n","147996: done 1736 episodes, mean reward 0.231, speed 52.81 f/s\n","148157: done 1737 episodes, mean reward 0.232, speed 56.12 f/s\n","148241: done 1739 episodes, mean reward 0.232, speed 50.13 f/s\n","148304: done 1740 episodes, mean reward 0.232, speed 52.57 f/s\n","148401: done 1742 episodes, mean reward 0.233, speed 50.85 f/s\n","148466: done 1743 episodes, mean reward 0.234, speed 51.69 f/s\n","148530: done 1744 episodes, mean reward 0.235, speed 52.70 f/s\n","148593: done 1745 episodes, mean reward 0.234, speed 51.90 f/s\n","148720: done 1747 episodes, mean reward 0.235, speed 52.02 f/s\n","148778: done 1748 episodes, mean reward 0.234, speed 51.25 f/s\n","148888: done 1750 episodes, mean reward 0.234, speed 51.28 f/s\n","148976: done 1752 episodes, mean reward 0.235, speed 50.58 f/s\n","149098: done 1754 episodes, mean reward 0.234, speed 52.29 f/s\n","149183: done 1756 episodes, mean reward 0.236, speed 50.62 f/s\n","149254: done 1757 episodes, mean reward 0.237, speed 53.18 f/s\n","149311: done 1758 episodes, mean reward 0.237, speed 52.06 f/s\n","149392: done 1760 episodes, mean reward 0.237, speed 49.73 f/s\n","149456: done 1761 episodes, mean reward 0.238, speed 53.55 f/s\n","149525: done 1762 episodes, mean reward 0.239, speed 52.29 f/s\n","149593: done 1763 episodes, mean reward 0.239, speed 51.56 f/s\n","149856: done 1764 episodes, mean reward 0.237, speed 56.43 f/s\n","149957: done 1766 episodes, mean reward 0.237, speed 51.18 f/s\n","EEEE tensor(-8.0136, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0891, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0001, grad_fn=<ExpBackward>)\n","Test done in 4.59 sec, reward 0.257, steps 54\n","Best reward updated: 0.252 -> 0.257\n","150015: done 1767 episodes, mean reward 0.237, speed 10.13 f/s\n","150069: done 1768 episodes, mean reward 0.238, speed 51.29 f/s\n","150286: done 1770 episodes, mean reward 0.239, speed 54.45 f/s\n","150377: done 1772 episodes, mean reward 0.240, speed 50.67 f/s\n","150536: done 1774 episodes, mean reward 0.241, speed 53.88 f/s\n","150635: done 1776 episodes, mean reward 0.241, speed 50.45 f/s\n","150710: done 1778 episodes, mean reward 0.242, speed 48.77 f/s\n","150787: done 1780 episodes, mean reward 0.241, speed 48.78 f/s\n","150838: done 1781 episodes, mean reward 0.241, speed 50.00 f/s\n","150922: done 1783 episodes, mean reward 0.241, speed 49.38 f/s\n","151018: done 1785 episodes, mean reward 0.243, speed 50.78 f/s\n","151080: done 1786 episodes, mean reward 0.244, speed 51.90 f/s\n","151183: done 1788 episodes, mean reward 0.244, speed 51.37 f/s\n","151248: done 1789 episodes, mean reward 0.244, speed 52.71 f/s\n","151325: done 1790 episodes, mean reward 0.245, speed 53.52 f/s\n","151407: done 1792 episodes, mean reward 0.244, speed 49.06 f/s\n","151487: done 1793 episodes, mean reward 0.244, speed 53.93 f/s\n","151566: done 1795 episodes, mean reward 0.242, speed 49.30 f/s\n","151659: done 1797 episodes, mean reward 0.243, speed 50.35 f/s\n","151759: done 1798 episodes, mean reward 0.243, speed 54.27 f/s\n","151883: done 1800 episodes, mean reward 0.243, speed 51.44 f/s\n","151945: done 1801 episodes, mean reward 0.244, speed 52.30 f/s\n","152047: done 1803 episodes, mean reward 0.243, speed 50.65 f/s\n","152116: done 1804 episodes, mean reward 0.243, speed 51.08 f/s\n","152168: done 1805 episodes, mean reward 0.243, speed 49.64 f/s\n","152220: done 1806 episodes, mean reward 0.244, speed 50.17 f/s\n","152277: done 1807 episodes, mean reward 0.244, speed 51.56 f/s\n","152358: done 1808 episodes, mean reward 0.244, speed 53.24 f/s\n","152443: done 1810 episodes, mean reward 0.246, speed 49.87 f/s\n","152502: done 1811 episodes, mean reward 0.246, speed 51.90 f/s\n","152573: done 1812 episodes, mean reward 0.248, speed 52.78 f/s\n","152666: done 1814 episodes, mean reward 0.247, speed 50.68 f/s\n","152719: done 1815 episodes, mean reward 0.248, speed 51.70 f/s\n","152802: done 1817 episodes, mean reward 0.249, speed 49.50 f/s\n","152854: done 1818 episodes, mean reward 0.248, speed 51.01 f/s\n","152910: done 1819 episodes, mean reward 0.248, speed 51.35 f/s\n","153019: done 1821 episodes, mean reward 0.248, speed 51.54 f/s\n","153088: done 1822 episodes, mean reward 0.249, speed 51.81 f/s\n","153226: done 1824 episodes, mean reward 0.249, speed 52.85 f/s\n","153339: done 1826 episodes, mean reward 0.250, speed 51.54 f/s\n","153390: done 1827 episodes, mean reward 0.250, speed 50.28 f/s\n","153492: done 1829 episodes, mean reward 0.249, speed 51.17 f/s\n","153580: done 1831 episodes, mean reward 0.250, speed 50.36 f/s\n","153677: done 1833 episodes, mean reward 0.249, speed 50.16 f/s\n","153751: done 1835 episodes, mean reward 0.248, speed 48.27 f/s\n","153805: done 1836 episodes, mean reward 0.247, speed 50.90 f/s\n","153886: done 1838 episodes, mean reward 0.245, speed 49.53 f/s\n","153941: done 1839 episodes, mean reward 0.246, speed 51.05 f/s\n","153996: done 1840 episodes, mean reward 0.246, speed 51.04 f/s\n","154112: done 1842 episodes, mean reward 0.246, speed 51.39 f/s\n","154178: done 1843 episodes, mean reward 0.246, speed 51.76 f/s\n","154236: done 1844 episodes, mean reward 0.246, speed 52.05 f/s\n","154292: done 1845 episodes, mean reward 0.245, speed 50.72 f/s\n","154357: done 1846 episodes, mean reward 0.245, speed 52.27 f/s\n","154433: done 1847 episodes, mean reward 0.246, speed 53.16 f/s\n","154509: done 1848 episodes, mean reward 0.246, speed 53.57 f/s\n","154604: done 1850 episodes, mean reward 0.245, speed 50.65 f/s\n","154689: done 1852 episodes, mean reward 0.245, speed 49.27 f/s\n","154756: done 1853 episodes, mean reward 0.245, speed 51.68 f/s\n","154812: done 1854 episodes, mean reward 0.244, speed 51.26 f/s\n","154896: done 1855 episodes, mean reward 0.245, speed 52.88 f/s\n","154991: done 1857 episodes, mean reward 0.244, speed 50.27 f/s\n","155098: done 1859 episodes, mean reward 0.244, speed 51.03 f/s\n","155196: done 1861 episodes, mean reward 0.243, speed 50.64 f/s\n","155258: done 1862 episodes, mean reward 0.243, speed 51.31 f/s\n","155361: done 1864 episodes, mean reward 0.244, speed 50.87 f/s\n","155416: done 1865 episodes, mean reward 0.244, speed 49.18 f/s\n","155468: done 1866 episodes, mean reward 0.243, speed 49.77 f/s\n","155526: done 1867 episodes, mean reward 0.242, speed 51.30 f/s\n","155605: done 1868 episodes, mean reward 0.242, speed 51.83 f/s\n","155663: done 1869 episodes, mean reward 0.241, speed 50.19 f/s\n","155725: done 1870 episodes, mean reward 0.243, speed 51.29 f/s\n","155789: done 1871 episodes, mean reward 0.243, speed 51.05 f/s\n","155852: done 1872 episodes, mean reward 0.242, speed 51.06 f/s\n","155945: done 1874 episodes, mean reward 0.242, speed 50.70 f/s\n","156027: done 1875 episodes, mean reward 0.242, speed 53.81 f/s\n","156129: done 1876 episodes, mean reward 0.243, speed 54.85 f/s\n","156266: done 1878 episodes, mean reward 0.244, speed 52.81 f/s\n","156341: done 1879 episodes, mean reward 0.245, speed 53.26 f/s\n","156425: done 1880 episodes, mean reward 0.245, speed 50.70 f/s\n","156513: done 1881 episodes, mean reward 0.247, speed 53.54 f/s\n","156615: done 1882 episodes, mean reward 0.247, speed 54.82 f/s\n","156746: done 1884 episodes, mean reward 0.248, speed 52.25 f/s\n","156809: done 1885 episodes, mean reward 0.248, speed 51.78 f/s\n","156875: done 1886 episodes, mean reward 0.247, speed 52.15 f/s\n","156932: done 1887 episodes, mean reward 0.248, speed 52.17 f/s\n","156994: done 1888 episodes, mean reward 0.247, speed 52.43 f/s\n","157059: done 1889 episodes, mean reward 0.246, speed 51.57 f/s\n","157161: done 1891 episodes, mean reward 0.247, speed 51.59 f/s\n","157219: done 1892 episodes, mean reward 0.247, speed 51.47 f/s\n","157305: done 1893 episodes, mean reward 0.248, speed 53.28 f/s\n","157375: done 1894 episodes, mean reward 0.248, speed 52.87 f/s\n","157441: done 1895 episodes, mean reward 0.249, speed 51.77 f/s\n","157497: done 1896 episodes, mean reward 0.249, speed 51.36 f/s\n","157604: done 1898 episodes, mean reward 0.250, speed 51.56 f/s\n","157697: done 1899 episodes, mean reward 0.249, speed 54.33 f/s\n","157789: done 1900 episodes, mean reward 0.249, speed 54.09 f/s\n","157855: done 1901 episodes, mean reward 0.248, speed 50.11 f/s\n","157953: done 1903 episodes, mean reward 0.247, speed 51.01 f/s\n","158046: done 1905 episodes, mean reward 0.247, speed 50.61 f/s\n","158154: done 1907 episodes, mean reward 0.245, speed 51.50 f/s\n","158214: done 1908 episodes, mean reward 0.245, speed 52.25 f/s\n","158300: done 1909 episodes, mean reward 0.246, speed 53.78 f/s\n","158366: done 1910 episodes, mean reward 0.245, speed 52.70 f/s\n","158455: done 1911 episodes, mean reward 0.246, speed 53.28 f/s\n","158529: done 1912 episodes, mean reward 0.245, speed 52.54 f/s\n","158592: done 1913 episodes, mean reward 0.245, speed 52.24 f/s\n","158662: done 1914 episodes, mean reward 0.246, speed 52.74 f/s\n","158724: done 1915 episodes, mean reward 0.245, speed 51.54 f/s\n","158806: done 1916 episodes, mean reward 0.244, speed 52.45 f/s\n","158911: done 1918 episodes, mean reward 0.243, speed 51.19 f/s\n","158968: done 1919 episodes, mean reward 0.243, speed 50.89 f/s\n","159059: done 1921 episodes, mean reward 0.244, speed 49.68 f/s\n","159168: done 1923 episodes, mean reward 0.242, speed 50.54 f/s\n","159236: done 1924 episodes, mean reward 0.245, speed 51.62 f/s\n","159339: done 1926 episodes, mean reward 0.244, speed 50.71 f/s\n","159414: done 1927 episodes, mean reward 0.245, speed 52.70 f/s\n","159478: done 1928 episodes, mean reward 0.245, speed 51.90 f/s\n","159547: done 1929 episodes, mean reward 0.246, speed 51.38 f/s\n","159612: done 1930 episodes, mean reward 0.246, speed 50.96 f/s\n","159682: done 1931 episodes, mean reward 0.246, speed 51.81 f/s\n","159745: done 1932 episodes, mean reward 0.247, speed 50.45 f/s\n","159865: done 1934 episodes, mean reward 0.250, speed 51.85 f/s\n","159928: done 1935 episodes, mean reward 0.250, speed 51.30 f/s\n","159995: done 1936 episodes, mean reward 0.250, speed 51.39 f/s\n","EEEE tensor(-8.9628, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0916, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0001, grad_fn=<ExpBackward>)\n","Test done in 5.65 sec, reward 0.305, steps 72\n","Best reward updated: 0.257 -> 0.305\n","160044: done 1937 episodes, mean reward 0.250, speed 7.39 f/s\n","160123: done 1938 episodes, mean reward 0.251, speed 52.83 f/s\n","160205: done 1940 episodes, mean reward 0.252, speed 49.02 f/s\n","160281: done 1941 episodes, mean reward 0.253, speed 53.05 f/s\n","160353: done 1942 episodes, mean reward 0.253, speed 52.74 f/s\n","160415: done 1943 episodes, mean reward 0.253, speed 51.74 f/s\n","160477: done 1944 episodes, mean reward 0.253, speed 51.99 f/s\n","160621: done 1945 episodes, mean reward 0.253, speed 54.68 f/s\n","160691: done 1946 episodes, mean reward 0.254, speed 52.80 f/s\n","160756: done 1947 episodes, mean reward 0.254, speed 53.14 f/s\n","160827: done 1948 episodes, mean reward 0.254, speed 52.95 f/s\n","160914: done 1949 episodes, mean reward 0.255, speed 53.54 f/s\n","160979: done 1950 episodes, mean reward 0.256, speed 52.99 f/s\n","161044: done 1951 episodes, mean reward 0.257, speed 52.55 f/s\n","161157: done 1952 episodes, mean reward 0.258, speed 54.43 f/s\n","161243: done 1954 episodes, mean reward 0.259, speed 49.34 f/s\n","161376: done 1955 episodes, mean reward 0.259, speed 54.50 f/s\n","161521: done 1957 episodes, mean reward 0.260, speed 52.13 f/s\n","161592: done 1958 episodes, mean reward 0.261, speed 51.64 f/s\n","161676: done 1959 episodes, mean reward 0.262, speed 52.74 f/s\n","161769: done 1960 episodes, mean reward 0.263, speed 52.83 f/s\n","161842: done 1961 episodes, mean reward 0.264, speed 52.30 f/s\n","162028: done 1962 episodes, mean reward 0.263, speed 54.83 f/s\n","162143: done 1964 episodes, mean reward 0.265, speed 49.38 f/s\n","162210: done 1965 episodes, mean reward 0.266, speed 50.65 f/s\n","162284: done 1966 episodes, mean reward 0.267, speed 52.13 f/s\n","162395: done 1967 episodes, mean reward 0.268, speed 53.01 f/s\n","162466: done 1968 episodes, mean reward 0.268, speed 51.80 f/s\n","162553: done 1969 episodes, mean reward 0.269, speed 51.47 f/s\n","162642: done 1970 episodes, mean reward 0.269, speed 52.65 f/s\n","162729: done 1971 episodes, mean reward 0.270, speed 50.67 f/s\n","162843: done 1972 episodes, mean reward 0.271, speed 53.57 f/s\n","162923: done 1973 episodes, mean reward 0.272, speed 51.93 f/s\n","163064: done 1974 episodes, mean reward 0.273, speed 53.52 f/s\n","163140: done 1975 episodes, mean reward 0.273, speed 51.16 f/s\n","163249: done 1976 episodes, mean reward 0.274, speed 52.14 f/s\n","163318: done 1977 episodes, mean reward 0.275, speed 51.21 f/s\n","163384: done 1978 episodes, mean reward 0.277, speed 51.30 f/s\n","163448: done 1979 episodes, mean reward 0.278, speed 50.83 f/s\n","163528: done 1980 episodes, mean reward 0.279, speed 52.54 f/s\n","163613: done 1981 episodes, mean reward 0.278, speed 51.77 f/s\n","163664: done 1982 episodes, mean reward 0.280, speed 49.90 f/s\n","163746: done 1983 episodes, mean reward 0.281, speed 50.71 f/s\n","163888: done 1985 episodes, mean reward 0.282, speed 51.60 f/s\n","164068: done 1986 episodes, mean reward 0.283, speed 54.10 f/s\n","164134: done 1987 episodes, mean reward 0.283, speed 51.24 f/s\n","164221: done 1988 episodes, mean reward 0.285, speed 52.50 f/s\n","164354: done 1990 episodes, mean reward 0.286, speed 51.15 f/s\n","164483: done 1992 episodes, mean reward 0.287, speed 51.64 f/s\n","164585: done 1993 episodes, mean reward 0.287, speed 53.82 f/s\n","164666: done 1994 episodes, mean reward 0.288, speed 53.03 f/s\n","164866: done 1995 episodes, mean reward 0.289, speed 55.39 f/s\n","164999: done 1997 episodes, mean reward 0.290, speed 52.74 f/s\n","165073: done 1999 episodes, mean reward 0.290, speed 49.35 f/s\n","165129: done 2000 episodes, mean reward 0.291, speed 51.40 f/s\n","165197: done 2002 episodes, mean reward 0.291, speed 48.28 f/s\n","165279: done 2004 episodes, mean reward 0.292, speed 49.69 f/s\n","165339: done 2005 episodes, mean reward 0.292, speed 50.94 f/s\n","165406: done 2007 episodes, mean reward 0.291, speed 46.24 f/s\n","165457: done 2008 episodes, mean reward 0.292, speed 50.74 f/s\n","165569: done 2010 episodes, mean reward 0.292, speed 51.21 f/s\n","165670: done 2012 episodes, mean reward 0.292, speed 50.81 f/s\n","165744: done 2014 episodes, mean reward 0.292, speed 48.54 f/s\n","165813: done 2015 episodes, mean reward 0.294, speed 52.45 f/s\n","165888: done 2016 episodes, mean reward 0.295, speed 52.14 f/s\n","165954: done 2017 episodes, mean reward 0.297, speed 51.99 f/s\n","166039: done 2019 episodes, mean reward 0.299, speed 49.84 f/s\n","166176: done 2021 episodes, mean reward 0.299, speed 51.89 f/s\n","166242: done 2022 episodes, mean reward 0.301, speed 52.21 f/s\n","166327: done 2023 episodes, mean reward 0.301, speed 52.74 f/s\n","166406: done 2024 episodes, mean reward 0.301, speed 52.96 f/s\n","166498: done 2026 episodes, mean reward 0.300, speed 49.31 f/s\n","166572: done 2027 episodes, mean reward 0.301, speed 52.88 f/s\n","166646: done 2028 episodes, mean reward 0.302, speed 53.16 f/s\n","166757: done 2029 episodes, mean reward 0.302, speed 54.02 f/s\n","166819: done 2031 episodes, mean reward 0.300, speed 47.51 f/s\n","166908: done 2032 episodes, mean reward 0.301, speed 54.05 f/s\n","166982: done 2033 episodes, mean reward 0.302, speed 52.17 f/s\n","167144: done 2034 episodes, mean reward 0.302, speed 54.65 f/s\n","167269: done 2036 episodes, mean reward 0.302, speed 51.07 f/s\n","167322: done 2037 episodes, mean reward 0.303, speed 50.73 f/s\n","167423: done 2038 episodes, mean reward 0.304, speed 53.55 f/s\n","167516: done 2039 episodes, mean reward 0.303, speed 53.83 f/s\n","167607: done 2040 episodes, mean reward 0.304, speed 53.29 f/s\n","167745: done 2041 episodes, mean reward 0.305, speed 53.98 f/s\n","167881: done 2043 episodes, mean reward 0.305, speed 52.16 f/s\n","167947: done 2045 episodes, mean reward 0.304, speed 46.96 f/s\n","168017: done 2047 episodes, mean reward 0.302, speed 47.96 f/s\n","168078: done 2049 episodes, mean reward 0.299, speed 46.76 f/s\n","168176: done 2051 episodes, mean reward 0.297, speed 50.41 f/s\n","168256: done 2052 episodes, mean reward 0.297, speed 52.54 f/s\n","168316: done 2054 episodes, mean reward 0.294, speed 45.42 f/s\n","168449: done 2056 episodes, mean reward 0.295, speed 51.41 f/s\n","168527: done 2057 episodes, mean reward 0.294, speed 52.12 f/s\n","168604: done 2058 episodes, mean reward 0.295, speed 51.90 f/s\n","168713: done 2059 episodes, mean reward 0.294, speed 53.45 f/s\n","168788: done 2061 episodes, mean reward 0.292, speed 48.80 f/s\n","168861: done 2063 episodes, mean reward 0.292, speed 47.59 f/s\n","168930: done 2064 episodes, mean reward 0.292, speed 51.60 f/s\n","169003: done 2065 episodes, mean reward 0.292, speed 52.22 f/s\n","169074: done 2067 episodes, mean reward 0.290, speed 47.43 f/s\n","169144: done 2069 episodes, mean reward 0.289, speed 48.15 f/s\n","169216: done 2071 episodes, mean reward 0.287, speed 48.50 f/s\n","169355: done 2072 episodes, mean reward 0.287, speed 54.85 f/s\n","169424: done 2074 episodes, mean reward 0.285, speed 47.56 f/s\n","169490: done 2075 episodes, mean reward 0.285, speed 52.19 f/s\n","169576: done 2077 episodes, mean reward 0.284, speed 49.41 f/s\n","169644: done 2078 episodes, mean reward 0.284, speed 51.71 f/s\n","169711: done 2080 episodes, mean reward 0.281, speed 47.29 f/s\n","169778: done 2082 episodes, mean reward 0.279, speed 46.24 f/s\n","169840: done 2084 episodes, mean reward 0.276, speed 46.74 f/s\n","169902: done 2086 episodes, mean reward 0.273, speed 46.04 f/s\n","EEEE tensor(-10.2011, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0975, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0001, grad_fn=<ExpBackward>)\n","Test done in 3.50 sec, reward 0.194, steps 36\n","170002: done 2088 episodes, mean reward 0.272, speed 18.10 f/s\n","170061: done 2090 episodes, mean reward 0.269, speed 45.46 f/s\n","170159: done 2091 episodes, mean reward 0.270, speed 52.91 f/s\n","170226: done 2092 episodes, mean reward 0.270, speed 51.61 f/s\n","170290: done 2094 episodes, mean reward 0.266, speed 47.07 f/s\n","170347: done 2096 episodes, mean reward 0.263, speed 44.91 f/s\n","170429: done 2098 episodes, mean reward 0.262, speed 48.97 f/s\n","170496: done 2099 episodes, mean reward 0.263, speed 51.04 f/s\n","170577: done 2101 episodes, mean reward 0.262, speed 49.17 f/s\n","170641: done 2103 episodes, mean reward 0.261, speed 47.11 f/s\n","170757: done 2105 episodes, mean reward 0.261, speed 50.70 f/s\n","170949: done 2107 episodes, mean reward 0.263, speed 53.17 f/s\n","171039: done 2109 episodes, mean reward 0.262, speed 48.64 f/s\n","171120: done 2111 episodes, mean reward 0.262, speed 48.21 f/s\n","171222: done 2113 episodes, mean reward 0.262, speed 49.97 f/s\n","171299: done 2115 episodes, mean reward 0.261, speed 48.83 f/s\n","171375: done 2117 episodes, mean reward 0.259, speed 48.91 f/s\n","171490: done 2119 episodes, mean reward 0.260, speed 51.46 f/s\n","171568: done 2121 episodes, mean reward 0.260, speed 48.28 f/s\n","171632: done 2123 episodes, mean reward 0.257, speed 47.72 f/s\n","171695: done 2125 episodes, mean reward 0.256, speed 47.58 f/s\n","171760: done 2127 episodes, mean reward 0.253, speed 45.70 f/s\n","171814: done 2129 episodes, mean reward 0.249, speed 45.47 f/s\n","171918: done 2130 episodes, mean reward 0.250, speed 54.47 f/s\n","171974: done 2132 episodes, mean reward 0.247, speed 45.71 f/s\n","172040: done 2134 episodes, mean reward 0.243, speed 47.60 f/s\n","172105: done 2136 episodes, mean reward 0.242, speed 47.72 f/s\n","172172: done 2138 episodes, mean reward 0.239, speed 47.56 f/s\n","172231: done 2140 episodes, mean reward 0.236, speed 45.99 f/s\n","172344: done 2141 episodes, mean reward 0.235, speed 54.87 f/s\n","172439: done 2143 episodes, mean reward 0.234, speed 50.71 f/s\n","172501: done 2145 episodes, mean reward 0.234, speed 43.46 f/s\n","172609: done 2146 episodes, mean reward 0.236, speed 54.15 f/s\n","172692: done 2147 episodes, mean reward 0.237, speed 54.08 f/s\n","172810: done 2149 episodes, mean reward 0.238, speed 52.20 f/s\n","172929: done 2150 episodes, mean reward 0.240, speed 55.43 f/s\n","172989: done 2152 episodes, mean reward 0.237, speed 46.56 f/s\n","173058: done 2154 episodes, mean reward 0.239, speed 48.41 f/s\n","173150: done 2155 episodes, mean reward 0.240, speed 53.90 f/s\n","173215: done 2157 episodes, mean reward 0.236, speed 47.68 f/s\n","173272: done 2159 episodes, mean reward 0.233, speed 46.35 f/s\n","173333: done 2161 episodes, mean reward 0.231, speed 47.21 f/s\n","173443: done 2162 episodes, mean reward 0.232, speed 55.16 f/s\n","173545: done 2163 episodes, mean reward 0.233, speed 54.18 f/s\n","173745: done 2165 episodes, mean reward 0.231, speed 54.83 f/s\n","173820: done 2167 episodes, mean reward 0.231, speed 49.20 f/s\n","173905: done 2169 episodes, mean reward 0.232, speed 49.79 f/s\n","173981: done 2171 episodes, mean reward 0.232, speed 49.37 f/s\n","174070: done 2172 episodes, mean reward 0.231, speed 53.63 f/s\n","174137: done 2174 episodes, mean reward 0.231, speed 48.23 f/s\n","174236: done 2175 episodes, mean reward 0.231, speed 54.47 f/s\n","174377: done 2177 episodes, mean reward 0.228, speed 51.46 f/s\n","174439: done 2179 episodes, mean reward 0.226, speed 47.11 f/s\n","174600: done 2181 episodes, mean reward 0.227, speed 54.13 f/s\n","174663: done 2183 episodes, mean reward 0.227, speed 47.23 f/s\n","174738: done 2185 episodes, mean reward 0.229, speed 48.24 f/s\n","174909: done 2186 episodes, mean reward 0.229, speed 55.45 f/s\n","175027: done 2187 episodes, mean reward 0.230, speed 54.19 f/s\n","175093: done 2189 episodes, mean reward 0.228, speed 47.28 f/s\n","175153: done 2191 episodes, mean reward 0.226, speed 46.36 f/s\n","175221: done 2193 episodes, mean reward 0.225, speed 47.73 f/s\n","175274: done 2195 episodes, mean reward 0.223, speed 44.58 f/s\n","175340: done 2197 episodes, mean reward 0.224, speed 47.14 f/s\n","175409: done 2199 episodes, mean reward 0.221, speed 47.21 f/s\n","175467: done 2201 episodes, mean reward 0.219, speed 46.14 f/s\n","175529: done 2203 episodes, mean reward 0.218, speed 46.73 f/s\n","175598: done 2205 episodes, mean reward 0.217, speed 47.62 f/s\n","175659: done 2207 episodes, mean reward 0.214, speed 47.22 f/s\n","175815: done 2208 episodes, mean reward 0.215, speed 56.36 f/s\n","175880: done 2210 episodes, mean reward 0.213, speed 48.26 f/s\n","176033: done 2212 episodes, mean reward 0.212, speed 52.85 f/s\n","176180: done 2214 episodes, mean reward 0.211, speed 52.42 f/s\n","176237: done 2216 episodes, mean reward 0.208, speed 45.84 f/s\n","176300: done 2218 episodes, mean reward 0.206, speed 46.65 f/s\n","176367: done 2220 episodes, mean reward 0.203, speed 47.86 f/s\n","176435: done 2222 episodes, mean reward 0.204, speed 48.00 f/s\n","176557: done 2224 episodes, mean reward 0.205, speed 51.73 f/s\n","176618: done 2226 episodes, mean reward 0.204, speed 46.92 f/s\n","176687: done 2228 episodes, mean reward 0.205, speed 48.46 f/s\n","176763: done 2230 episodes, mean reward 0.205, speed 48.93 f/s\n","176833: done 2232 episodes, mean reward 0.207, speed 48.98 f/s\n","177006: done 2233 episodes, mean reward 0.208, speed 55.97 f/s\n","177184: done 2235 episodes, mean reward 0.208, speed 54.13 f/s\n","177250: done 2237 episodes, mean reward 0.207, speed 47.37 f/s\n","177309: done 2239 episodes, mean reward 0.206, speed 46.60 f/s\n","177369: done 2241 episodes, mean reward 0.205, speed 46.57 f/s\n","177439: done 2243 episodes, mean reward 0.204, speed 47.96 f/s\n","177511: done 2245 episodes, mean reward 0.204, speed 48.67 f/s\n","177584: done 2246 episodes, mean reward 0.204, speed 52.61 f/s\n","177676: done 2247 episodes, mean reward 0.203, speed 54.04 f/s\n","177741: done 2249 episodes, mean reward 0.201, speed 47.84 f/s\n","177806: done 2251 episodes, mean reward 0.199, speed 46.62 f/s\n","177898: done 2252 episodes, mean reward 0.200, speed 52.72 f/s\n","177964: done 2254 episodes, mean reward 0.199, speed 47.90 f/s\n","178089: done 2255 episodes, mean reward 0.197, speed 54.95 f/s\n","178168: done 2256 episodes, mean reward 0.198, speed 53.50 f/s\n","178271: done 2257 episodes, mean reward 0.198, speed 54.28 f/s\n","178431: done 2258 episodes, mean reward 0.200, speed 56.11 f/s\n","178580: done 2259 episodes, mean reward 0.200, speed 55.64 f/s\n","178733: done 2260 episodes, mean reward 0.201, speed 55.97 f/s\n","178890: done 2262 episodes, mean reward 0.200, speed 53.26 f/s\n","178966: done 2264 episodes, mean reward 0.199, speed 49.47 f/s\n","179107: done 2265 episodes, mean reward 0.199, speed 54.91 f/s\n","179225: done 2266 episodes, mean reward 0.199, speed 54.62 f/s\n","179288: done 2268 episodes, mean reward 0.199, speed 47.52 f/s\n","179433: done 2269 episodes, mean reward 0.197, speed 54.60 f/s\n","179500: done 2271 episodes, mean reward 0.196, speed 47.22 f/s\n","179571: done 2273 episodes, mean reward 0.195, speed 47.55 f/s\n","179634: done 2275 episodes, mean reward 0.192, speed 46.63 f/s\n","179711: done 2277 episodes, mean reward 0.192, speed 48.62 f/s\n","179780: done 2279 episodes, mean reward 0.192, speed 48.73 f/s\n","179952: done 2280 episodes, mean reward 0.192, speed 55.82 f/s\n","EEEE tensor(-7.9723, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0789, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0001, grad_fn=<ExpBackward>)\n","Test done in 8.60 sec, reward 0.226, steps 121\n","180054: done 2281 episodes, mean reward 0.192, speed 9.73 f/s\n","180224: done 2282 episodes, mean reward 0.194, speed 55.54 f/s\n","180428: done 2284 episodes, mean reward 0.194, speed 54.35 f/s\n","180652: done 2286 episodes, mean reward 0.193, speed 54.28 f/s\n","180751: done 2287 episodes, mean reward 0.193, speed 53.75 f/s\n","180968: done 2289 episodes, mean reward 0.192, speed 53.82 f/s\n","181031: done 2291 episodes, mean reward 0.192, speed 46.15 f/s\n","181132: done 2292 episodes, mean reward 0.192, speed 54.02 f/s\n","181333: done 2294 episodes, mean reward 0.193, speed 54.40 f/s\n","181542: done 2296 episodes, mean reward 0.193, speed 54.29 f/s\n","181606: done 2298 episodes, mean reward 0.192, speed 46.94 f/s\n","181675: done 2300 episodes, mean reward 0.192, speed 47.60 f/s\n","181889: done 2301 episodes, mean reward 0.193, speed 56.19 f/s\n","182064: done 2303 episodes, mean reward 0.194, speed 53.25 f/s\n","182212: done 2304 episodes, mean reward 0.194, speed 54.80 f/s\n","182315: done 2306 episodes, mean reward 0.195, speed 50.56 f/s\n","182366: done 2307 episodes, mean reward 0.196, speed 50.86 f/s\n","182569: done 2308 episodes, mean reward 0.196, speed 55.21 f/s\n","182782: done 2309 episodes, mean reward 0.195, speed 56.04 f/s\n","182852: done 2311 episodes, mean reward 0.194, speed 47.62 f/s\n","183078: done 2312 episodes, mean reward 0.193, speed 55.16 f/s\n","183151: done 2314 episodes, mean reward 0.192, speed 47.55 f/s\n","183222: done 2316 episodes, mean reward 0.193, speed 47.09 f/s\n","183410: done 2317 episodes, mean reward 0.193, speed 55.62 f/s\n","183586: done 2318 episodes, mean reward 0.194, speed 55.87 f/s\n","183705: done 2319 episodes, mean reward 0.194, speed 53.65 f/s\n","183786: done 2320 episodes, mean reward 0.195, speed 52.33 f/s\n","183860: done 2321 episodes, mean reward 0.197, speed 52.89 f/s\n","183998: done 2323 episodes, mean reward 0.197, speed 51.69 f/s\n","184104: done 2324 episodes, mean reward 0.197, speed 53.56 f/s\n","184181: done 2325 episodes, mean reward 0.197, speed 52.76 f/s\n","184387: done 2326 episodes, mean reward 0.198, speed 55.65 f/s\n","184687: done 2327 episodes, mean reward 0.199, speed 56.71 f/s\n","184884: done 2328 episodes, mean reward 0.199, speed 55.56 f/s\n","184965: done 2329 episodes, mean reward 0.200, speed 52.81 f/s\n","185107: done 2330 episodes, mean reward 0.200, speed 55.71 f/s\n","185158: done 2331 episodes, mean reward 0.201, speed 50.96 f/s\n","185256: done 2333 episodes, mean reward 0.202, speed 50.65 f/s\n","185327: done 2334 episodes, mean reward 0.204, speed 52.37 f/s\n","185415: done 2335 episodes, mean reward 0.203, speed 53.01 f/s\n","185466: done 2336 episodes, mean reward 0.204, speed 50.27 f/s\n","185560: done 2338 episodes, mean reward 0.206, speed 50.97 f/s\n","185742: done 2340 episodes, mean reward 0.208, speed 53.80 f/s\n","185860: done 2341 episodes, mean reward 0.209, speed 54.62 f/s\n","186203: done 2342 episodes, mean reward 0.210, speed 56.97 f/s\n","186271: done 2343 episodes, mean reward 0.212, speed 52.51 f/s\n","186337: done 2344 episodes, mean reward 0.211, speed 52.99 f/s\n","186393: done 2345 episodes, mean reward 0.212, speed 51.65 f/s\n","186490: done 2347 episodes, mean reward 0.211, speed 50.75 f/s\n","186544: done 2348 episodes, mean reward 0.213, speed 50.93 f/s\n","186595: done 2349 episodes, mean reward 0.214, speed 50.85 f/s\n","186722: done 2350 episodes, mean reward 0.215, speed 55.14 f/s\n","186794: done 2351 episodes, mean reward 0.217, speed 52.49 f/s\n","187086: done 2352 episodes, mean reward 0.217, speed 56.05 f/s\n","187147: done 2353 episodes, mean reward 0.218, speed 51.14 f/s\n","187241: done 2355 episodes, mean reward 0.220, speed 49.46 f/s\n","187447: done 2356 episodes, mean reward 0.220, speed 54.20 f/s\n","187499: done 2357 episodes, mean reward 0.221, speed 49.81 f/s\n","187739: done 2358 episodes, mean reward 0.220, speed 54.81 f/s\n","187835: done 2359 episodes, mean reward 0.221, speed 53.12 f/s\n","187990: done 2360 episodes, mean reward 0.221, speed 54.30 f/s\n","188154: done 2361 episodes, mean reward 0.221, speed 53.16 f/s\n","188248: done 2363 episodes, mean reward 0.222, speed 49.30 f/s\n","188593: done 2365 episodes, mean reward 0.221, speed 53.87 f/s\n","189244: done 2367 episodes, mean reward 0.217, speed 54.12 f/s\n","189548: done 2368 episodes, mean reward 0.217, speed 55.15 f/s\n","189619: done 2369 episodes, mean reward 0.217, speed 52.06 f/s\n","189791: done 2370 episodes, mean reward 0.217, speed 54.12 f/s\n","EEEE tensor(-8.2754, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0499, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(9.6789e-05, grad_fn=<ExpBackward>)\n","Test done in 10.52 sec, reward 0.202, steps 153\n","190047: done 2371 episodes, mean reward 0.218, speed 16.88 f/s\n","190301: done 2373 episodes, mean reward 0.220, speed 53.24 f/s\n","190383: done 2374 episodes, mean reward 0.221, speed 51.92 f/s\n","190490: done 2375 episodes, mean reward 0.222, speed 49.97 f/s\n","190560: done 2376 episodes, mean reward 0.223, speed 50.84 f/s\n","190633: done 2377 episodes, mean reward 0.224, speed 51.62 f/s\n","190700: done 2378 episodes, mean reward 0.226, speed 51.91 f/s\n","190775: done 2379 episodes, mean reward 0.226, speed 51.74 f/s\n","190846: done 2380 episodes, mean reward 0.227, speed 51.78 f/s\n","190907: done 2381 episodes, mean reward 0.226, speed 51.57 f/s\n","190967: done 2382 episodes, mean reward 0.225, speed 50.70 f/s\n","191034: done 2383 episodes, mean reward 0.226, speed 51.35 f/s\n","191099: done 2384 episodes, mean reward 0.226, speed 51.28 f/s\n","191152: done 2385 episodes, mean reward 0.227, speed 50.36 f/s\n","191218: done 2386 episodes, mean reward 0.227, speed 51.53 f/s\n","191353: done 2387 episodes, mean reward 0.227, speed 53.71 f/s\n","191419: done 2388 episodes, mean reward 0.228, speed 51.22 f/s\n","191537: done 2389 episodes, mean reward 0.228, speed 54.50 f/s\n","191661: done 2390 episodes, mean reward 0.229, speed 55.08 f/s\n","191777: done 2391 episodes, mean reward 0.228, speed 54.64 f/s\n","191848: done 2392 episodes, mean reward 0.228, speed 51.43 f/s\n","191958: done 2393 episodes, mean reward 0.227, speed 52.53 f/s\n","192046: done 2394 episodes, mean reward 0.226, speed 51.78 f/s\n","192129: done 2395 episodes, mean reward 0.226, speed 52.71 f/s\n","192221: done 2396 episodes, mean reward 0.226, speed 52.69 f/s\n","192517: done 2397 episodes, mean reward 0.225, speed 56.11 f/s\n","192578: done 2398 episodes, mean reward 0.226, speed 50.88 f/s\n","192736: done 2399 episodes, mean reward 0.225, speed 55.34 f/s\n","192796: done 2400 episodes, mean reward 0.226, speed 51.30 f/s\n","192891: done 2401 episodes, mean reward 0.224, speed 53.67 f/s\n","192959: done 2402 episodes, mean reward 0.223, speed 52.08 f/s\n","193046: done 2403 episodes, mean reward 0.222, speed 52.98 f/s\n","193211: done 2404 episodes, mean reward 0.220, speed 54.78 f/s\n","193290: done 2405 episodes, mean reward 0.219, speed 53.06 f/s\n","193395: done 2406 episodes, mean reward 0.217, speed 53.95 f/s\n","193486: done 2407 episodes, mean reward 0.216, speed 53.87 f/s\n","193620: done 2408 episodes, mean reward 0.214, speed 54.50 f/s\n","193673: done 2409 episodes, mean reward 0.215, speed 50.64 f/s\n","193735: done 2410 episodes, mean reward 0.215, speed 49.13 f/s\n","193800: done 2411 episodes, mean reward 0.215, speed 51.21 f/s\n","193863: done 2412 episodes, mean reward 0.215, speed 50.72 f/s\n","193921: done 2413 episodes, mean reward 0.215, speed 50.19 f/s\n","194024: done 2414 episodes, mean reward 0.214, speed 52.68 f/s\n","194090: done 2415 episodes, mean reward 0.212, speed 51.88 f/s\n","194153: done 2416 episodes, mean reward 0.210, speed 50.91 f/s\n","194295: done 2417 episodes, mean reward 0.210, speed 54.18 f/s\n","194468: done 2418 episodes, mean reward 0.210, speed 54.76 f/s\n","194594: done 2419 episodes, mean reward 0.208, speed 53.63 f/s\n","194770: done 2420 episodes, mean reward 0.206, speed 54.86 f/s\n","194838: done 2421 episodes, mean reward 0.204, speed 51.11 f/s\n","195095: done 2422 episodes, mean reward 0.203, speed 56.85 f/s\n","195262: done 2423 episodes, mean reward 0.201, speed 55.56 f/s\n","195345: done 2424 episodes, mean reward 0.201, speed 53.65 f/s\n","195397: done 2425 episodes, mean reward 0.202, speed 48.81 f/s\n","195460: done 2426 episodes, mean reward 0.201, speed 51.46 f/s\n","195825: done 2427 episodes, mean reward 0.198, speed 56.84 f/s\n","195982: done 2429 episodes, mean reward 0.195, speed 53.33 f/s\n","196129: done 2431 episodes, mean reward 0.193, speed 52.34 f/s\n","196194: done 2433 episodes, mean reward 0.190, speed 46.69 f/s\n","196309: done 2434 episodes, mean reward 0.190, speed 54.33 f/s\n","196538: done 2435 episodes, mean reward 0.190, speed 56.93 f/s\n","196700: done 2436 episodes, mean reward 0.189, speed 55.78 f/s\n","196766: done 2438 episodes, mean reward 0.186, speed 47.41 f/s\n","196877: done 2439 episodes, mean reward 0.186, speed 55.01 f/s\n","197085: done 2440 episodes, mean reward 0.185, speed 56.97 f/s\n","197169: done 2441 episodes, mean reward 0.184, speed 53.07 f/s\n","197337: done 2442 episodes, mean reward 0.184, speed 56.20 f/s\n","197406: done 2443 episodes, mean reward 0.181, speed 53.06 f/s\n","197484: done 2445 episodes, mean reward 0.181, speed 49.37 f/s\n","197600: done 2447 episodes, mean reward 0.179, speed 51.26 f/s\n","197663: done 2449 episodes, mean reward 0.176, speed 46.54 f/s\n","197741: done 2451 episodes, mean reward 0.176, speed 48.67 f/s\n","197834: done 2452 episodes, mean reward 0.176, speed 54.03 f/s\n","197963: done 2453 episodes, mean reward 0.176, speed 54.67 f/s\n","198091: done 2454 episodes, mean reward 0.175, speed 53.75 f/s\n","198209: done 2455 episodes, mean reward 0.174, speed 54.53 f/s\n","198337: done 2456 episodes, mean reward 0.173, speed 54.03 f/s\n","198498: done 2457 episodes, mean reward 0.173, speed 54.96 f/s\n","198623: done 2459 episodes, mean reward 0.175, speed 51.39 f/s\n","198765: done 2460 episodes, mean reward 0.175, speed 52.43 f/s\n","198924: done 2461 episodes, mean reward 0.175, speed 52.17 f/s\n","198994: done 2462 episodes, mean reward 0.174, speed 49.86 f/s\n","199065: done 2464 episodes, mean reward 0.175, speed 43.60 f/s\n","199130: done 2466 episodes, mean reward 0.175, speed 46.28 f/s\n","199198: done 2468 episodes, mean reward 0.179, speed 46.79 f/s\n","199312: done 2469 episodes, mean reward 0.181, speed 52.40 f/s\n","199392: done 2471 episodes, mean reward 0.181, speed 48.92 f/s\n","199524: done 2472 episodes, mean reward 0.181, speed 54.71 f/s\n","199779: done 2474 episodes, mean reward 0.179, speed 53.02 f/s\n","199938: done 2476 episodes, mean reward 0.178, speed 52.00 f/s\n","EEEE tensor(-8.7092, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0573, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(9.0247e-05, grad_fn=<ExpBackward>)\n","Test done in 5.92 sec, reward 0.275, steps 76\n","200007: done 2478 episodes, mean reward 0.176, speed 9.33 f/s\n","200301: done 2479 episodes, mean reward 0.176, speed 54.98 f/s\n","200370: done 2481 episodes, mean reward 0.174, speed 46.78 f/s\n","200434: done 2482 episodes, mean reward 0.175, speed 50.83 f/s\n","200488: done 2483 episodes, mean reward 0.174, speed 48.83 f/s\n","200570: done 2485 episodes, mean reward 0.173, speed 48.65 f/s\n","200782: done 2486 episodes, mean reward 0.172, speed 54.92 f/s\n","200867: done 2488 episodes, mean reward 0.172, speed 48.78 f/s\n","200918: done 2489 episodes, mean reward 0.174, speed 50.16 f/s\n","200983: done 2491 episodes, mean reward 0.175, speed 47.20 f/s\n","201047: done 2493 episodes, mean reward 0.176, speed 46.74 f/s\n","201157: done 2495 episodes, mean reward 0.179, speed 50.41 f/s\n","201370: done 2496 episodes, mean reward 0.181, speed 54.62 f/s\n","201454: done 2498 episodes, mean reward 0.183, speed 49.27 f/s\n","201542: done 2499 episodes, mean reward 0.186, speed 52.37 f/s\n","201665: done 2500 episodes, mean reward 0.187, speed 54.07 f/s\n","201785: done 2502 episodes, mean reward 0.189, speed 51.45 f/s\n","201856: done 2504 episodes, mean reward 0.193, speed 48.55 f/s\n","202856: done 2505 episodes, mean reward 0.198, speed 56.81 f/s\n","203082: done 2506 episodes, mean reward 0.201, speed 55.37 f/s\n","204082: done 2507 episodes, mean reward 0.211, speed 56.74 f/s\n","204179: done 2509 episodes, mean reward 0.215, speed 49.99 f/s\n","204292: done 2511 episodes, mean reward 0.217, speed 51.53 f/s\n","204641: done 2513 episodes, mean reward 0.219, speed 55.74 f/s\n","204756: done 2514 episodes, mean reward 0.221, speed 55.27 f/s\n","205756: done 2515 episodes, mean reward 0.232, speed 56.01 f/s\n","206193: done 2516 episodes, mean reward 0.235, speed 55.83 f/s\n","206327: done 2518 episodes, mean reward 0.236, speed 51.72 f/s\n","206378: done 2519 episodes, mean reward 0.240, speed 49.66 f/s\n","207426: done 2521 episodes, mean reward 0.250, speed 55.58 f/s\n","208384: done 2522 episodes, mean reward 0.258, speed 56.16 f/s\n","208481: done 2524 episodes, mean reward 0.262, speed 49.63 f/s\n","208966: done 2525 episodes, mean reward 0.266, speed 55.51 f/s\n","209052: done 2526 episodes, mean reward 0.266, speed 53.75 f/s\n","209140: done 2528 episodes, mean reward 0.271, speed 50.01 f/s\n","EEEE tensor(-10.1889, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0836, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(9.9821e-05, grad_fn=<ExpBackward>)\n","Test done in 18.18 sec, reward 0.508, steps 268\n","Best reward updated: 0.305 -> 0.508\n","210140: done 2529 episodes, mean reward 0.282, speed 27.91 f/s\n","210271: done 2530 episodes, mean reward 0.285, speed 55.51 f/s\n","210733: done 2532 episodes, mean reward 0.292, speed 56.50 f/s\n","210937: done 2534 episodes, mean reward 0.297, speed 53.76 f/s\n","211046: done 2536 episodes, mean reward 0.299, speed 50.70 f/s\n","211137: done 2538 episodes, mean reward 0.301, speed 49.14 f/s\n","211194: done 2539 episodes, mean reward 0.302, speed 50.94 f/s\n","211406: done 2541 episodes, mean reward 0.306, speed 54.49 f/s\n","211528: done 2543 episodes, mean reward 0.309, speed 50.99 f/s\n","211739: done 2544 episodes, mean reward 0.314, speed 55.54 f/s\n","211849: done 2545 episodes, mean reward 0.318, speed 54.78 f/s\n","212061: done 2546 episodes, mean reward 0.321, speed 55.84 f/s\n","212147: done 2548 episodes, mean reward 0.322, speed 49.89 f/s\n","212242: done 2550 episodes, mean reward 0.323, speed 50.95 f/s\n","212330: done 2552 episodes, mean reward 0.323, speed 49.97 f/s\n","212427: done 2554 episodes, mean reward 0.324, speed 51.62 f/s\n","212478: done 2555 episodes, mean reward 0.326, speed 50.42 f/s\n","212579: done 2557 episodes, mean reward 0.326, speed 51.14 f/s\n","212673: done 2559 episodes, mean reward 0.324, speed 50.47 f/s\n","212766: done 2561 episodes, mean reward 0.325, speed 50.58 f/s\n","212852: done 2563 episodes, mean reward 0.325, speed 49.15 f/s\n","212933: done 2565 episodes, mean reward 0.326, speed 49.80 f/s\n","213026: done 2567 episodes, mean reward 0.328, speed 50.63 f/s\n","213118: done 2569 episodes, mean reward 0.329, speed 50.36 f/s\n","213211: done 2571 episodes, mean reward 0.330, speed 50.59 f/s\n","213306: done 2573 episodes, mean reward 0.331, speed 50.90 f/s\n","213407: done 2575 episodes, mean reward 0.334, speed 50.91 f/s\n","213494: done 2577 episodes, mean reward 0.334, speed 50.63 f/s\n","213555: done 2578 episodes, mean reward 0.335, speed 51.69 f/s\n","213639: done 2580 episodes, mean reward 0.335, speed 49.79 f/s\n","213731: done 2582 episodes, mean reward 0.335, speed 50.63 f/s\n","213824: done 2584 episodes, mean reward 0.338, speed 50.84 f/s\n","213910: done 2586 episodes, mean reward 0.339, speed 49.80 f/s\n","213997: done 2588 episodes, mean reward 0.339, speed 49.89 f/s\n","214091: done 2590 episodes, mean reward 0.339, speed 50.16 f/s\n","214179: done 2592 episodes, mean reward 0.340, speed 49.48 f/s\n","214264: done 2594 episodes, mean reward 0.340, speed 49.27 f/s\n","214362: done 2596 episodes, mean reward 0.340, speed 49.89 f/s\n","214455: done 2598 episodes, mean reward 0.340, speed 49.62 f/s\n","214546: done 2600 episodes, mean reward 0.338, speed 49.96 f/s\n","214641: done 2602 episodes, mean reward 0.340, speed 49.96 f/s\n","214725: done 2604 episodes, mean reward 0.340, speed 49.60 f/s\n","214818: done 2606 episodes, mean reward 0.336, speed 50.63 f/s\n","214909: done 2608 episodes, mean reward 0.325, speed 49.94 f/s\n","215003: done 2610 episodes, mean reward 0.324, speed 50.20 f/s\n","215087: done 2612 episodes, mean reward 0.322, speed 49.88 f/s\n","215170: done 2614 episodes, mean reward 0.322, speed 49.70 f/s\n","215260: done 2616 episodes, mean reward 0.311, speed 50.63 f/s\n","215348: done 2618 episodes, mean reward 0.312, speed 50.79 f/s\n","215432: done 2619 episodes, mean reward 0.311, speed 53.96 f/s\n","215518: done 2621 episodes, mean reward 0.304, speed 50.39 f/s\n","215612: done 2623 episodes, mean reward 0.296, speed 50.61 f/s\n","215696: done 2625 episodes, mean reward 0.291, speed 49.65 f/s\n","215772: done 2627 episodes, mean reward 0.289, speed 48.63 f/s\n","215866: done 2629 episodes, mean reward 0.281, speed 49.58 f/s\n","215964: done 2631 episodes, mean reward 0.279, speed 50.28 f/s\n","216050: done 2633 episodes, mean reward 0.272, speed 49.57 f/s\n","216143: done 2635 episodes, mean reward 0.269, speed 50.30 f/s\n","216236: done 2637 episodes, mean reward 0.270, speed 51.15 f/s\n","216332: done 2639 episodes, mean reward 0.269, speed 51.41 f/s\n","216404: done 2641 episodes, mean reward 0.265, speed 48.60 f/s\n","216484: done 2643 episodes, mean reward 0.263, speed 49.68 f/s\n","216570: done 2645 episodes, mean reward 0.254, speed 50.51 f/s\n","216656: done 2647 episodes, mean reward 0.253, speed 49.42 f/s\n","216743: done 2649 episodes, mean reward 0.253, speed 50.08 f/s\n","216837: done 2651 episodes, mean reward 0.252, speed 50.95 f/s\n","217695: done 2653 episodes, mean reward 0.262, speed 57.98 f/s\n","217775: done 2655 episodes, mean reward 0.261, speed 48.91 f/s\n","217869: done 2657 episodes, mean reward 0.261, speed 51.25 f/s\n","217945: done 2659 episodes, mean reward 0.260, speed 49.56 f/s\n","218028: done 2661 episodes, mean reward 0.260, speed 49.77 f/s\n","218111: done 2662 episodes, mean reward 0.259, speed 53.58 f/s\n","218207: done 2664 episodes, mean reward 0.259, speed 51.03 f/s\n","218643: done 2666 episodes, mean reward 0.263, speed 57.26 f/s\n","218731: done 2668 episodes, mean reward 0.263, speed 50.87 f/s\n","218814: done 2670 episodes, mean reward 0.263, speed 50.51 f/s\n","218903: done 2672 episodes, mean reward 0.262, speed 50.40 f/s\n","218984: done 2674 episodes, mean reward 0.260, speed 50.80 f/s\n","219064: done 2676 episodes, mean reward 0.259, speed 49.94 f/s\n","219151: done 2678 episodes, mean reward 0.259, speed 50.58 f/s\n","219236: done 2680 episodes, mean reward 0.259, speed 50.35 f/s\n","219333: done 2682 episodes, mean reward 0.260, speed 49.58 f/s\n","219421: done 2684 episodes, mean reward 0.259, speed 51.15 f/s\n","219505: done 2686 episodes, mean reward 0.258, speed 50.55 f/s\n","219558: done 2687 episodes, mean reward 0.259, speed 50.95 f/s\n","219649: done 2689 episodes, mean reward 0.258, speed 49.76 f/s\n","219697: done 2690 episodes, mean reward 0.258, speed 47.32 f/s\n","219783: done 2692 episodes, mean reward 0.257, speed 49.14 f/s\n","219877: done 2694 episodes, mean reward 0.257, speed 50.31 f/s\n","EEEE tensor(-8.6392, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0884, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0001, grad_fn=<ExpBackward>)\n","Test done in 4.63 sec, reward 0.231, steps 57\n","220081: done 2696 episodes, mean reward 0.259, speed 24.23 f/s\n","220445: done 2698 episodes, mean reward 0.258, speed 56.25 f/s\n","220531: done 2700 episodes, mean reward 0.258, speed 49.49 f/s\n","220614: done 2702 episodes, mean reward 0.256, speed 49.59 f/s\n","220737: done 2704 episodes, mean reward 0.257, speed 51.57 f/s\n","220825: done 2706 episodes, mean reward 0.256, speed 50.30 f/s\n","220903: done 2708 episodes, mean reward 0.255, speed 49.25 f/s\n","220986: done 2710 episodes, mean reward 0.254, speed 50.19 f/s\n","221074: done 2711 episodes, mean reward 0.256, speed 53.79 f/s\n","221148: done 2713 episodes, mean reward 0.256, speed 48.78 f/s\n","221236: done 2715 episodes, mean reward 0.255, speed 50.22 f/s\n","221332: done 2717 episodes, mean reward 0.256, speed 51.01 f/s\n","221414: done 2718 episodes, mean reward 0.256, speed 53.68 f/s\n","221567: done 2719 episodes, mean reward 0.258, speed 56.12 f/s\n","221639: done 2721 episodes, mean reward 0.257, speed 49.14 f/s\n","221723: done 2723 episodes, mean reward 0.255, speed 49.81 f/s\n","221815: done 2725 episodes, mean reward 0.255, speed 50.67 f/s\n","221904: done 2727 episodes, mean reward 0.256, speed 50.48 f/s\n","221982: done 2729 episodes, mean reward 0.254, speed 49.36 f/s\n","222066: done 2730 episodes, mean reward 0.255, speed 54.39 f/s\n","222160: done 2732 episodes, mean reward 0.255, speed 50.73 f/s\n","222251: done 2733 episodes, mean reward 0.256, speed 54.20 f/s\n","222324: done 2735 episodes, mean reward 0.255, speed 48.17 f/s\n","222407: done 2737 episodes, mean reward 0.253, speed 50.09 f/s\n","223279: done 2738 episodes, mean reward 0.259, speed 58.86 f/s\n","223391: done 2739 episodes, mean reward 0.258, speed 54.35 f/s\n","223490: done 2740 episodes, mean reward 0.259, speed 54.43 f/s\n","223571: done 2741 episodes, mean reward 0.259, speed 54.12 f/s\n","223730: done 2743 episodes, mean reward 0.260, speed 53.84 f/s\n","223815: done 2744 episodes, mean reward 0.262, speed 53.76 f/s\n","223897: done 2745 episodes, mean reward 0.260, speed 54.01 f/s\n","224058: done 2746 episodes, mean reward 0.263, speed 55.66 f/s\n","224207: done 2747 episodes, mean reward 0.264, speed 54.57 f/s\n","224314: done 2748 episodes, mean reward 0.264, speed 54.72 f/s\n","224424: done 2749 episodes, mean reward 0.264, speed 54.49 f/s\n","224598: done 2750 episodes, mean reward 0.266, speed 56.16 f/s\n","224783: done 2751 episodes, mean reward 0.266, speed 55.50 f/s\n","225235: done 2752 episodes, mean reward 0.267, speed 57.31 f/s\n","225305: done 2753 episodes, mean reward 0.258, speed 52.58 f/s\n","225388: done 2755 episodes, mean reward 0.256, speed 49.81 f/s\n","225462: done 2756 episodes, mean reward 0.255, speed 52.97 f/s\n","225658: done 2757 episodes, mean reward 0.256, speed 56.08 f/s\n","225857: done 2758 episodes, mean reward 0.257, speed 56.39 f/s\n","225925: done 2759 episodes, mean reward 0.258, speed 51.43 f/s\n","226127: done 2760 episodes, mean reward 0.257, speed 56.55 f/s\n","226297: done 2761 episodes, mean reward 0.257, speed 55.92 f/s\n","226568: done 2763 episodes, mean reward 0.255, speed 55.08 f/s\n","227357: done 2764 episodes, mean reward 0.254, speed 58.39 f/s\n","227449: done 2766 episodes, mean reward 0.250, speed 51.17 f/s\n","227547: done 2767 episodes, mean reward 0.250, speed 55.22 f/s\n","227644: done 2768 episodes, mean reward 0.248, speed 54.44 f/s\n","227895: done 2769 episodes, mean reward 0.249, speed 56.18 f/s\n","227955: done 2770 episodes, mean reward 0.250, speed 52.58 f/s\n","228020: done 2771 episodes, mean reward 0.249, speed 53.25 f/s\n","228086: done 2772 episodes, mean reward 0.249, speed 53.21 f/s\n","228212: done 2774 episodes, mean reward 0.250, speed 52.81 f/s\n","228313: done 2775 episodes, mean reward 0.252, speed 55.26 f/s\n","228447: done 2776 episodes, mean reward 0.252, speed 54.42 f/s\n","228555: done 2777 episodes, mean reward 0.254, speed 53.89 f/s\n","229029: done 2778 episodes, mean reward 0.252, speed 57.00 f/s\n","229346: done 2779 episodes, mean reward 0.253, speed 57.27 f/s\n","229675: done 2780 episodes, mean reward 0.254, speed 56.65 f/s\n","229863: done 2781 episodes, mean reward 0.255, speed 56.38 f/s\n","EEEE tensor(-7.8645, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0736, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0001, grad_fn=<ExpBackward>)\n","Test done in 13.97 sec, reward 0.378, steps 216\n","230067: done 2782 episodes, mean reward 0.259, speed 11.61 f/s\n","230239: done 2783 episodes, mean reward 0.261, speed 54.90 f/s\n","230370: done 2784 episodes, mean reward 0.261, speed 55.24 f/s\n","230456: done 2785 episodes, mean reward 0.260, speed 54.01 f/s\n","230544: done 2786 episodes, mean reward 0.260, speed 54.33 f/s\n","230609: done 2787 episodes, mean reward 0.261, speed 52.24 f/s\n","230724: done 2788 episodes, mean reward 0.262, speed 55.22 f/s\n","230883: done 2790 episodes, mean reward 0.263, speed 54.01 f/s\n","231091: done 2791 episodes, mean reward 0.266, speed 57.20 f/s\n","231193: done 2793 episodes, mean reward 0.267, speed 51.64 f/s\n","231322: done 2794 episodes, mean reward 0.268, speed 56.23 f/s\n","231421: done 2796 episodes, mean reward 0.267, speed 51.83 f/s\n","231659: done 2798 episodes, mean reward 0.267, speed 54.98 f/s\n","231730: done 2799 episodes, mean reward 0.269, speed 53.23 f/s\n","231988: done 2800 episodes, mean reward 0.271, speed 57.43 f/s\n","232307: done 2801 episodes, mean reward 0.272, speed 56.62 f/s\n","232394: done 2802 episodes, mean reward 0.272, speed 53.69 f/s\n","232455: done 2803 episodes, mean reward 0.273, speed 52.02 f/s\n","232607: done 2804 episodes, mean reward 0.276, speed 55.03 f/s\n","232660: done 2805 episodes, mean reward 0.278, speed 50.37 f/s\n","232894: done 2806 episodes, mean reward 0.281, speed 56.68 f/s\n","233082: done 2807 episodes, mean reward 0.283, speed 55.79 f/s\n","233210: done 2808 episodes, mean reward 0.285, speed 55.25 f/s\n","233324: done 2810 episodes, mean reward 0.287, speed 51.83 f/s\n","233426: done 2812 episodes, mean reward 0.286, speed 50.86 f/s\n","233553: done 2813 episodes, mean reward 0.287, speed 55.18 f/s\n","233614: done 2814 episodes, mean reward 0.289, speed 52.41 f/s\n","233778: done 2815 episodes, mean reward 0.291, speed 56.37 f/s\n","234250: done 2816 episodes, mean reward 0.294, speed 57.33 f/s\n","234386: done 2818 episodes, mean reward 0.294, speed 53.06 f/s\n","234448: done 2819 episodes, mean reward 0.293, speed 51.17 f/s\n","234517: done 2820 episodes, mean reward 0.295, speed 52.25 f/s\n","234582: done 2821 episodes, mean reward 0.297, speed 52.43 f/s\n","235537: done 2823 episodes, mean reward 0.299, speed 57.90 f/s\n","235629: done 2825 episodes, mean reward 0.300, speed 50.31 f/s\n","235737: done 2826 episodes, mean reward 0.301, speed 55.80 f/s\n","236155: done 2828 episodes, mean reward 0.307, speed 56.66 f/s\n","236262: done 2830 episodes, mean reward 0.307, speed 51.71 f/s\n","236320: done 2831 episodes, mean reward 0.307, speed 52.14 f/s\n","236533: done 2833 episodes, mean reward 0.308, speed 54.61 f/s\n","236629: done 2835 episodes, mean reward 0.310, speed 51.09 f/s\n","236726: done 2837 episodes, mean reward 0.312, speed 50.40 f/s\n","237198: done 2838 episodes, mean reward 0.312, speed 57.09 f/s\n","238246: done 2840 episodes, mean reward 0.327, speed 58.11 f/s\n","238302: done 2841 episodes, mean reward 0.327, speed 51.81 f/s\n","239069: done 2842 episodes, mean reward 0.333, speed 57.00 f/s\n","239294: done 2843 episodes, mean reward 0.334, speed 56.85 f/s\n","239532: done 2845 episodes, mean reward 0.335, speed 54.71 f/s\n","EEEE tensor(-9.3598, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0770, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0001, grad_fn=<ExpBackward>)\n","Test done in 14.20 sec, reward 0.364, steps 213\n","240018: done 2846 episodes, mean reward 0.335, speed 21.37 f/s\n","240193: done 2848 episodes, mean reward 0.336, speed 55.02 f/s\n","241244: done 2850 episodes, mean reward 0.339, speed 56.60 f/s\n","241434: done 2851 episodes, mean reward 0.340, speed 55.55 f/s\n","241511: done 2852 episodes, mean reward 0.341, speed 54.52 f/s\n","241580: done 2853 episodes, mean reward 0.342, speed 52.42 f/s\n","241646: done 2854 episodes, mean reward 0.344, speed 52.58 f/s\n","241913: done 2856 episodes, mean reward 0.348, speed 55.62 f/s\n","242913: done 2857 episodes, mean reward 0.357, speed 57.43 f/s\n","243108: done 2858 episodes, mean reward 0.360, speed 56.23 f/s\n","243427: done 2859 episodes, mean reward 0.364, speed 57.22 f/s\n","243641: done 2860 episodes, mean reward 0.366, speed 56.19 f/s\n","243846: done 2861 episodes, mean reward 0.367, speed 56.61 f/s\n","243951: done 2862 episodes, mean reward 0.368, speed 55.12 f/s\n","244023: done 2863 episodes, mean reward 0.370, speed 54.40 f/s\n","244107: done 2864 episodes, mean reward 0.373, speed 54.06 f/s\n","244461: done 2865 episodes, mean reward 0.377, speed 57.05 f/s\n","244689: done 2866 episodes, mean reward 0.380, speed 57.00 f/s\n","245120: done 2867 episodes, mean reward 0.384, speed 57.53 f/s\n","245535: done 2869 episodes, mean reward 0.387, speed 55.59 f/s\n","245624: done 2870 episodes, mean reward 0.386, speed 53.82 f/s\n","245704: done 2871 episodes, mean reward 0.389, speed 53.86 f/s\n","245785: done 2872 episodes, mean reward 0.392, speed 54.23 f/s\n","245853: done 2873 episodes, mean reward 0.393, speed 53.22 f/s\n","246332: done 2874 episodes, mean reward 0.396, speed 57.15 f/s\n","247190: done 2875 episodes, mean reward 0.403, speed 57.28 f/s\n","247261: done 2876 episodes, mean reward 0.404, speed 52.83 f/s\n","247355: done 2877 episodes, mean reward 0.406, speed 54.81 f/s\n","247535: done 2879 episodes, mean reward 0.407, speed 53.85 f/s\n","247670: done 2880 episodes, mean reward 0.407, speed 54.64 f/s\n","247939: done 2881 episodes, mean reward 0.410, speed 57.47 f/s\n","248073: done 2882 episodes, mean reward 0.405, speed 56.42 f/s\n","248354: done 2883 episodes, mean reward 0.406, speed 56.10 f/s\n","249218: done 2885 episodes, mean reward 0.414, speed 57.64 f/s\n","249306: done 2887 episodes, mean reward 0.413, speed 51.43 f/s\n","249462: done 2888 episodes, mean reward 0.413, speed 56.41 f/s\n","249549: done 2889 episodes, mean reward 0.414, speed 54.10 f/s\n","249721: done 2891 episodes, mean reward 0.410, speed 53.84 f/s\n","249813: done 2893 episodes, mean reward 0.409, speed 50.39 f/s\n","249877: done 2894 episodes, mean reward 0.408, speed 51.69 f/s\n","EEEE tensor(-8.3777, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0748, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0001, grad_fn=<ExpBackward>)\n","Test done in 5.30 sec, reward 0.245, steps 69\n","250070: done 2895 episodes, mean reward 0.413, speed 22.04 f/s\n","250164: done 2897 episodes, mean reward 0.411, speed 50.98 f/s\n","250318: done 2898 episodes, mean reward 0.417, speed 56.50 f/s\n","250370: done 2899 episodes, mean reward 0.416, speed 50.14 f/s\n","250440: done 2900 episodes, mean reward 0.416, speed 53.54 f/s\n","250532: done 2902 episodes, mean reward 0.415, speed 50.79 f/s\n","250598: done 2903 episodes, mean reward 0.415, speed 52.06 f/s\n","251080: done 2904 episodes, mean reward 0.415, speed 56.77 f/s\n","251176: done 2906 episodes, mean reward 0.411, speed 51.44 f/s\n","251305: done 2908 episodes, mean reward 0.411, speed 53.19 f/s\n","252351: done 2910 episodes, mean reward 0.426, speed 57.43 f/s\n","252416: done 2911 episodes, mean reward 0.428, speed 52.50 f/s\n","252538: done 2913 episodes, mean reward 0.429, speed 52.58 f/s\n","252792: done 2914 episodes, mean reward 0.432, speed 56.94 f/s\n","253330: done 2915 episodes, mean reward 0.439, speed 57.52 f/s\n","253806: done 2916 episodes, mean reward 0.446, speed 57.78 f/s\n","254008: done 2917 episodes, mean reward 0.449, speed 55.43 f/s\n","254279: done 2918 episodes, mean reward 0.449, speed 56.54 f/s\n","254338: done 2919 episodes, mean reward 0.449, speed 51.81 f/s\n","254417: done 2920 episodes, mean reward 0.450, speed 53.81 f/s\n","254479: done 2921 episodes, mean reward 0.450, speed 52.33 f/s\n","254607: done 2923 episodes, mean reward 0.451, speed 52.71 f/s\n","254714: done 2924 episodes, mean reward 0.456, speed 55.10 f/s\n","254989: done 2925 episodes, mean reward 0.458, speed 56.87 f/s\n","255429: done 2927 episodes, mean reward 0.461, speed 56.61 f/s\n","255906: done 2928 episodes, mean reward 0.462, speed 57.71 f/s\n","255978: done 2929 episodes, mean reward 0.463, speed 53.84 f/s\n","256072: done 2931 episodes, mean reward 0.462, speed 51.30 f/s\n","256556: done 2932 episodes, mean reward 0.470, speed 57.46 f/s\n","256624: done 2933 episodes, mean reward 0.471, speed 53.30 f/s\n","257068: done 2935 episodes, mean reward 0.473, speed 56.81 f/s\n","257194: done 2936 episodes, mean reward 0.474, speed 55.22 f/s\n","258236: done 2938 episodes, mean reward 0.483, speed 57.17 f/s\n","258544: done 2939 episodes, mean reward 0.485, speed 56.37 f/s\n","258674: done 2940 episodes, mean reward 0.474, speed 53.99 f/s\n","258810: done 2942 episodes, mean reward 0.470, speed 52.65 f/s\n","258919: done 2944 episodes, mean reward 0.469, speed 51.02 f/s\n","259042: done 2945 episodes, mean reward 0.470, speed 55.28 f/s\n","259295: done 2946 episodes, mean reward 0.475, speed 57.13 f/s\n","259362: done 2947 episodes, mean reward 0.476, speed 52.63 f/s\n","259444: done 2948 episodes, mean reward 0.474, speed 53.90 f/s\n","259549: done 2949 episodes, mean reward 0.478, speed 55.35 f/s\n","259948: done 2951 episodes, mean reward 0.479, speed 57.21 f/s\n","EEEE tensor(-7.4199, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0554, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0001, grad_fn=<ExpBackward>)\n","Test done in 11.02 sec, reward 0.479, steps 166\n","260036: done 2953 episodes, mean reward 0.475, speed 6.89 f/s\n","260112: done 2954 episodes, mean reward 0.473, speed 53.80 f/s\n","260277: done 2955 episodes, mean reward 0.474, speed 55.73 f/s\n","260418: done 2956 episodes, mean reward 0.475, speed 55.38 f/s\n","260927: done 2957 episodes, mean reward 0.471, speed 57.48 f/s\n","261003: done 2958 episodes, mean reward 0.469, speed 53.13 f/s\n","261167: done 2960 episodes, mean reward 0.464, speed 53.96 f/s\n","261253: done 2961 episodes, mean reward 0.465, speed 53.95 f/s\n","261646: done 2962 episodes, mean reward 0.474, speed 57.34 f/s\n","261830: done 2963 episodes, mean reward 0.477, speed 56.82 f/s\n","261923: done 2965 episodes, mean reward 0.471, speed 50.40 f/s\n","262145: done 2966 episodes, mean reward 0.475, speed 56.61 f/s\n","262209: done 2967 episodes, mean reward 0.472, speed 52.61 f/s\n","262356: done 2968 episodes, mean reward 0.475, speed 54.14 f/s\n","262532: done 2969 episodes, mean reward 0.481, speed 56.58 f/s\n","262625: done 2971 episodes, mean reward 0.479, speed 49.92 f/s\n","262765: done 2973 episodes, mean reward 0.478, speed 51.95 f/s\n","262888: done 2974 episodes, mean reward 0.478, speed 54.77 f/s\n","263002: done 2976 episodes, mean reward 0.470, speed 51.41 f/s\n","263061: done 2977 episodes, mean reward 0.467, speed 50.92 f/s\n","263151: done 2979 episodes, mean reward 0.466, speed 48.19 f/s\n","263283: done 2980 episodes, mean reward 0.467, speed 55.10 f/s\n","263396: done 2981 episodes, mean reward 0.466, speed 54.74 f/s\n","263455: done 2982 episodes, mean reward 0.467, speed 51.33 f/s\n","263585: done 2983 episodes, mean reward 0.467, speed 55.65 f/s\n","263648: done 2984 episodes, mean reward 0.468, speed 53.31 f/s\n","263857: done 2986 episodes, mean reward 0.464, speed 54.76 f/s\n","263965: done 2987 episodes, mean reward 0.471, speed 55.42 f/s\n","264346: done 2989 episodes, mean reward 0.482, speed 57.22 f/s\n","264583: done 2991 episodes, mean reward 0.490, speed 55.27 f/s\n","264655: done 2992 episodes, mean reward 0.492, speed 53.66 f/s\n","264709: done 2993 episodes, mean reward 0.493, speed 51.46 f/s\n","264865: done 2995 episodes, mean reward 0.490, speed 53.64 f/s\n","265033: done 2997 episodes, mean reward 0.494, speed 53.83 f/s\n","265258: done 2998 episodes, mean reward 0.490, speed 55.86 f/s\n","265440: done 2999 episodes, mean reward 0.498, speed 56.75 f/s\n","265694: done 3001 episodes, mean reward 0.499, speed 55.26 f/s\n","265764: done 3002 episodes, mean reward 0.501, speed 53.13 f/s\n","265944: done 3004 episodes, mean reward 0.500, speed 53.67 f/s\n","266024: done 3005 episodes, mean reward 0.502, speed 53.15 f/s\n","266202: done 3006 episodes, mean reward 0.505, speed 55.34 f/s\n","266271: done 3007 episodes, mean reward 0.506, speed 53.19 f/s\n","266448: done 3008 episodes, mean reward 0.510, speed 56.85 f/s\n","266578: done 3009 episodes, mean reward 0.513, speed 55.54 f/s\n","266670: done 3010 episodes, mean reward 0.500, speed 53.69 f/s\n","266945: done 3011 episodes, mean reward 0.510, speed 57.26 f/s\n","267158: done 3012 episodes, mean reward 0.516, speed 55.90 f/s\n","267319: done 3013 episodes, mean reward 0.522, speed 55.91 f/s\n","267416: done 3014 episodes, mean reward 0.521, speed 54.94 f/s\n","267498: done 3015 episodes, mean reward 0.514, speed 54.15 f/s\n","267743: done 3016 episodes, mean reward 0.511, speed 57.33 f/s\n","267825: done 3017 episodes, mean reward 0.510, speed 54.06 f/s\n","267967: done 3018 episodes, mean reward 0.513, speed 55.75 f/s\n","268229: done 3019 episodes, mean reward 0.516, speed 57.26 f/s\n","268360: done 3020 episodes, mean reward 0.519, speed 56.06 f/s\n","268522: done 3022 episodes, mean reward 0.519, speed 53.45 f/s\n","268680: done 3024 episodes, mean reward 0.518, speed 53.73 f/s\n","268778: done 3026 episodes, mean reward 0.516, speed 50.90 f/s\n","269152: done 3027 episodes, mean reward 0.522, speed 57.35 f/s\n","269254: done 3028 episodes, mean reward 0.519, speed 54.41 f/s\n","269554: done 3029 episodes, mean reward 0.519, speed 56.56 f/s\n","269642: done 3030 episodes, mean reward 0.521, speed 54.00 f/s\n","269894: done 3031 episodes, mean reward 0.534, speed 56.79 f/s\n","EEEE tensor(-7.3815, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0559, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0001, grad_fn=<ExpBackward>)\n","Test done in 8.02 sec, reward 0.580, steps 117\n","Best reward updated: 0.508 -> 0.580\n","270035: done 3032 episodes, mean reward 0.529, speed 13.32 f/s\n","270174: done 3033 episodes, mean reward 0.533, speed 55.32 f/s\n","270432: done 3034 episodes, mean reward 0.544, speed 57.29 f/s\n","270674: done 3035 episodes, mean reward 0.553, speed 57.32 f/s\n","270754: done 3036 episodes, mean reward 0.551, speed 54.33 f/s\n","270932: done 3038 episodes, mean reward 0.538, speed 54.26 f/s\n","271024: done 3039 episodes, mean reward 0.536, speed 54.19 f/s\n","271280: done 3040 episodes, mean reward 0.540, speed 56.51 f/s\n","271370: done 3042 episodes, mean reward 0.538, speed 51.27 f/s\n","271442: done 3043 episodes, mean reward 0.539, speed 53.63 f/s\n","271965: done 3044 episodes, mean reward 0.563, speed 57.88 f/s\n","272055: done 3045 episodes, mean reward 0.564, speed 54.77 f/s\n","272220: done 3046 episodes, mean reward 0.567, speed 56.34 f/s\n","272368: done 3047 episodes, mean reward 0.572, speed 56.20 f/s\n","272454: done 3048 episodes, mean reward 0.574, speed 54.60 f/s\n","272630: done 3049 episodes, mean reward 0.578, speed 56.00 f/s\n","273446: done 3050 episodes, mean reward 0.611, speed 58.49 f/s\n","273586: done 3051 episodes, mean reward 0.606, speed 56.63 f/s\n","274186: done 3052 episodes, mean reward 0.641, speed 58.28 f/s\n","275186: done 3053 episodes, mean reward 0.670, speed 59.09 f/s\n","275480: done 3054 episodes, mean reward 0.681, speed 57.76 f/s\n","275632: done 3055 episodes, mean reward 0.689, speed 55.73 f/s\n","276214: done 3056 episodes, mean reward 0.702, speed 58.31 f/s\n","277214: done 3057 episodes, mean reward 0.724, speed 59.01 f/s\n","277374: done 3058 episodes, mean reward 0.727, speed 56.66 f/s\n","277464: done 3059 episodes, mean reward 0.728, speed 54.76 f/s\n","278464: done 3060 episodes, mean reward 0.742, speed 58.51 f/s\n","278770: done 3061 episodes, mean reward 0.746, speed 57.95 f/s\n","279770: done 3062 episodes, mean reward 0.757, speed 58.44 f/s\n","EEEE tensor(-7.1466, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0796, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0001, grad_fn=<ExpBackward>)\n","Test done in 30.52 sec, reward 1.967, steps 511\n","Best reward updated: 0.580 -> 1.967\n","280231: done 3063 episodes, mean reward 0.766, speed 11.98 f/s\n","280425: done 3065 episodes, mean reward 0.768, speed 54.70 f/s\n","280558: done 3066 episodes, mean reward 0.763, speed 56.31 f/s\n","280838: done 3068 episodes, mean reward 0.764, speed 56.14 f/s\n","280932: done 3070 episodes, mean reward 0.754, speed 50.93 f/s\n","281619: done 3071 episodes, mean reward 0.772, speed 58.28 f/s\n","282195: done 3072 episodes, mean reward 0.797, speed 58.49 f/s\n","282729: done 3073 episodes, mean reward 0.817, speed 58.61 f/s\n","282995: done 3074 episodes, mean reward 0.820, speed 57.38 f/s\n","283395: done 3075 episodes, mean reward 0.831, speed 56.59 f/s\n","283632: done 3076 episodes, mean reward 0.838, speed 57.04 f/s\n","283769: done 3078 episodes, mean reward 0.839, speed 53.25 f/s\n","283923: done 3079 episodes, mean reward 0.847, speed 55.97 f/s\n","284076: done 3080 episodes, mean reward 0.853, speed 56.36 f/s\n","284654: done 3082 episodes, mean reward 0.881, speed 57.71 f/s\n","285098: done 3083 episodes, mean reward 0.897, speed 58.24 f/s\n","285818: done 3084 episodes, mean reward 0.925, speed 58.29 f/s\n","285949: done 3085 episodes, mean reward 0.932, speed 56.12 f/s\n","286017: done 3086 episodes, mean reward 0.927, speed 53.51 f/s\n","287017: done 3087 episodes, mean reward 0.940, speed 58.85 f/s\n","287198: done 3088 episodes, mean reward 0.943, speed 55.59 f/s\n","287350: done 3089 episodes, mean reward 0.935, speed 55.94 f/s\n","287437: done 3090 episodes, mean reward 0.935, speed 54.86 f/s\n","287629: done 3091 episodes, mean reward 0.933, speed 56.70 f/s\n","287791: done 3092 episodes, mean reward 0.933, speed 55.73 f/s\n","288115: done 3093 episodes, mean reward 0.957, speed 57.07 f/s\n","288302: done 3094 episodes, mean reward 0.960, speed 55.32 f/s\n","288638: done 3095 episodes, mean reward 0.978, speed 58.41 f/s\n","288713: done 3096 episodes, mean reward 0.980, speed 54.09 f/s\n","288809: done 3097 episodes, mean reward 0.978, speed 54.88 f/s\n","289056: done 3098 episodes, mean reward 0.986, speed 57.66 f/s\n","289155: done 3099 episodes, mean reward 0.981, speed 54.92 f/s\n","289224: done 3100 episodes, mean reward 0.983, speed 52.33 f/s\n","289275: done 3101 episodes, mean reward 0.980, speed 50.51 f/s\n","289376: done 3102 episodes, mean reward 0.983, speed 54.11 f/s\n","289481: done 3103 episodes, mean reward 0.985, speed 55.23 f/s\n","289568: done 3104 episodes, mean reward 0.984, speed 54.28 f/s\n","289719: done 3105 episodes, mean reward 0.987, speed 55.26 f/s\n","289827: done 3106 episodes, mean reward 0.986, speed 53.88 f/s\n","EEEE tensor(-7.4072, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0751, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0002, grad_fn=<ExpBackward>)\n","Test done in 14.20 sec, reward 0.966, steps 226\n","290101: done 3107 episodes, mean reward 0.995, speed 14.44 f/s\n","290372: done 3108 episodes, mean reward 1.005, speed 57.60 f/s\n","290473: done 3109 episodes, mean reward 1.004, speed 54.94 f/s\n","290610: done 3110 episodes, mean reward 1.007, speed 56.39 f/s\n","290694: done 3111 episodes, mean reward 0.997, speed 53.91 f/s\n","290782: done 3112 episodes, mean reward 0.994, speed 53.98 f/s\n","290932: done 3113 episodes, mean reward 0.991, speed 55.99 f/s\n","291039: done 3114 episodes, mean reward 0.990, speed 55.48 f/s\n","291098: done 3115 episodes, mean reward 0.989, speed 51.73 f/s\n","291313: done 3116 episodes, mean reward 0.985, speed 57.12 f/s\n","291636: done 3117 episodes, mean reward 0.992, speed 56.81 f/s\n","291729: done 3118 episodes, mean reward 0.990, speed 53.46 f/s\n","291814: done 3119 episodes, mean reward 0.989, speed 53.22 f/s\n","291891: done 3120 episodes, mean reward 0.986, speed 52.97 f/s\n","291956: done 3121 episodes, mean reward 0.988, speed 51.91 f/s\n","292029: done 3122 episodes, mean reward 0.986, speed 53.15 f/s\n","292271: done 3123 episodes, mean reward 0.993, speed 57.36 f/s\n","292359: done 3124 episodes, mean reward 0.989, speed 53.64 f/s\n","292586: done 3125 episodes, mean reward 1.003, speed 57.76 f/s\n","292667: done 3126 episodes, mean reward 1.005, speed 53.73 f/s\n","292819: done 3127 episodes, mean reward 1.000, speed 56.39 f/s\n","292876: done 3128 episodes, mean reward 0.999, speed 52.70 f/s\n","293000: done 3129 episodes, mean reward 1.004, speed 55.44 f/s\n","293135: done 3130 episodes, mean reward 1.006, speed 56.51 f/s\n","293223: done 3131 episodes, mean reward 0.995, speed 54.36 f/s\n","293440: done 3133 episodes, mean reward 0.990, speed 55.75 f/s\n","293505: done 3134 episodes, mean reward 0.982, speed 52.55 f/s\n","293558: done 3135 episodes, mean reward 0.970, speed 51.60 f/s\n","293637: done 3136 episodes, mean reward 0.972, speed 54.96 f/s\n","293698: done 3137 episodes, mean reward 0.973, speed 53.04 f/s\n","293833: done 3138 episodes, mean reward 0.974, speed 56.67 f/s\n","293895: done 3139 episodes, mean reward 0.975, speed 52.97 f/s\n","294003: done 3140 episodes, mean reward 0.972, speed 55.35 f/s\n","294083: done 3141 episodes, mean reward 0.974, speed 54.49 f/s\n","294191: done 3142 episodes, mean reward 0.976, speed 55.75 f/s\n","294267: done 3143 episodes, mean reward 0.978, speed 54.23 f/s\n","294346: done 3144 episodes, mean reward 0.955, speed 54.36 f/s\n","294407: done 3145 episodes, mean reward 0.952, speed 51.90 f/s\n","294560: done 3146 episodes, mean reward 0.944, speed 56.61 f/s\n","294674: done 3148 episodes, mean reward 0.936, speed 52.54 f/s\n","294763: done 3149 episodes, mean reward 0.931, speed 53.69 f/s\n","294929: done 3150 episodes, mean reward 0.900, speed 56.96 f/s\n","295145: done 3151 episodes, mean reward 0.905, speed 57.12 f/s\n","295223: done 3152 episodes, mean reward 0.872, speed 53.42 f/s\n","295559: done 3153 episodes, mean reward 0.846, speed 56.72 f/s\n","295610: done 3154 episodes, mean reward 0.836, speed 50.86 f/s\n","295667: done 3155 episodes, mean reward 0.827, speed 51.58 f/s\n","295839: done 3156 episodes, mean reward 0.819, speed 57.10 f/s\n","295921: done 3157 episodes, mean reward 0.794, speed 53.14 f/s\n","296035: done 3158 episodes, mean reward 0.793, speed 54.52 f/s\n","296160: done 3159 episodes, mean reward 0.793, speed 54.32 f/s\n","296227: done 3160 episodes, mean reward 0.778, speed 52.86 f/s\n","296303: done 3161 episodes, mean reward 0.775, speed 53.51 f/s\n","296497: done 3162 episodes, mean reward 0.762, speed 56.25 f/s\n","296571: done 3163 episodes, mean reward 0.752, speed 53.59 f/s\n","296635: done 3164 episodes, mean reward 0.753, speed 52.84 f/s\n","296714: done 3165 episodes, mean reward 0.754, speed 54.23 f/s\n","296842: done 3166 episodes, mean reward 0.760, speed 56.51 f/s\n","296932: done 3167 episodes, mean reward 0.764, speed 55.16 f/s\n","297090: done 3168 episodes, mean reward 0.760, speed 56.18 f/s\n","297241: done 3169 episodes, mean reward 0.766, speed 56.80 f/s\n","297344: done 3170 episodes, mean reward 0.768, speed 54.41 f/s\n","297438: done 3171 episodes, mean reward 0.754, speed 55.11 f/s\n","297500: done 3172 episodes, mean reward 0.730, speed 52.58 f/s\n","297705: done 3173 episodes, mean reward 0.717, speed 57.69 f/s\n","297808: done 3174 episodes, mean reward 0.714, speed 55.23 f/s\n","298002: done 3175 episodes, mean reward 0.705, speed 57.42 f/s\n","298123: done 3176 episodes, mean reward 0.701, speed 55.89 f/s\n","298258: done 3177 episodes, mean reward 0.704, speed 55.46 f/s\n","298341: done 3178 episodes, mean reward 0.704, speed 54.53 f/s\n","298511: done 3180 episodes, mean reward 0.693, speed 54.91 f/s\n","298563: done 3181 episodes, mean reward 0.694, speed 51.69 f/s\n","298756: done 3182 episodes, mean reward 0.666, speed 57.78 f/s\n","298831: done 3183 episodes, mean reward 0.650, speed 54.09 f/s\n","299044: done 3184 episodes, mean reward 0.626, speed 56.42 f/s\n","299587: done 3185 episodes, mean reward 0.641, speed 58.66 f/s\n","299753: done 3186 episodes, mean reward 0.643, speed 57.18 f/s\n","299846: done 3187 episodes, mean reward 0.627, speed 55.40 f/s\n","299987: done 3188 episodes, mean reward 0.629, speed 56.57 f/s\n","EEEE tensor(-7.8081, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.0875, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0002, grad_fn=<ExpBackward>)\n","Test done in 10.12 sec, reward 0.505, steps 150\n","300096: done 3189 episodes, mean reward 0.629, speed 9.00 f/s\n","300178: done 3190 episodes, mean reward 0.629, speed 54.06 f/s\n","300411: done 3192 episodes, mean reward 0.624, speed 55.14 f/s\n","300697: done 3193 episodes, mean reward 0.603, speed 58.31 f/s\n","300823: done 3194 episodes, mean reward 0.604, speed 56.55 f/s\n","300913: done 3195 episodes, mean reward 0.587, speed 55.43 f/s\n","301126: done 3196 episodes, mean reward 0.591, speed 57.32 f/s\n","301250: done 3197 episodes, mean reward 0.591, speed 56.60 f/s\n","301375: done 3198 episodes, mean reward 0.586, speed 56.02 f/s\n","301651: done 3199 episodes, mean reward 0.599, speed 56.93 f/s\n","301780: done 3200 episodes, mean reward 0.602, speed 56.86 f/s\n","302104: done 3201 episodes, mean reward 0.605, speed 57.51 f/s\n","302156: done 3202 episodes, mean reward 0.601, speed 51.84 f/s\n","302259: done 3203 episodes, mean reward 0.603, speed 55.83 f/s\n","302469: done 3204 episodes, mean reward 0.607, speed 57.50 f/s\n","302616: done 3205 episodes, mean reward 0.607, speed 56.81 f/s\n","302730: done 3206 episodes, mean reward 0.609, speed 55.77 f/s\n","302887: done 3207 episodes, mean reward 0.603, speed 57.41 f/s\n","303136: done 3208 episodes, mean reward 0.592, speed 58.00 f/s\n","303214: done 3209 episodes, mean reward 0.592, speed 54.50 f/s\n","303324: done 3210 episodes, mean reward 0.588, speed 55.95 f/s\n","303423: done 3211 episodes, mean reward 0.590, speed 55.80 f/s\n","303513: done 3212 episodes, mean reward 0.590, speed 54.31 f/s\n","303886: done 3213 episodes, mean reward 0.597, speed 58.12 f/s\n","304008: done 3214 episodes, mean reward 0.596, speed 55.96 f/s\n","304187: done 3215 episodes, mean reward 0.600, speed 57.42 f/s\n","304424: done 3216 episodes, mean reward 0.604, speed 57.79 f/s\n","304553: done 3217 episodes, mean reward 0.598, speed 55.70 f/s\n","304673: done 3218 episodes, mean reward 0.598, speed 55.60 f/s\n","305179: done 3220 episodes, mean reward 0.620, speed 57.38 f/s\n","305378: done 3221 episodes, mean reward 0.622, speed 57.00 f/s\n","305571: done 3222 episodes, mean reward 0.626, speed 57.80 f/s\n","305811: done 3223 episodes, mean reward 0.635, speed 58.15 f/s\n","305951: done 3224 episodes, mean reward 0.637, speed 56.22 f/s\n","306055: done 3225 episodes, mean reward 0.626, speed 55.78 f/s\n","306198: done 3226 episodes, mean reward 0.628, speed 56.61 f/s\n","306288: done 3227 episodes, mean reward 0.625, speed 54.95 f/s\n","306404: done 3228 episodes, mean reward 0.627, speed 56.15 f/s\n","306681: done 3229 episodes, mean reward 0.631, speed 57.33 f/s\n","306908: done 3230 episodes, mean reward 0.632, speed 57.12 f/s\n","307049: done 3231 episodes, mean reward 0.635, speed 56.08 f/s\n","307312: done 3232 episodes, mean reward 0.641, speed 57.74 f/s\n","307497: done 3233 episodes, mean reward 0.648, speed 57.36 f/s\n","307628: done 3235 episodes, mean reward 0.648, speed 53.76 f/s\n","307807: done 3236 episodes, mean reward 0.659, speed 57.50 f/s\n","307883: done 3237 episodes, mean reward 0.661, speed 54.03 f/s\n","307944: done 3238 episodes, mean reward 0.659, speed 52.92 f/s\n","308130: done 3239 episodes, mean reward 0.663, speed 57.53 f/s\n","308307: done 3240 episodes, mean reward 0.661, speed 56.12 f/s\n","308431: done 3242 episodes, mean reward 0.659, speed 53.08 f/s\n","308604: done 3243 episodes, mean reward 0.657, speed 57.13 f/s\n","308688: done 3244 episodes, mean reward 0.657, speed 53.50 f/s\n","309121: done 3245 episodes, mean reward 0.666, speed 58.26 f/s\n","309207: done 3246 episodes, mean reward 0.666, speed 54.79 f/s\n","309405: done 3247 episodes, mean reward 0.671, speed 56.93 f/s\n","309491: done 3248 episodes, mean reward 0.671, speed 53.83 f/s\n","309697: done 3249 episodes, mean reward 0.677, speed 57.49 f/s\n","309848: done 3250 episodes, mean reward 0.678, speed 56.90 f/s\n","309938: done 3251 episodes, mean reward 0.674, speed 55.32 f/s\n","EEEE tensor(-8.1705, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.1017, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0002, grad_fn=<ExpBackward>)\n","Test done in 16.07 sec, reward 1.322, steps 256\n","310091: done 3252 episodes, mean reward 0.682, speed 8.16 f/s\n","310366: done 3253 episodes, mean reward 0.688, speed 57.96 f/s\n","310456: done 3254 episodes, mean reward 0.691, speed 54.47 f/s\n","310582: done 3255 episodes, mean reward 0.695, speed 56.64 f/s\n","310852: done 3256 episodes, mean reward 0.698, speed 57.84 f/s\n","311164: done 3257 episodes, mean reward 0.716, speed 57.84 f/s\n","311318: done 3258 episodes, mean reward 0.717, speed 56.77 f/s\n","311535: done 3259 episodes, mean reward 0.732, speed 57.23 f/s\n","311606: done 3260 episodes, mean reward 0.731, speed 52.39 f/s\n","311817: done 3261 episodes, mean reward 0.737, speed 57.58 f/s\n","312025: done 3262 episodes, mean reward 0.738, speed 57.83 f/s\n","312559: done 3264 episodes, mean reward 0.769, speed 58.57 f/s\n","312695: done 3265 episodes, mean reward 0.769, speed 55.95 f/s\n","312880: done 3266 episodes, mean reward 0.772, speed 56.44 f/s\n","313011: done 3267 episodes, mean reward 0.777, speed 55.59 f/s\n","313101: done 3268 episodes, mean reward 0.778, speed 54.13 f/s\n","313227: done 3269 episodes, mean reward 0.779, speed 56.29 f/s\n","313910: done 3270 episodes, mean reward 0.782, speed 59.07 f/s\n","314248: done 3271 episodes, mean reward 0.812, speed 59.19 f/s\n","314630: done 3273 episodes, mean reward 0.826, speed 57.39 f/s\n","315168: done 3274 episodes, mean reward 0.862, speed 58.87 f/s\n","316096: done 3275 episodes, mean reward 0.947, speed 59.37 f/s\n","316159: done 3276 episodes, mean reward 0.942, speed 52.54 f/s\n","316242: done 3277 episodes, mean reward 0.941, speed 54.01 f/s\n","316588: done 3278 episodes, mean reward 0.987, speed 58.63 f/s\n","317629: done 3280 episodes, mean reward 1.046, speed 58.28 f/s\n","318046: done 3281 episodes, mean reward 1.053, speed 57.67 f/s\n","318225: done 3282 episodes, mean reward 1.061, speed 56.23 f/s\n","318531: done 3283 episodes, mean reward 1.075, speed 58.33 f/s\n","319206: done 3284 episodes, mean reward 1.149, speed 59.21 f/s\n","319298: done 3285 episodes, mean reward 1.130, speed 55.89 f/s\n","319604: done 3286 episodes, mean reward 1.141, speed 58.51 f/s\n","EEEE tensor(-8.7288, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.1179, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0002, grad_fn=<ExpBackward>)\n","Test done in 20.92 sec, reward 3.146, steps 345\n","Best reward updated: 1.967 -> 3.146\n","320015: done 3287 episodes, mean reward 1.151, speed 14.72 f/s\n","320398: done 3288 episodes, mean reward 1.185, speed 58.51 f/s\n","321419: done 3290 episodes, mean reward 1.182, speed 57.33 f/s\n","321835: done 3291 episodes, mean reward 1.222, speed 59.38 f/s\n","322123: done 3292 episodes, mean reward 1.250, speed 57.95 f/s\n","322773: done 3293 episodes, mean reward 1.326, speed 59.21 f/s\n","323384: done 3294 episodes, mean reward 1.347, speed 59.19 f/s\n","324054: done 3295 episodes, mean reward 1.413, speed 58.97 f/s\n","325054: done 3296 episodes, mean reward 1.533, speed 60.33 f/s\n","325509: done 3297 episodes, mean reward 1.557, speed 59.19 f/s\n","326092: done 3298 episodes, mean reward 1.610, speed 59.21 f/s\n","326196: done 3299 episodes, mean reward 1.602, speed 54.74 f/s\n","326257: done 3300 episodes, mean reward 1.599, speed 51.49 f/s\n","326417: done 3301 episodes, mean reward 1.609, speed 56.62 f/s\n","327417: done 3302 episodes, mean reward 1.693, speed 59.42 f/s\n","327851: done 3303 episodes, mean reward 1.733, speed 58.75 f/s\n","328105: done 3304 episodes, mean reward 1.751, speed 57.84 f/s\n","328173: done 3306 episodes, mean reward 1.740, speed 47.38 f/s\n","328371: done 3307 episodes, mean reward 1.756, speed 56.71 f/s\n","328510: done 3308 episodes, mean reward 1.756, speed 56.26 f/s\n","328966: done 3309 episodes, mean reward 1.810, speed 58.88 f/s\n","329360: done 3310 episodes, mean reward 1.838, speed 58.45 f/s\n","EEEE tensor(-7.4655, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.1476, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0002, grad_fn=<ExpBackward>)\n","Test done in 22.39 sec, reward 3.772, steps 379\n","Best reward updated: 3.146 -> 3.772\n","330194: done 3312 episodes, mean reward 1.896, speed 22.77 f/s\n","330580: done 3313 episodes, mean reward 1.929, speed 59.57 f/s\n","330909: done 3315 episodes, mean reward 1.953, speed 57.92 f/s\n","331181: done 3316 episodes, mean reward 1.968, speed 59.19 f/s\n","331282: done 3317 episodes, mean reward 1.969, speed 55.59 f/s\n","331963: done 3318 episodes, mean reward 2.031, speed 59.87 f/s\n","332455: done 3319 episodes, mean reward 2.105, speed 60.05 f/s\n","332581: done 3320 episodes, mean reward 2.080, speed 55.92 f/s\n","333409: done 3321 episodes, mean reward 2.186, speed 59.41 f/s\n","333971: done 3322 episodes, mean reward 2.232, speed 58.04 f/s\n","334971: done 3323 episodes, mean reward 2.337, speed 59.36 f/s\n","336014: done 3325 episodes, mean reward 2.419, speed 59.22 f/s\n","336502: done 3326 episodes, mean reward 2.466, speed 59.31 f/s\n","336949: done 3328 episodes, mean reward 2.496, speed 58.35 f/s\n","337697: done 3329 episodes, mean reward 2.559, speed 56.78 f/s\n","338697: done 3330 episodes, mean reward 2.683, speed 59.07 f/s\n","339697: done 3331 episodes, mean reward 2.825, speed 57.85 f/s\n","EEEE tensor(-7.4429, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.1767, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0003, grad_fn=<ExpBackward>)\n","Test done in 41.90 sec, reward 9.738, steps 748\n","Best reward updated: 3.772 -> 9.738\n","340697: done 3332 episodes, mean reward 2.954, speed 17.07 f/s\n","340988: done 3333 episodes, mean reward 2.971, speed 56.95 f/s\n","341956: done 3334 episodes, mean reward 3.053, speed 58.45 f/s\n","342956: done 3335 episodes, mean reward 3.172, speed 58.78 f/s\n","343134: done 3336 episodes, mean reward 3.182, speed 56.89 f/s\n","343347: done 3337 episodes, mean reward 3.199, speed 57.55 f/s\n","343490: done 3338 episodes, mean reward 3.209, speed 56.20 f/s\n","344394: done 3339 episodes, mean reward 3.274, speed 59.31 f/s\n","344748: done 3340 episodes, mean reward 3.307, speed 58.13 f/s\n","345498: done 3341 episodes, mean reward 3.374, speed 58.68 f/s\n","345801: done 3342 episodes, mean reward 3.402, speed 56.76 f/s\n","346801: done 3343 episodes, mean reward 3.480, speed 59.87 f/s\n","347801: done 3344 episodes, mean reward 3.598, speed 60.50 f/s\n","348671: done 3345 episodes, mean reward 3.662, speed 60.51 f/s\n","349411: done 3346 episodes, mean reward 3.702, speed 59.98 f/s\n","EEEE tensor(-8.7550, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2131, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0003, grad_fn=<ExpBackward>)\n","Test done in 32.95 sec, reward 4.556, steps 577\n","350083: done 3347 episodes, mean reward 3.729, speed 15.19 f/s\n","351125: done 3349 episodes, mean reward 3.780, speed 59.36 f/s\n","352125: done 3350 episodes, mean reward 3.812, speed 59.94 f/s\n","352789: done 3351 episodes, mean reward 3.854, speed 59.81 f/s\n","353250: done 3352 episodes, mean reward 3.878, speed 60.30 f/s\n","353698: done 3353 episodes, mean reward 3.894, speed 59.07 f/s\n","354009: done 3354 episodes, mean reward 3.921, speed 58.56 f/s\n","354639: done 3355 episodes, mean reward 3.947, speed 60.17 f/s\n","355152: done 3357 episodes, mean reward 3.969, speed 59.38 f/s\n","355778: done 3358 episodes, mean reward 4.000, speed 60.27 f/s\n","356778: done 3359 episodes, mean reward 4.056, speed 60.36 f/s\n","357004: done 3360 episodes, mean reward 4.075, speed 58.44 f/s\n","357259: done 3361 episodes, mean reward 4.092, speed 58.26 f/s\n","358259: done 3362 episodes, mean reward 4.141, speed 60.13 f/s\n","359259: done 3363 episodes, mean reward 4.201, speed 59.68 f/s\n","EEEE tensor(-7.2363, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2641, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 46.22 sec, reward 7.221, steps 837\n","360176: done 3364 episodes, mean reward 4.246, speed 14.92 f/s\n","361136: done 3365 episodes, mean reward 4.331, speed 60.27 f/s\n","362136: done 3366 episodes, mean reward 4.417, speed 60.26 f/s\n","363136: done 3367 episodes, mean reward 4.506, speed 60.14 f/s\n","364136: done 3368 episodes, mean reward 4.582, speed 59.99 f/s\n","364380: done 3369 episodes, mean reward 4.607, speed 58.04 f/s\n","365380: done 3370 episodes, mean reward 4.727, speed 59.63 f/s\n","366380: done 3371 episodes, mean reward 4.794, speed 60.11 f/s\n","367380: done 3372 episodes, mean reward 4.895, speed 60.93 f/s\n","367669: done 3373 episodes, mean reward 4.894, speed 60.24 f/s\n","367830: done 3375 episodes, mean reward 4.773, speed 55.25 f/s\n","367948: done 3377 episodes, mean reward 4.774, speed 53.26 f/s\n","368948: done 3378 episodes, mean reward 4.820, speed 60.58 f/s\n","369989: done 3380 episodes, mean reward 4.852, speed 60.12 f/s\n","EEEE tensor(-7.7868, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2811, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 41.39 sec, reward 6.541, steps 734\n","370103: done 3381 episodes, mean reward 4.851, speed 2.62 f/s\n","371103: done 3382 episodes, mean reward 4.945, speed 59.41 f/s\n","372103: done 3383 episodes, mean reward 5.027, speed 59.05 f/s\n","373103: done 3384 episodes, mean reward 5.065, speed 58.78 f/s\n","374103: done 3385 episodes, mean reward 5.179, speed 59.89 f/s\n","374226: done 3386 episodes, mean reward 5.173, speed 57.12 f/s\n","375226: done 3387 episodes, mean reward 5.281, speed 59.20 f/s\n","376226: done 3388 episodes, mean reward 5.388, speed 59.27 f/s\n","377226: done 3389 episodes, mean reward 5.505, speed 59.23 f/s\n","378226: done 3390 episodes, mean reward 5.629, speed 59.08 f/s\n","379226: done 3391 episodes, mean reward 5.683, speed 59.66 f/s\n","EEEE tensor(-7.9958, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3021, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 38.37 sec, reward 10.004, steps 675\n","Best reward updated: 9.738 -> 10.004\n","380226: done 3392 episodes, mean reward 5.772, speed 18.17 f/s\n","381226: done 3393 episodes, mean reward 5.849, speed 59.74 f/s\n","381472: done 3394 episodes, mean reward 5.847, speed 58.80 f/s\n","382472: done 3395 episodes, mean reward 5.942, speed 60.28 f/s\n","383461: done 3396 episodes, mean reward 5.954, speed 60.15 f/s\n","384461: done 3397 episodes, mean reward 6.037, speed 60.02 f/s\n","385461: done 3398 episodes, mean reward 6.112, speed 59.66 f/s\n","386461: done 3399 episodes, mean reward 6.252, speed 59.62 f/s\n","386752: done 3400 episodes, mean reward 6.282, speed 58.26 f/s\n","387124: done 3401 episodes, mean reward 6.308, speed 59.22 f/s\n","388124: done 3402 episodes, mean reward 6.324, speed 59.46 f/s\n","389124: done 3403 episodes, mean reward 6.433, speed 59.22 f/s\n","EEEE tensor(-7.6079, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3575, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 36.69 sec, reward 7.972, steps 645\n","390124: done 3404 episodes, mean reward 6.557, speed 18.61 f/s\n","390266: done 3405 episodes, mean reward 6.572, speed 57.44 f/s\n","391266: done 3406 episodes, mean reward 6.669, speed 59.62 f/s\n","392300: done 3408 episodes, mean reward 6.777, speed 59.44 f/s\n","393300: done 3409 episodes, mean reward 6.815, speed 60.00 f/s\n","394300: done 3410 episodes, mean reward 6.879, speed 59.68 f/s\n","395191: done 3411 episodes, mean reward 7.004, speed 60.17 f/s\n","396191: done 3412 episodes, mean reward 7.040, speed 60.13 f/s\n","397191: done 3413 episodes, mean reward 7.130, speed 59.67 f/s\n","397577: done 3414 episodes, mean reward 7.192, speed 59.37 f/s\n","398265: done 3415 episodes, mean reward 7.260, speed 59.93 f/s\n","399306: done 3417 episodes, mean reward 7.368, speed 59.14 f/s\n","399529: done 3418 episodes, mean reward 7.329, speed 57.76 f/s\n","399585: done 3419 episodes, mean reward 7.256, speed 52.25 f/s\n","EEEE tensor(-8.4607, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3693, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 36.39 sec, reward 9.438, steps 651\n","400585: done 3420 episodes, mean reward 7.433, speed 18.90 f/s\n","401269: done 3421 episodes, mean reward 7.425, speed 60.38 f/s\n","401437: done 3422 episodes, mean reward 7.392, speed 58.07 f/s\n","402437: done 3423 episodes, mean reward 7.394, speed 60.50 f/s\n","402650: done 3424 episodes, mean reward 7.419, speed 58.87 f/s\n","403650: done 3425 episodes, mean reward 7.456, speed 59.95 f/s\n","404650: done 3426 episodes, mean reward 7.467, speed 59.89 f/s\n","405650: done 3427 episodes, mean reward 7.558, speed 59.89 f/s\n","406650: done 3428 episodes, mean reward 7.601, speed 59.83 f/s\n","407650: done 3429 episodes, mean reward 7.615, speed 60.05 f/s\n","408650: done 3430 episodes, mean reward 7.594, speed 59.86 f/s\n","409650: done 3431 episodes, mean reward 7.617, speed 60.01 f/s\n","409867: done 3432 episodes, mean reward 7.505, speed 55.94 f/s\n","EEEE tensor(-7.5331, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4301, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 50.11 sec, reward 10.382, steps 905\n","Best reward updated: 10.004 -> 10.382\n","410406: done 3433 episodes, mean reward 7.526, speed 9.10 f/s\n","411030: done 3434 episodes, mean reward 7.521, speed 59.50 f/s\n","412063: done 3436 episodes, mean reward 7.479, speed 59.54 f/s\n","412682: done 3437 episodes, mean reward 7.520, speed 59.75 f/s\n","413682: done 3438 episodes, mean reward 7.578, speed 60.12 f/s\n","414682: done 3439 episodes, mean reward 7.614, speed 59.75 f/s\n","415682: done 3440 episodes, mean reward 7.727, speed 59.94 f/s\n","416682: done 3441 episodes, mean reward 7.788, speed 60.10 f/s\n","417214: done 3442 episodes, mean reward 7.810, speed 60.58 f/s\n","418214: done 3443 episodes, mean reward 7.880, speed 60.53 f/s\n","419214: done 3444 episodes, mean reward 7.854, speed 59.84 f/s\n","EEEE tensor(-8.1806, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4470, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 47.97 sec, reward 8.343, steps 846\n","420214: done 3445 episodes, mean reward 7.880, speed 15.45 f/s\n","421214: done 3446 episodes, mean reward 7.917, speed 59.79 f/s\n","422074: done 3447 episodes, mean reward 7.977, speed 59.90 f/s\n","422155: done 3448 episodes, mean reward 7.982, speed 54.62 f/s\n","423155: done 3449 episodes, mean reward 8.006, speed 59.96 f/s\n","423483: done 3450 episodes, mean reward 8.008, speed 59.35 f/s\n","424483: done 3451 episodes, mean reward 8.041, speed 60.00 f/s\n","424736: done 3452 episodes, mean reward 8.035, speed 59.42 f/s\n","425002: done 3453 episodes, mean reward 8.040, speed 58.82 f/s\n","426002: done 3454 episodes, mean reward 8.109, speed 59.77 f/s\n","426451: done 3456 episodes, mean reward 8.127, speed 57.93 f/s\n","427451: done 3457 episodes, mean reward 8.168, speed 59.41 f/s\n","428451: done 3458 episodes, mean reward 8.228, speed 59.92 f/s\n","429451: done 3459 episodes, mean reward 8.293, speed 59.95 f/s\n","EEEE tensor(-7.4290, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4425, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 34.60 sec, reward 7.762, steps 607\n","430451: done 3460 episodes, mean reward 8.388, speed 19.48 f/s\n","430673: done 3461 episodes, mean reward 8.376, speed 58.47 f/s\n","431356: done 3462 episodes, mean reward 8.395, speed 59.71 f/s\n","431970: done 3463 episodes, mean reward 8.419, speed 59.11 f/s\n","432299: done 3465 episodes, mean reward 8.288, speed 57.16 f/s\n","433299: done 3466 episodes, mean reward 8.290, speed 59.49 f/s\n","434186: done 3467 episodes, mean reward 8.289, speed 59.82 f/s\n","435036: done 3468 episodes, mean reward 8.306, speed 58.65 f/s\n","435415: done 3469 episodes, mean reward 8.314, speed 58.20 f/s\n","436415: done 3470 episodes, mean reward 8.328, speed 59.51 f/s\n","436751: done 3471 episodes, mean reward 8.262, speed 59.43 f/s\n","436974: done 3472 episodes, mean reward 8.179, speed 58.79 f/s\n","437867: done 3473 episodes, mean reward 8.277, speed 60.03 f/s\n","438746: done 3474 episodes, mean reward 8.415, speed 59.90 f/s\n","438907: done 3475 episodes, mean reward 8.425, speed 58.06 f/s\n","439063: done 3476 episodes, mean reward 8.442, speed 57.75 f/s\n","EEEE tensor(-8.1786, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4558, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 25.69 sec, reward 5.596, steps 437\n","440021: done 3477 episodes, mean reward 8.562, speed 23.01 f/s\n","440344: done 3478 episodes, mean reward 8.508, speed 57.70 f/s\n","440407: done 3479 episodes, mean reward 8.511, speed 52.84 f/s\n","440657: done 3480 episodes, mean reward 8.444, speed 57.85 f/s\n","441657: done 3481 episodes, mean reward 8.567, speed 58.89 f/s\n","442657: done 3482 episodes, mean reward 8.615, speed 59.12 f/s\n","442739: done 3483 episodes, mean reward 8.518, speed 53.57 f/s\n","443739: done 3484 episodes, mean reward 8.526, speed 58.54 f/s\n","444739: done 3485 episodes, mean reward 8.553, speed 59.59 f/s\n","445739: done 3486 episodes, mean reward 8.675, speed 58.78 f/s\n","446264: done 3487 episodes, mean reward 8.615, speed 59.07 f/s\n","446355: done 3488 episodes, mean reward 8.472, speed 54.56 f/s\n","446943: done 3489 episodes, mean reward 8.441, speed 59.17 f/s\n","447539: done 3490 episodes, mean reward 8.391, speed 58.84 f/s\n","448539: done 3491 episodes, mean reward 8.424, speed 58.96 f/s\n","449403: done 3492 episodes, mean reward 8.418, speed 59.69 f/s\n","EEEE tensor(-7.9059, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4934, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 40.91 sec, reward 10.847, steps 735\n","Best reward updated: 10.382 -> 10.847\n","450186: done 3493 episodes, mean reward 8.375, speed 14.53 f/s\n","450922: done 3494 episodes, mean reward 8.446, speed 59.26 f/s\n","451623: done 3495 episodes, mean reward 8.373, speed 59.82 f/s\n","452097: done 3496 episodes, mean reward 8.285, speed 58.79 f/s\n","452228: done 3497 episodes, mean reward 8.186, speed 57.15 f/s\n","452554: done 3498 episodes, mean reward 8.089, speed 58.55 f/s\n","453554: done 3499 episodes, mean reward 8.053, speed 59.96 f/s\n","454554: done 3500 episodes, mean reward 8.177, speed 59.66 f/s\n","455554: done 3501 episodes, mean reward 8.261, speed 59.74 f/s\n","455634: done 3502 episodes, mean reward 8.164, speed 55.16 f/s\n","456634: done 3503 episodes, mean reward 8.149, speed 60.18 f/s\n","457044: done 3504 episodes, mean reward 8.048, speed 59.74 f/s\n","458044: done 3505 episodes, mean reward 8.166, speed 60.05 f/s\n","459044: done 3506 episodes, mean reward 8.195, speed 59.72 f/s\n","459243: done 3507 episodes, mean reward 8.209, speed 58.20 f/s\n","459315: done 3508 episodes, mean reward 8.079, speed 54.31 f/s\n","459775: done 3509 episodes, mean reward 8.048, speed 58.71 f/s\n","EEEE tensor(-7.3225, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5009, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 39.21 sec, reward 9.090, steps 695\n","460526: done 3510 episodes, mean reward 8.041, speed 14.47 f/s\n","461526: done 3511 episodes, mean reward 8.030, speed 60.22 f/s\n","462526: done 3512 episodes, mean reward 8.090, speed 59.33 f/s\n","463264: done 3513 episodes, mean reward 8.048, speed 58.74 f/s\n","463735: done 3514 episodes, mean reward 8.043, speed 58.97 f/s\n","463883: done 3515 episodes, mean reward 7.947, speed 56.88 f/s\n","464883: done 3516 episodes, mean reward 8.096, speed 60.07 f/s\n","465614: done 3517 episodes, mean reward 8.061, speed 60.14 f/s\n","466614: done 3518 episodes, mean reward 8.174, speed 59.40 f/s\n","466897: done 3519 episodes, mean reward 8.200, speed 59.21 f/s\n","467897: done 3520 episodes, mean reward 8.169, speed 59.07 f/s\n","468248: done 3521 episodes, mean reward 8.111, speed 59.37 f/s\n","469248: done 3522 episodes, mean reward 8.236, speed 59.82 f/s\n","469349: done 3523 episodes, mean reward 8.116, speed 56.29 f/s\n","EEEE tensor(-7.5274, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5160, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 38.15 sec, reward 8.165, steps 672\n","470349: done 3524 episodes, mean reward 8.227, speed 18.22 f/s\n","471395: done 3526 episodes, mean reward 8.182, speed 59.23 f/s\n","471472: done 3528 episodes, mean reward 8.010, speed 48.45 f/s\n","472472: done 3529 episodes, mean reward 8.069, speed 59.03 f/s\n","473459: done 3530 episodes, mean reward 8.078, speed 59.77 f/s\n","474459: done 3531 episodes, mean reward 8.054, speed 59.71 f/s\n","475459: done 3532 episodes, mean reward 8.148, speed 60.01 f/s\n","476143: done 3533 episodes, mean reward 8.182, speed 59.75 f/s\n","476242: done 3534 episodes, mean reward 8.107, speed 56.48 f/s\n","476559: done 3535 episodes, mean reward 8.141, speed 59.60 f/s\n","477559: done 3536 episodes, mean reward 8.173, speed 60.35 f/s\n","477904: done 3537 episodes, mean reward 8.151, speed 59.97 f/s\n","478904: done 3538 episodes, mean reward 8.219, speed 59.64 f/s\n","479904: done 3539 episodes, mean reward 8.250, speed 59.68 f/s\n","EEEE tensor(-8.5532, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5801, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 23.45 sec, reward 4.974, steps 405\n","480136: done 3540 episodes, mean reward 8.126, speed 8.47 f/s\n","480252: done 3541 episodes, mean reward 8.001, speed 56.49 f/s\n","480909: done 3542 episodes, mean reward 8.022, speed 59.48 f/s\n","481484: done 3543 episodes, mean reward 7.945, speed 59.71 f/s\n","481878: done 3544 episodes, mean reward 7.906, speed 58.85 f/s\n","481968: done 3545 episodes, mean reward 7.807, speed 54.98 f/s\n","482199: done 3546 episodes, mean reward 7.750, speed 58.17 f/s\n","482552: done 3548 episodes, mean reward 7.690, speed 57.79 f/s\n","482712: done 3549 episodes, mean reward 7.615, speed 56.42 f/s\n","483653: done 3550 episodes, mean reward 7.700, speed 59.49 f/s\n","483730: done 3551 episodes, mean reward 7.624, speed 54.49 f/s\n","484196: done 3552 episodes, mean reward 7.656, speed 59.61 f/s\n","484421: done 3553 episodes, mean reward 7.646, speed 58.60 f/s\n","484522: done 3554 episodes, mean reward 7.549, speed 56.04 f/s\n","484838: done 3555 episodes, mean reward 7.584, speed 59.14 f/s\n","485838: done 3556 episodes, mean reward 7.670, speed 60.51 f/s\n","486210: done 3557 episodes, mean reward 7.615, speed 59.42 f/s\n","486789: done 3558 episodes, mean reward 7.569, speed 59.71 f/s\n","487190: done 3559 episodes, mean reward 7.469, speed 59.37 f/s\n","487541: done 3561 episodes, mean reward 7.377, speed 57.45 f/s\n","488517: done 3562 episodes, mean reward 7.422, speed 60.28 f/s\n","489401: done 3563 episodes, mean reward 7.434, speed 60.33 f/s\n","489480: done 3564 episodes, mean reward 7.436, speed 55.29 f/s\n","EEEE tensor(-7.8849, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5676, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 24.11 sec, reward 4.681, steps 420\n","490314: done 3565 episodes, mean reward 7.509, speed 21.97 f/s\n","490468: done 3566 episodes, mean reward 7.422, speed 58.03 f/s\n","491304: done 3567 episodes, mean reward 7.455, speed 59.79 f/s\n","491559: done 3568 episodes, mean reward 7.393, speed 59.11 f/s\n","492559: done 3569 episodes, mean reward 7.471, speed 61.05 f/s\n","493598: done 3571 episodes, mean reward 7.421, speed 60.14 f/s\n","493774: done 3572 episodes, mean reward 7.412, speed 58.92 f/s\n","494774: done 3573 episodes, mean reward 7.417, speed 60.08 f/s\n","494936: done 3574 episodes, mean reward 7.290, speed 56.79 f/s\n","495936: done 3575 episodes, mean reward 7.373, speed 59.93 f/s\n","496229: done 3576 episodes, mean reward 7.382, speed 59.08 f/s\n","497229: done 3577 episodes, mean reward 7.391, speed 60.24 f/s\n","497724: done 3578 episodes, mean reward 7.406, speed 59.49 f/s\n","497979: done 3580 episodes, mean reward 7.397, speed 57.16 f/s\n","498265: done 3581 episodes, mean reward 7.301, speed 59.36 f/s\n","498518: done 3582 episodes, mean reward 7.173, speed 58.64 f/s\n","499217: done 3583 episodes, mean reward 7.236, speed 60.17 f/s\n","EEEE tensor(-9.2910, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5607, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 31.90 sec, reward 6.577, steps 558\n","500041: done 3584 episodes, mean reward 7.192, speed 18.01 f/s\n","500266: done 3585 episodes, mean reward 7.071, speed 58.47 f/s\n","500501: done 3587 episodes, mean reward 6.888, speed 56.29 f/s\n","501060: done 3588 episodes, mean reward 6.964, speed 60.40 f/s\n","502060: done 3589 episodes, mean reward 7.008, speed 60.59 f/s\n","502619: done 3590 episodes, mean reward 6.980, speed 59.31 f/s\n","503132: done 3591 episodes, mean reward 6.911, speed 59.46 f/s\n","504132: done 3592 episodes, mean reward 6.908, speed 59.25 f/s\n","504250: done 3593 episodes, mean reward 6.799, speed 55.92 f/s\n","504341: done 3594 episodes, mean reward 6.712, speed 55.51 f/s\n","504761: done 3595 episodes, mean reward 6.666, speed 58.63 f/s\n","505761: done 3596 episodes, mean reward 6.746, speed 60.51 f/s\n","506354: done 3598 episodes, mean reward 6.760, speed 59.23 f/s\n","506990: done 3599 episodes, mean reward 6.728, speed 59.75 f/s\n","507342: done 3600 episodes, mean reward 6.613, speed 60.04 f/s\n","507670: done 3601 episodes, mean reward 6.533, speed 58.62 f/s\n","508211: done 3602 episodes, mean reward 6.599, speed 58.30 f/s\n","508481: done 3603 episodes, mean reward 6.493, speed 58.18 f/s\n","509481: done 3604 episodes, mean reward 6.543, speed 59.83 f/s\n","509817: done 3606 episodes, mean reward 6.312, speed 57.44 f/s\n","EEEE tensor(-7.4372, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5950, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0006, grad_fn=<ExpBackward>)\n","Test done in 40.06 sec, reward 8.925, steps 710\n","510817: done 3607 episodes, mean reward 6.431, speed 17.59 f/s\n","511817: done 3608 episodes, mean reward 6.577, speed 59.53 f/s\n","512817: done 3609 episodes, mean reward 6.637, speed 59.86 f/s\n","513817: done 3610 episodes, mean reward 6.681, speed 60.21 f/s\n","514106: done 3611 episodes, mean reward 6.589, speed 58.35 f/s\n","514706: done 3612 episodes, mean reward 6.510, speed 59.78 f/s\n","515706: done 3613 episodes, mean reward 6.562, speed 59.40 f/s\n","516198: done 3614 episodes, mean reward 6.558, speed 59.14 f/s\n","516404: done 3615 episodes, mean reward 6.561, speed 56.64 f/s\n","517404: done 3616 episodes, mean reward 6.545, speed 60.49 f/s\n","517600: done 3617 episodes, mean reward 6.452, speed 57.93 f/s\n","518600: done 3618 episodes, mean reward 6.452, speed 59.67 f/s\n","519600: done 3619 episodes, mean reward 6.571, speed 59.75 f/s\n","EEEE tensor(-7.7949, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5838, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0006, grad_fn=<ExpBackward>)\n","Test done in 26.68 sec, reward 5.033, steps 464\n","520520: done 3620 episodes, mean reward 6.530, speed 21.91 f/s\n","520905: done 3621 episodes, mean reward 6.529, speed 58.69 f/s\n","521295: done 3622 episodes, mean reward 6.425, speed 58.95 f/s\n","522295: done 3623 episodes, mean reward 6.542, speed 59.94 f/s\n","522816: done 3624 episodes, mean reward 6.469, speed 57.15 f/s\n","523089: done 3625 episodes, mean reward 6.494, speed 57.78 f/s\n","524089: done 3626 episodes, mean reward 6.450, speed 58.88 f/s\n","524760: done 3627 episodes, mean reward 6.541, speed 59.58 f/s\n","525152: done 3628 episodes, mean reward 6.557, speed 58.64 f/s\n","525490: done 3629 episodes, mean reward 6.443, speed 57.78 f/s\n","525692: done 3630 episodes, mean reward 6.341, speed 57.14 f/s\n","526149: done 3631 episodes, mean reward 6.250, speed 58.83 f/s\n","526421: done 3632 episodes, mean reward 6.156, speed 57.80 f/s\n","526518: done 3633 episodes, mean reward 6.077, speed 54.54 f/s\n","527518: done 3634 episodes, mean reward 6.219, speed 59.41 f/s\n","528518: done 3635 episodes, mean reward 6.326, speed 58.69 f/s\n","528760: done 3636 episodes, mean reward 6.211, speed 58.22 f/s\n","529760: done 3637 episodes, mean reward 6.268, speed 60.56 f/s\n","EEEE tensor(-9.2274, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5829, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 26.28 sec, reward 4.577, steps 453\n","530022: done 3638 episodes, mean reward 6.145, speed 8.50 f/s\n","530286: done 3639 episodes, mean reward 6.030, speed 57.26 f/s\n","530426: done 3640 episodes, mean reward 6.018, speed 56.23 f/s\n","531426: done 3641 episodes, mean reward 6.164, speed 58.68 f/s\n","532069: done 3642 episodes, mean reward 6.165, speed 59.11 f/s\n","533069: done 3643 episodes, mean reward 6.187, speed 59.89 f/s\n","533399: done 3644 episodes, mean reward 6.171, speed 57.92 f/s\n","533659: done 3645 episodes, mean reward 6.191, speed 57.33 f/s\n","533914: done 3646 episodes, mean reward 6.182, speed 57.90 f/s\n","534369: done 3647 episodes, mean reward 6.226, speed 58.28 f/s\n","535369: done 3648 episodes, mean reward 6.317, speed 58.66 f/s\n","535574: done 3649 episodes, mean reward 6.322, speed 57.45 f/s\n","536574: done 3650 episodes, mean reward 6.318, speed 58.58 f/s\n","537175: done 3651 episodes, mean reward 6.395, speed 58.55 f/s\n","537537: done 3652 episodes, mean reward 6.373, speed 59.01 f/s\n","537595: done 3653 episodes, mean reward 6.353, speed 52.17 f/s\n","538175: done 3654 episodes, mean reward 6.401, speed 59.40 f/s\n","539175: done 3655 episodes, mean reward 6.516, speed 60.04 f/s\n","539802: done 3656 episodes, mean reward 6.468, speed 59.90 f/s\n","EEEE tensor(-8.0079, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5864, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0006, grad_fn=<ExpBackward>)\n","Test done in 25.63 sec, reward 4.683, steps 444\n","540193: done 3657 episodes, mean reward 6.469, speed 12.10 f/s\n","540485: done 3658 episodes, mean reward 6.450, speed 58.01 f/s\n","540665: done 3659 episodes, mean reward 6.424, speed 56.50 f/s\n","541430: done 3660 episodes, mean reward 6.516, speed 59.80 f/s\n","542354: done 3661 episodes, mean reward 6.600, speed 60.12 f/s\n","542562: done 3662 episodes, mean reward 6.491, speed 57.89 f/s\n","542694: done 3663 episodes, mean reward 6.397, speed 56.97 f/s\n","542886: done 3664 episodes, mean reward 6.406, speed 57.70 f/s\n","543675: done 3665 episodes, mean reward 6.395, speed 59.84 f/s\n","543922: done 3666 episodes, mean reward 6.407, speed 57.84 f/s\n","544066: done 3667 episodes, mean reward 6.281, speed 57.51 f/s\n","544241: done 3668 episodes, mean reward 6.255, speed 57.41 f/s\n","545241: done 3669 episodes, mean reward 6.279, speed 59.94 f/s\n","546276: done 3671 episodes, mean reward 6.263, speed 59.82 f/s\n","546529: done 3672 episodes, mean reward 6.268, speed 58.12 f/s\n","546738: done 3673 episodes, mean reward 6.159, speed 58.86 f/s\n","547738: done 3674 episodes, mean reward 6.290, speed 60.00 f/s\n","547859: done 3675 episodes, mean reward 6.200, speed 56.36 f/s\n","547969: done 3676 episodes, mean reward 6.180, speed 56.33 f/s\n","548367: done 3677 episodes, mean reward 6.088, speed 58.86 f/s\n","548501: done 3678 episodes, mean reward 6.036, speed 57.25 f/s\n","548640: done 3679 episodes, mean reward 6.042, speed 57.07 f/s\n","548735: done 3680 episodes, mean reward 6.022, speed 55.17 f/s\n","548826: done 3681 episodes, mean reward 5.992, speed 54.71 f/s\n","548958: done 3682 episodes, mean reward 5.969, speed 56.47 f/s\n","549046: done 3683 episodes, mean reward 5.905, speed 54.05 f/s\n","549324: done 3684 episodes, mean reward 5.846, speed 57.46 f/s\n","549422: done 3685 episodes, mean reward 5.827, speed 54.83 f/s\n","EEEE tensor(-7.8074, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5926, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0006, grad_fn=<ExpBackward>)\n","Test done in 31.21 sec, reward 7.626, steps 550\n","550071: done 3686 episodes, mean reward 5.896, speed 15.38 f/s\n","550477: done 3687 episodes, mean reward 5.927, speed 59.40 f/s\n","550814: done 3688 episodes, mean reward 5.860, speed 59.40 f/s\n","551485: done 3689 episodes, mean reward 5.794, speed 59.24 f/s\n","552485: done 3690 episodes, mean reward 5.891, speed 60.04 f/s\n","552628: done 3691 episodes, mean reward 5.836, speed 56.99 f/s\n","552982: done 3692 episodes, mean reward 5.761, speed 58.36 f/s\n","553982: done 3693 episodes, mean reward 5.890, speed 60.16 f/s\n","554142: done 3694 episodes, mean reward 5.895, speed 58.00 f/s\n","554319: done 3695 episodes, mean reward 5.861, speed 58.39 f/s\n","554808: done 3696 episodes, mean reward 5.777, speed 60.20 f/s\n","555583: done 3697 episodes, mean reward 5.878, speed 60.26 f/s\n","555756: done 3698 episodes, mean reward 5.834, speed 57.70 f/s\n","556056: done 3699 episodes, mean reward 5.788, speed 59.02 f/s\n","556227: done 3700 episodes, mean reward 5.757, speed 57.62 f/s\n","556466: done 3701 episodes, mean reward 5.737, speed 59.00 f/s\n","556588: done 3703 episodes, mean reward 5.637, speed 52.28 f/s\n","556903: done 3704 episodes, mean reward 5.551, speed 57.55 f/s\n","557201: done 3705 episodes, mean reward 5.578, speed 57.55 f/s\n","558201: done 3706 episodes, mean reward 5.677, speed 60.52 f/s\n","558557: done 3707 episodes, mean reward 5.583, speed 59.12 f/s\n","558758: done 3708 episodes, mean reward 5.447, speed 58.13 f/s\n","559619: done 3709 episodes, mean reward 5.443, speed 59.87 f/s\n","559740: done 3710 episodes, mean reward 5.315, speed 56.89 f/s\n","EEEE tensor(-8.0077, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5566, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0006, grad_fn=<ExpBackward>)\n","Test done in 39.68 sec, reward 10.134, steps 706\n","560740: done 3711 episodes, mean reward 5.428, speed 17.78 f/s\n","561740: done 3712 episodes, mean reward 5.467, speed 60.49 f/s\n","562259: done 3713 episodes, mean reward 5.374, speed 60.05 f/s\n","563259: done 3714 episodes, mean reward 5.481, speed 60.33 f/s\n","564259: done 3715 episodes, mean reward 5.620, speed 59.73 f/s\n","564350: done 3716 episodes, mean reward 5.488, speed 53.85 f/s\n","564487: done 3717 episodes, mean reward 5.490, speed 56.64 f/s\n","564721: done 3718 episodes, mean reward 5.373, speed 57.70 f/s\n","564932: done 3719 episodes, mean reward 5.248, speed 58.02 f/s\n","565932: done 3720 episodes, mean reward 5.281, speed 60.04 f/s\n","566551: done 3721 episodes, mean reward 5.291, speed 59.98 f/s\n","567551: done 3722 episodes, mean reward 5.376, speed 60.74 f/s\n","567918: done 3723 episodes, mean reward 5.299, speed 59.44 f/s\n","568046: done 3724 episodes, mean reward 5.246, speed 56.30 f/s\n","568155: done 3725 episodes, mean reward 5.228, speed 54.82 f/s\n","568590: done 3726 episodes, mean reward 5.185, speed 59.19 f/s\n","568961: done 3727 episodes, mean reward 5.139, speed 58.96 f/s\n","569589: done 3728 episodes, mean reward 5.198, speed 58.89 f/s\n","EEEE tensor(-7.9380, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5564, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0006, grad_fn=<ExpBackward>)\n","Test done in 37.44 sec, reward 8.678, steps 665\n","570433: done 3729 episodes, mean reward 5.243, speed 16.41 f/s\n","570509: done 3730 episodes, mean reward 5.227, speed 54.40 f/s\n","570748: done 3731 episodes, mean reward 5.204, speed 58.71 f/s\n","570952: done 3732 episodes, mean reward 5.200, speed 58.31 f/s\n","571952: done 3733 episodes, mean reward 5.333, speed 59.11 f/s\n","572952: done 3734 episodes, mean reward 5.306, speed 60.31 f/s\n","573952: done 3735 episodes, mean reward 5.277, speed 59.99 f/s\n","574827: done 3736 episodes, mean reward 5.386, speed 61.11 f/s\n","575519: done 3738 episodes, mean reward 5.348, speed 58.87 f/s\n","575650: done 3739 episodes, mean reward 5.332, speed 56.36 f/s\n","576650: done 3740 episodes, mean reward 5.441, speed 59.14 f/s\n","577650: done 3741 episodes, mean reward 5.426, speed 60.33 f/s\n","578476: done 3742 episodes, mean reward 5.452, speed 60.26 f/s\n","578837: done 3743 episodes, mean reward 5.382, speed 58.43 f/s\n","579084: done 3744 episodes, mean reward 5.365, speed 59.20 f/s\n","579322: done 3745 episodes, mean reward 5.369, speed 59.34 f/s\n","579790: done 3746 episodes, mean reward 5.398, speed 60.14 f/s\n","EEEE tensor(-7.5101, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5450, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 27.46 sec, reward 5.090, steps 475\n","580418: done 3747 episodes, mean reward 5.403, speed 16.58 f/s\n","580698: done 3748 episodes, mean reward 5.298, speed 58.76 f/s\n","581698: done 3749 episodes, mean reward 5.387, speed 59.75 f/s\n","582016: done 3750 episodes, mean reward 5.293, speed 58.93 f/s\n","582573: done 3751 episodes, mean reward 5.242, speed 60.18 f/s\n","582940: done 3752 episodes, mean reward 5.247, speed 60.27 f/s\n","583020: done 3753 episodes, mean reward 5.244, speed 53.45 f/s\n","583141: done 3754 episodes, mean reward 5.204, speed 56.74 f/s\n","584097: done 3755 episodes, mean reward 5.166, speed 61.15 f/s\n","584387: done 3756 episodes, mean reward 5.092, speed 58.48 f/s\n","585387: done 3757 episodes, mean reward 5.138, speed 60.33 f/s\n","586387: done 3758 episodes, mean reward 5.230, speed 60.57 f/s\n","586730: done 3759 episodes, mean reward 5.242, speed 59.67 f/s\n","587040: done 3760 episodes, mean reward 5.173, speed 59.61 f/s\n","587170: done 3761 episodes, mean reward 5.056, speed 57.32 f/s\n","588170: done 3762 episodes, mean reward 5.164, speed 60.18 f/s\n","588239: done 3763 episodes, mean reward 5.161, speed 53.39 f/s\n","588492: done 3764 episodes, mean reward 5.164, speed 58.10 f/s\n","589119: done 3765 episodes, mean reward 5.129, speed 60.11 f/s\n","589384: done 3766 episodes, mean reward 5.131, speed 58.38 f/s\n","589850: done 3767 episodes, mean reward 5.183, speed 60.07 f/s\n","EEEE tensor(-8.1058, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5381, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 29.04 sec, reward 5.960, steps 516\n","590080: done 3768 episodes, mean reward 5.180, speed 6.98 f/s\n","590315: done 3769 episodes, mean reward 5.057, speed 58.66 f/s\n","590422: done 3770 episodes, mean reward 5.061, speed 56.02 f/s\n","590518: done 3771 episodes, mean reward 4.957, speed 56.48 f/s\n","591066: done 3772 episodes, mean reward 4.982, speed 60.15 f/s\n","591437: done 3773 episodes, mean reward 4.993, speed 59.60 f/s\n","591918: done 3774 episodes, mean reward 4.886, speed 60.26 f/s\n","591975: done 3775 episodes, mean reward 4.876, speed 52.56 f/s\n","592317: done 3776 episodes, mean reward 4.903, speed 58.73 f/s\n","593317: done 3777 episodes, mean reward 4.965, speed 60.31 f/s\n","593529: done 3778 episodes, mean reward 4.975, speed 58.31 f/s\n","593677: done 3779 episodes, mean reward 4.972, speed 57.52 f/s\n","594003: done 3780 episodes, mean reward 5.007, speed 59.20 f/s\n","594169: done 3781 episodes, mean reward 5.014, speed 58.30 f/s\n","594470: done 3782 episodes, mean reward 5.038, speed 59.39 f/s\n","595385: done 3783 episodes, mean reward 5.159, speed 60.27 f/s\n","595657: done 3784 episodes, mean reward 5.147, speed 57.77 f/s\n","595753: done 3785 episodes, mean reward 5.146, speed 56.04 f/s\n","596753: done 3786 episodes, mean reward 5.190, speed 60.79 f/s\n","596808: done 3787 episodes, mean reward 5.153, speed 52.20 f/s\n","597105: done 3788 episodes, mean reward 5.159, speed 58.47 f/s\n","597362: done 3789 episodes, mean reward 5.115, speed 57.95 f/s\n","597540: done 3790 episodes, mean reward 4.983, speed 58.02 f/s\n","598081: done 3791 episodes, mean reward 5.043, speed 60.05 f/s\n","598557: done 3792 episodes, mean reward 5.062, speed 60.53 f/s\n","598924: done 3793 episodes, mean reward 4.952, speed 59.44 f/s\n","599448: done 3794 episodes, mean reward 4.979, speed 60.32 f/s\n","599643: done 3795 episodes, mean reward 4.981, speed 58.10 f/s\n","599964: done 3796 episodes, mean reward 4.962, speed 59.36 f/s\n","EEEE tensor(-8.4192, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5317, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 29.65 sec, reward 5.250, steps 521\n","600187: done 3797 episodes, mean reward 4.875, speed 6.66 f/s\n","600508: done 3798 episodes, mean reward 4.874, speed 58.41 f/s\n","600700: done 3799 episodes, mean reward 4.847, speed 58.56 f/s\n","600925: done 3800 episodes, mean reward 4.844, speed 58.23 f/s\n","601147: done 3801 episodes, mean reward 4.838, speed 58.56 f/s\n","601335: done 3802 episodes, mean reward 4.852, speed 58.74 f/s\n","601510: done 3803 episodes, mean reward 4.857, speed 56.74 f/s\n","602193: done 3805 episodes, mean reward 4.870, speed 59.36 f/s\n","602404: done 3806 episodes, mean reward 4.763, speed 58.36 f/s\n","602601: done 3807 episodes, mean reward 4.724, speed 57.55 f/s\n","602716: done 3808 episodes, mean reward 4.717, speed 56.33 f/s\n","603366: done 3809 episodes, mean reward 4.678, speed 59.94 f/s\n","603748: done 3810 episodes, mean reward 4.719, speed 59.49 f/s\n","604105: done 3811 episodes, mean reward 4.602, speed 58.83 f/s\n","604285: done 3812 episodes, mean reward 4.497, speed 57.56 f/s\n","604646: done 3813 episodes, mean reward 4.483, speed 59.51 f/s\n","604781: done 3814 episodes, mean reward 4.332, speed 56.50 f/s\n","605781: done 3815 episodes, mean reward 4.298, speed 60.18 f/s\n","606141: done 3816 episodes, mean reward 4.318, speed 59.35 f/s\n","606551: done 3817 episodes, mean reward 4.349, speed 60.24 f/s\n","607059: done 3818 episodes, mean reward 4.378, speed 60.44 f/s\n","608028: done 3819 episodes, mean reward 4.476, speed 60.49 f/s\n","608123: done 3820 episodes, mean reward 4.339, speed 55.70 f/s\n","608246: done 3821 episodes, mean reward 4.293, speed 56.88 f/s\n","608842: done 3823 episodes, mean reward 4.198, speed 59.44 f/s\n","608922: done 3824 episodes, mean reward 4.192, speed 53.67 f/s\n","609148: done 3825 episodes, mean reward 4.203, speed 58.69 f/s\n","609237: done 3826 episodes, mean reward 4.146, speed 54.86 f/s\n","609820: done 3827 episodes, mean reward 4.155, speed 58.65 f/s\n","609981: done 3828 episodes, mean reward 4.090, speed 56.87 f/s\n","EEEE tensor(-7.6328, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5381, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 22.90 sec, reward 4.700, steps 402\n","610165: done 3829 episodes, mean reward 4.030, speed 7.05 f/s\n","610507: done 3830 episodes, mean reward 4.048, speed 59.17 f/s\n","610827: done 3831 episodes, mean reward 4.054, speed 59.16 f/s\n","611023: done 3832 episodes, mean reward 4.045, speed 57.99 f/s\n","611361: done 3834 episodes, mean reward 3.821, speed 57.12 f/s\n","611829: done 3835 episodes, mean reward 3.745, speed 59.59 f/s\n","611959: done 3836 episodes, mean reward 3.623, speed 56.77 f/s\n","612233: done 3837 episodes, mean reward 3.638, speed 58.79 f/s\n","613233: done 3838 episodes, mean reward 3.691, speed 60.32 f/s\n","613328: done 3839 episodes, mean reward 3.687, speed 55.72 f/s\n","613513: done 3840 episodes, mean reward 3.580, speed 58.26 f/s\n","614513: done 3841 episodes, mean reward 3.591, speed 60.23 f/s\n","614618: done 3842 episodes, mean reward 3.495, speed 56.16 f/s\n","615521: done 3843 episodes, mean reward 3.584, speed 60.02 f/s\n","615703: done 3844 episodes, mean reward 3.568, speed 57.59 f/s\n","615900: done 3845 episodes, mean reward 3.557, speed 57.97 f/s\n","616115: done 3846 episodes, mean reward 3.526, speed 57.05 f/s\n","617115: done 3847 episodes, mean reward 3.617, speed 60.23 f/s\n","617475: done 3849 episodes, mean reward 3.529, speed 57.84 f/s\n","618475: done 3850 episodes, mean reward 3.642, speed 59.95 f/s\n","618545: done 3851 episodes, mean reward 3.614, speed 52.72 f/s\n","619070: done 3852 episodes, mean reward 3.629, speed 58.30 f/s\n","619689: done 3853 episodes, mean reward 3.721, speed 59.61 f/s\n","EEEE tensor(-7.9631, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5242, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 21.38 sec, reward 4.655, steps 368\n","620266: done 3854 episodes, mean reward 3.800, speed 18.58 f/s\n","620532: done 3855 episodes, mean reward 3.713, speed 58.71 f/s\n","621532: done 3856 episodes, mean reward 3.838, speed 60.04 f/s\n","622132: done 3857 episodes, mean reward 3.833, speed 59.14 f/s\n","622521: done 3858 episodes, mean reward 3.759, speed 58.58 f/s\n","622644: done 3859 episodes, mean reward 3.738, speed 55.92 f/s\n","623644: done 3860 episodes, mean reward 3.817, speed 60.08 f/s\n","624644: done 3861 episodes, mean reward 3.950, speed 60.57 f/s\n","625043: done 3862 episodes, mean reward 3.869, speed 59.11 f/s\n","625934: done 3863 episodes, mean reward 4.010, speed 59.87 f/s\n","626758: done 3864 episodes, mean reward 4.077, speed 59.36 f/s\n","627192: done 3865 episodes, mean reward 4.068, speed 59.25 f/s\n","627923: done 3866 episodes, mean reward 4.115, speed 59.76 f/s\n","628024: done 3867 episodes, mean reward 4.067, speed 56.19 f/s\n","629024: done 3868 episodes, mean reward 4.198, speed 60.29 f/s\n","629104: done 3869 episodes, mean reward 4.180, speed 54.67 f/s\n","629525: done 3870 episodes, mean reward 4.230, speed 58.81 f/s\n","629741: done 3871 episodes, mean reward 4.248, speed 57.84 f/s\n","EEEE tensor(-7.8626, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5148, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 24.05 sec, reward 5.220, steps 411\n","630453: done 3872 episodes, mean reward 4.305, speed 19.82 f/s\n","631453: done 3873 episodes, mean reward 4.430, speed 60.64 f/s\n","631862: done 3874 episodes, mean reward 4.431, speed 59.36 f/s\n","632298: done 3875 episodes, mean reward 4.472, speed 59.15 f/s\n","632416: done 3876 episodes, mean reward 4.447, speed 54.41 f/s\n","632605: done 3877 episodes, mean reward 4.359, speed 57.88 f/s\n","633605: done 3878 episodes, mean reward 4.486, speed 60.02 f/s\n","634087: done 3879 episodes, mean reward 4.549, speed 59.49 f/s\n","634237: done 3880 episodes, mean reward 4.520, speed 57.13 f/s\n","634488: done 3881 episodes, mean reward 4.524, speed 57.85 f/s\n","634986: done 3882 episodes, mean reward 4.551, speed 59.30 f/s\n","635447: done 3883 episodes, mean reward 4.476, speed 58.91 f/s\n","635568: done 3884 episodes, mean reward 4.466, speed 55.55 f/s\n","635857: done 3885 episodes, mean reward 4.488, speed 57.41 f/s\n","636285: done 3886 episodes, mean reward 4.423, speed 59.14 f/s\n","636403: done 3887 episodes, mean reward 4.430, speed 56.22 f/s\n","636536: done 3888 episodes, mean reward 4.420, speed 56.89 f/s\n","637536: done 3889 episodes, mean reward 4.537, speed 59.53 f/s\n","637742: done 3890 episodes, mean reward 4.538, speed 58.22 f/s\n","638343: done 3891 episodes, mean reward 4.528, speed 59.82 f/s\n","638469: done 3892 episodes, mean reward 4.483, speed 56.83 f/s\n","638989: done 3893 episodes, mean reward 4.489, speed 59.09 f/s\n","639183: done 3894 episodes, mean reward 4.465, speed 57.70 f/s\n","639552: done 3895 episodes, mean reward 4.494, speed 58.85 f/s\n","639723: done 3896 episodes, mean reward 4.480, speed 57.68 f/s\n","EEEE tensor(-9.6826, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4974, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 39.83 sec, reward 9.102, steps 710\n","640240: done 3897 episodes, mean reward 4.534, speed 10.65 f/s\n","640546: done 3898 episodes, mean reward 4.533, speed 58.97 f/s\n","640846: done 3899 episodes, mean reward 4.546, speed 57.92 f/s\n","641846: done 3900 episodes, mean reward 4.644, speed 59.60 f/s\n","641965: done 3901 episodes, mean reward 4.633, speed 55.74 f/s\n","642800: done 3902 episodes, mean reward 4.736, speed 60.14 f/s\n","643417: done 3903 episodes, mean reward 4.797, speed 59.48 f/s\n","643544: done 3904 episodes, mean reward 4.805, speed 56.15 f/s\n","644544: done 3905 episodes, mean reward 4.868, speed 60.68 f/s\n","644750: done 3906 episodes, mean reward 4.867, speed 58.75 f/s\n","645619: done 3907 episodes, mean reward 4.975, speed 59.91 f/s\n","645683: done 3908 episodes, mean reward 4.973, speed 53.53 f/s\n","646361: done 3909 episodes, mean reward 4.944, speed 59.20 f/s\n","646667: done 3910 episodes, mean reward 4.935, speed 58.60 f/s\n","647253: done 3911 episodes, mean reward 4.997, speed 59.26 f/s\n","647722: done 3912 episodes, mean reward 5.029, speed 59.38 f/s\n","648109: done 3913 episodes, mean reward 5.017, speed 58.98 f/s\n","649109: done 3914 episodes, mean reward 5.147, speed 60.15 f/s\n","649456: done 3915 episodes, mean reward 5.060, speed 58.98 f/s\n","EEEE tensor(-7.6994, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5006, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 20.30 sec, reward 3.450, steps 346\n","650456: done 3916 episodes, mean reward 5.170, speed 26.96 f/s\n","650927: done 3917 episodes, mean reward 5.162, speed 59.31 f/s\n","651054: done 3918 episodes, mean reward 5.123, speed 56.96 f/s\n","651440: done 3919 episodes, mean reward 5.052, speed 59.85 f/s\n","652440: done 3920 episodes, mean reward 5.205, speed 60.20 f/s\n","653312: done 3921 episodes, mean reward 5.314, speed 59.92 f/s\n","654312: done 3922 episodes, mean reward 5.448, speed 60.11 f/s\n","654496: done 3923 episodes, mean reward 5.389, speed 57.70 f/s\n","655395: done 3924 episodes, mean reward 5.506, speed 59.66 f/s\n","655717: done 3925 episodes, mean reward 5.523, speed 59.12 f/s\n","656109: done 3927 episodes, mean reward 5.504, speed 58.49 f/s\n","656899: done 3928 episodes, mean reward 5.597, speed 60.30 f/s\n","657071: done 3929 episodes, mean reward 5.588, speed 58.26 f/s\n","657555: done 3930 episodes, mean reward 5.612, speed 59.46 f/s\n","658050: done 3931 episodes, mean reward 5.614, speed 59.18 f/s\n","659050: done 3932 episodes, mean reward 5.751, speed 60.04 f/s\n","659510: done 3933 episodes, mean reward 5.784, speed 58.93 f/s\n","EEEE tensor(-8.3570, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4908, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 28.87 sec, reward 5.784, steps 506\n","660050: done 3934 episodes, mean reward 5.807, speed 14.21 f/s\n","660377: done 3935 episodes, mean reward 5.789, speed 59.03 f/s\n","661425: done 3937 episodes, mean reward 5.894, speed 59.75 f/s\n","661854: done 3938 episodes, mean reward 5.824, speed 59.35 f/s\n","662344: done 3939 episodes, mean reward 5.877, speed 58.59 f/s\n","662811: done 3940 episodes, mean reward 5.926, speed 59.68 f/s\n","663803: done 3941 episodes, mean reward 5.903, speed 60.23 f/s\n","664561: done 3942 episodes, mean reward 5.988, speed 60.12 f/s\n","665561: done 3943 episodes, mean reward 6.014, speed 59.99 f/s\n","665643: done 3944 episodes, mean reward 6.005, speed 54.57 f/s\n","666444: done 3945 episodes, mean reward 6.081, speed 59.75 f/s\n","667444: done 3946 episodes, mean reward 6.204, speed 59.35 f/s\n","668444: done 3947 episodes, mean reward 6.200, speed 59.20 f/s\n","669444: done 3948 episodes, mean reward 6.326, speed 59.74 f/s\n","669559: done 3949 episodes, mean reward 6.293, speed 56.41 f/s\n","669829: done 3950 episodes, mean reward 6.182, speed 58.47 f/s\n","EEEE tensor(-7.1588, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4764, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 30.94 sec, reward 6.312, steps 540\n","670829: done 3951 episodes, mean reward 6.303, speed 20.96 f/s\n","671829: done 3952 episodes, mean reward 6.351, speed 60.24 f/s\n","672829: done 3953 episodes, mean reward 6.415, speed 60.79 f/s\n","672911: done 3954 episodes, mean reward 6.327, speed 55.21 f/s\n","673911: done 3955 episodes, mean reward 6.415, speed 60.72 f/s\n","674911: done 3956 episodes, mean reward 6.387, speed 60.45 f/s\n","674988: done 3957 episodes, mean reward 6.303, speed 54.55 f/s\n","675504: done 3958 episodes, mean reward 6.323, speed 58.25 f/s\n","675734: done 3959 episodes, mean reward 6.338, speed 56.90 f/s\n","676047: done 3960 episodes, mean reward 6.271, speed 58.78 f/s\n","677047: done 3961 episodes, mean reward 6.254, speed 59.43 f/s\n","677295: done 3962 episodes, mean reward 6.238, speed 58.53 f/s\n","677366: done 3963 episodes, mean reward 6.096, speed 53.96 f/s\n","677486: done 3964 episodes, mean reward 6.022, speed 56.87 f/s\n","678364: done 3965 episodes, mean reward 6.056, speed 59.28 f/s\n","678546: done 3966 episodes, mean reward 5.997, speed 56.57 f/s\n","679202: done 3967 episodes, mean reward 6.074, speed 59.16 f/s\n","679915: done 3968 episodes, mean reward 6.033, speed 56.69 f/s\n","EEEE tensor(-7.3965, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4624, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 32.28 sec, reward 6.631, steps 553\n","680591: done 3969 episodes, mean reward 6.110, speed 15.42 f/s\n","681296: done 3970 episodes, mean reward 6.114, speed 58.74 f/s\n","682296: done 3971 episodes, mean reward 6.224, speed 59.05 f/s\n","683296: done 3972 episodes, mean reward 6.274, speed 59.39 f/s\n","683573: done 3973 episodes, mean reward 6.143, speed 58.24 f/s\n","684573: done 3974 episodes, mean reward 6.230, speed 59.86 f/s\n","685573: done 3975 episodes, mean reward 6.296, speed 59.84 f/s\n","686227: done 3976 episodes, mean reward 6.368, speed 59.26 f/s\n","686308: done 3977 episodes, mean reward 6.352, speed 54.47 f/s\n","687308: done 3978 episodes, mean reward 6.346, speed 59.65 f/s\n","687419: done 3979 episodes, mean reward 6.280, speed 56.75 f/s\n","687734: done 3980 episodes, mean reward 6.296, speed 58.92 f/s\n","688065: done 3981 episodes, mean reward 6.314, speed 58.77 f/s\n","688567: done 3982 episodes, mean reward 6.307, speed 58.78 f/s\n","688678: done 3983 episodes, mean reward 6.268, speed 56.74 f/s\n","689149: done 3984 episodes, mean reward 6.315, speed 59.45 f/s\n","EEEE tensor(-7.4556, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4782, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 41.60 sec, reward 9.229, steps 734\n","690149: done 3985 episodes, mean reward 6.377, speed 17.15 f/s\n","690448: done 3986 episodes, mean reward 6.353, speed 58.25 f/s\n","691448: done 3987 episodes, mean reward 6.446, speed 60.25 f/s\n","691553: done 3988 episodes, mean reward 6.439, speed 56.48 f/s\n","691721: done 3989 episodes, mean reward 6.305, speed 57.84 f/s\n","692089: done 3990 episodes, mean reward 6.337, speed 59.59 f/s\n","693088: done 3991 episodes, mean reward 6.413, speed 60.37 f/s\n","693892: done 3992 episodes, mean reward 6.509, speed 60.23 f/s\n","694892: done 3993 episodes, mean reward 6.603, speed 59.97 f/s\n","695084: done 3994 episodes, mean reward 6.604, speed 57.64 f/s\n","696084: done 3995 episodes, mean reward 6.692, speed 60.08 f/s\n","696434: done 3996 episodes, mean reward 6.726, speed 58.93 f/s\n","697434: done 3997 episodes, mean reward 6.754, speed 60.30 f/s\n","698089: done 3998 episodes, mean reward 6.793, speed 59.52 f/s\n","698872: done 3999 episodes, mean reward 6.864, speed 60.16 f/s\n","699569: done 4000 episodes, mean reward 6.833, speed 60.31 f/s\n","EEEE tensor(-7.9006, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4576, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 40.53 sec, reward 7.576, steps 719\n","700080: done 4001 episodes, mean reward 6.873, speed 10.40 f/s\n","700526: done 4002 episodes, mean reward 6.802, speed 59.94 f/s\n","701080: done 4003 episodes, mean reward 6.793, speed 59.57 f/s\n","701697: done 4004 episodes, mean reward 6.847, speed 59.74 f/s\n","702292: done 4005 episodes, mean reward 6.790, speed 59.02 f/s\n","702959: done 4006 episodes, mean reward 6.817, speed 60.32 f/s\n","703345: done 4007 episodes, mean reward 6.741, speed 59.56 f/s\n","704035: done 4008 episodes, mean reward 6.819, speed 60.58 f/s\n","704368: done 4009 episodes, mean reward 6.802, speed 59.95 f/s\n","705368: done 4010 episodes, mean reward 6.891, speed 60.23 f/s\n","706368: done 4011 episodes, mean reward 6.935, speed 60.77 f/s\n","706678: done 4012 episodes, mean reward 6.912, speed 59.31 f/s\n","707678: done 4013 episodes, mean reward 6.957, speed 59.99 f/s\n","708543: done 4014 episodes, mean reward 6.922, speed 60.49 f/s\n","709134: done 4015 episodes, mean reward 6.959, speed 59.98 f/s\n","EEEE tensor(-7.5913, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4884, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 22.15 sec, reward 3.047, steps 379\n","710074: done 4016 episodes, mean reward 6.937, speed 24.93 f/s\n","710231: done 4017 episodes, mean reward 6.909, speed 57.90 f/s\n","710515: done 4018 episodes, mean reward 6.930, speed 58.62 f/s\n","710677: done 4019 episodes, mean reward 6.888, speed 57.47 f/s\n","711013: done 4020 episodes, mean reward 6.765, speed 58.63 f/s\n","711420: done 4021 episodes, mean reward 6.690, speed 59.49 f/s\n","711533: done 4022 episodes, mean reward 6.560, speed 56.36 f/s\n","711940: done 4023 episodes, mean reward 6.572, speed 59.26 f/s\n","712759: done 4024 episodes, mean reward 6.518, speed 59.57 f/s\n","713129: done 4025 episodes, mean reward 6.512, speed 59.70 f/s\n","713322: done 4026 episodes, mean reward 6.529, speed 57.50 f/s\n","714322: done 4027 episodes, mean reward 6.593, speed 60.82 f/s\n","715322: done 4028 episodes, mean reward 6.598, speed 60.11 f/s\n","715699: done 4029 episodes, mean reward 6.631, speed 59.20 f/s\n","715992: done 4030 episodes, mean reward 6.616, speed 59.26 f/s\n","716512: done 4031 episodes, mean reward 6.633, speed 59.27 f/s\n","717512: done 4032 episodes, mean reward 6.562, speed 60.24 f/s\n","718424: done 4033 episodes, mean reward 6.632, speed 60.28 f/s\n","718492: done 4034 episodes, mean reward 6.578, speed 54.23 f/s\n","718721: done 4035 episodes, mean reward 6.575, speed 59.33 f/s\n","719558: done 4036 episodes, mean reward 6.680, speed 60.59 f/s\n","719815: done 4037 episodes, mean reward 6.577, speed 58.77 f/s\n","719914: done 4038 episodes, mean reward 6.524, speed 56.45 f/s\n","EEEE tensor(-7.2150, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4539, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 30.83 sec, reward 4.912, steps 542\n","720308: done 4039 episodes, mean reward 6.509, speed 10.52 f/s\n","720454: done 4040 episodes, mean reward 6.453, speed 57.31 f/s\n","720784: done 4041 episodes, mean reward 6.369, speed 59.20 f/s\n","721784: done 4042 episodes, mean reward 6.400, speed 60.42 f/s\n","722410: done 4043 episodes, mean reward 6.311, speed 59.98 f/s\n","722482: done 4044 episodes, mean reward 6.315, speed 53.86 f/s\n","722975: done 4045 episodes, mean reward 6.284, speed 59.74 f/s\n","723346: done 4047 episodes, mean reward 6.052, speed 57.09 f/s\n","723782: done 4048 episodes, mean reward 5.966, speed 59.18 f/s\n","723986: done 4049 episodes, mean reward 5.970, speed 58.58 f/s\n","724629: done 4050 episodes, mean reward 6.004, speed 59.53 f/s\n","724870: done 4051 episodes, mean reward 5.892, speed 58.53 f/s\n","725297: done 4052 episodes, mean reward 5.829, speed 59.86 f/s\n","725466: done 4053 episodes, mean reward 5.687, speed 57.43 f/s\n","725841: done 4054 episodes, mean reward 5.721, speed 59.89 f/s\n","726841: done 4055 episodes, mean reward 5.732, speed 60.61 f/s\n","727226: done 4056 episodes, mean reward 5.647, speed 59.28 f/s\n","727498: done 4057 episodes, mean reward 5.672, speed 58.92 f/s\n","727628: done 4058 episodes, mean reward 5.613, speed 57.19 f/s\n","728608: done 4059 episodes, mean reward 5.660, speed 59.77 f/s\n","729608: done 4060 episodes, mean reward 5.675, speed 60.06 f/s\n","EEEE tensor(-8.9088, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4870, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 25.40 sec, reward 3.719, steps 442\n","730034: done 4061 episodes, mean reward 5.601, speed 13.09 f/s\n","730329: done 4062 episodes, mean reward 5.615, speed 59.41 f/s\n","730513: done 4063 episodes, mean reward 5.627, speed 57.77 f/s\n","730768: done 4064 episodes, mean reward 5.648, speed 58.93 f/s\n","731031: done 4065 episodes, mean reward 5.588, speed 59.50 f/s\n","731432: done 4066 episodes, mean reward 5.620, speed 58.99 f/s\n","731552: done 4067 episodes, mean reward 5.539, speed 55.95 f/s\n","731735: done 4068 episodes, mean reward 5.457, speed 58.04 f/s\n","732404: done 4069 episodes, mean reward 5.441, speed 60.13 f/s\n","732574: done 4070 episodes, mean reward 5.396, speed 57.88 f/s\n","732917: done 4071 episodes, mean reward 5.289, speed 59.59 f/s\n","733846: done 4072 episodes, mean reward 5.172, speed 60.66 f/s\n","734144: done 4073 episodes, mean reward 5.168, speed 59.23 f/s\n","734737: done 4074 episodes, mean reward 5.112, speed 59.85 f/s\n","735515: done 4075 episodes, mean reward 5.087, speed 60.50 f/s\n","736041: done 4076 episodes, mean reward 5.055, speed 59.96 f/s\n","736620: done 4077 episodes, mean reward 5.101, speed 59.18 f/s\n","737036: done 4078 episodes, mean reward 5.004, speed 59.50 f/s\n","737674: done 4079 episodes, mean reward 5.035, speed 60.24 f/s\n","737776: done 4080 episodes, mean reward 5.017, speed 55.89 f/s\n","738213: done 4081 episodes, mean reward 5.038, speed 59.71 f/s\n","738425: done 4082 episodes, mean reward 5.014, speed 58.49 f/s\n","739425: done 4083 episodes, mean reward 5.136, speed 60.74 f/s\n","EEEE tensor(-8.6005, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4492, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 29.22 sec, reward 5.513, steps 511\n","740334: done 4084 episodes, mean reward 5.206, speed 20.49 f/s\n","741013: done 4085 episodes, mean reward 5.156, speed 60.10 f/s\n","741383: done 4086 episodes, mean reward 5.169, speed 59.66 f/s\n","742030: done 4087 episodes, mean reward 5.136, speed 59.58 f/s\n","742165: done 4088 episodes, mean reward 5.144, speed 57.21 f/s\n","742541: done 4089 episodes, mean reward 5.182, speed 59.66 f/s\n","742808: done 4090 episodes, mean reward 5.166, speed 59.07 f/s\n","743634: done 4091 episodes, mean reward 5.142, speed 60.55 f/s\n","744066: done 4092 episodes, mean reward 5.096, speed 59.69 f/s\n","744281: done 4093 episodes, mean reward 4.990, speed 57.64 f/s\n","745038: done 4094 episodes, mean reward 5.023, speed 59.93 f/s\n","746038: done 4095 episodes, mean reward 5.007, speed 60.47 f/s\n","746463: done 4096 episodes, mean reward 5.008, speed 59.87 f/s\n","747003: done 4097 episodes, mean reward 4.966, speed 60.12 f/s\n","747644: done 4098 episodes, mean reward 4.969, speed 60.54 f/s\n","748644: done 4099 episodes, mean reward 4.999, speed 60.70 f/s\n","749320: done 4100 episodes, mean reward 5.002, speed 59.77 f/s\n","EEEE tensor(-8.6256, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4671, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 31.72 sec, reward 6.323, steps 564\n","750320: done 4101 episodes, mean reward 5.042, speed 20.75 f/s\n","751320: done 4102 episodes, mean reward 5.101, speed 60.21 f/s\n","751737: done 4103 episodes, mean reward 5.101, speed 59.98 f/s\n","751894: done 4104 episodes, mean reward 5.053, speed 57.32 f/s\n","752582: done 4105 episodes, mean reward 5.063, speed 59.78 f/s\n","752902: done 4106 episodes, mean reward 5.053, speed 59.19 f/s\n","753484: done 4107 episodes, mean reward 5.089, speed 59.88 f/s\n","754143: done 4108 episodes, mean reward 5.087, speed 60.58 f/s\n","754793: done 4109 episodes, mean reward 5.138, speed 60.12 f/s\n","755028: done 4110 episodes, mean reward 5.040, speed 58.39 f/s\n","755489: done 4111 episodes, mean reward 4.970, speed 59.93 f/s\n","755808: done 4112 episodes, mean reward 4.978, speed 59.32 f/s\n","756021: done 4113 episodes, mean reward 4.931, speed 58.77 f/s\n","756311: done 4114 episodes, mean reward 4.857, speed 58.86 f/s\n","756517: done 4115 episodes, mean reward 4.819, speed 58.77 f/s\n","756592: done 4116 episodes, mean reward 4.712, speed 54.07 f/s\n","756683: done 4117 episodes, mean reward 4.712, speed 54.90 f/s\n","757683: done 4118 episodes, mean reward 4.797, speed 60.34 f/s\n","758506: done 4119 episodes, mean reward 4.875, speed 60.69 f/s\n","758716: done 4120 episodes, mean reward 4.855, speed 58.30 f/s\n","759057: done 4121 episodes, mean reward 4.848, speed 59.52 f/s\n","EEEE tensor(-7.7589, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4867, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 31.75 sec, reward 6.283, steps 560\n","760057: done 4122 episodes, mean reward 4.979, speed 20.69 f/s\n","760183: done 4123 episodes, mean reward 4.957, speed 55.90 f/s\n","761183: done 4124 episodes, mean reward 4.991, speed 60.01 f/s\n","762183: done 4125 episodes, mean reward 5.030, speed 61.02 f/s\n","762633: done 4126 episodes, mean reward 5.067, speed 60.01 f/s\n","762908: done 4127 episodes, mean reward 4.987, speed 59.51 f/s\n","763527: done 4128 episodes, mean reward 4.939, speed 59.81 f/s\n","764455: done 4129 episodes, mean reward 4.996, speed 60.54 f/s\n","765113: done 4130 episodes, mean reward 5.035, speed 59.76 f/s\n","765960: done 4131 episodes, mean reward 5.066, speed 60.79 f/s\n","766041: done 4132 episodes, mean reward 4.991, speed 54.76 f/s\n","767041: done 4133 episodes, mean reward 4.965, speed 60.49 f/s\n","767263: done 4134 episodes, mean reward 4.990, speed 58.62 f/s\n","767356: done 4135 episodes, mean reward 4.978, speed 56.03 f/s\n","767734: done 4136 episodes, mean reward 4.919, speed 59.53 f/s\n","768494: done 4137 episodes, mean reward 4.950, speed 60.34 f/s\n","769494: done 4138 episodes, mean reward 5.049, speed 60.48 f/s\n","769771: done 4139 episodes, mean reward 5.024, speed 58.62 f/s\n","EEEE tensor(-7.5988, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4681, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 33.28 sec, reward 5.727, steps 593\n","770052: done 4140 episodes, mean reward 5.036, speed 7.38 f/s\n","770381: done 4141 episodes, mean reward 5.034, speed 59.56 f/s\n","771075: done 4142 episodes, mean reward 4.982, speed 60.50 f/s\n","771515: done 4143 episodes, mean reward 4.975, speed 59.72 f/s\n","771962: done 4144 episodes, mean reward 4.998, speed 59.43 f/s\n","772962: done 4145 episodes, mean reward 5.053, speed 60.04 f/s\n","773743: done 4146 episodes, mean reward 5.127, speed 60.76 f/s\n","774328: done 4147 episodes, mean reward 5.136, speed 60.37 f/s\n","774520: done 4148 episodes, mean reward 5.114, speed 58.88 f/s\n","774765: done 4149 episodes, mean reward 5.124, speed 59.38 f/s\n","775021: done 4150 episodes, mean reward 5.088, speed 59.26 f/s\n","775705: done 4151 episodes, mean reward 5.136, speed 60.43 f/s\n","775883: done 4152 episodes, mean reward 5.108, speed 57.84 f/s\n","776125: done 4153 episodes, mean reward 5.119, speed 58.06 f/s\n","776452: done 4154 episodes, mean reward 5.117, speed 57.77 f/s\n","776825: done 4155 episodes, mean reward 5.027, speed 59.89 f/s\n","777332: done 4157 episodes, mean reward 5.016, speed 58.95 f/s\n","777581: done 4158 episodes, mean reward 5.024, speed 58.81 f/s\n","778056: done 4159 episodes, mean reward 5.012, speed 60.20 f/s\n","778558: done 4160 episodes, mean reward 5.000, speed 60.66 f/s\n","779195: done 4161 episodes, mean reward 5.008, speed 60.30 f/s\n","EEEE tensor(-7.9252, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4718, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 30.88 sec, reward 4.630, steps 543\n","780195: done 4162 episodes, mean reward 5.040, speed 21.10 f/s\n","781195: done 4163 episodes, mean reward 5.152, speed 60.34 f/s\n","781559: done 4164 episodes, mean reward 5.161, speed 59.11 f/s\n","781634: done 4165 episodes, mean reward 5.133, speed 54.50 f/s\n","782634: done 4166 episodes, mean reward 5.212, speed 60.53 f/s\n","782810: done 4167 episodes, mean reward 5.215, speed 58.46 f/s\n","782963: done 4168 episodes, mean reward 5.209, speed 57.81 f/s\n","783171: done 4169 episodes, mean reward 5.156, speed 58.62 f/s\n","783433: done 4170 episodes, mean reward 5.156, speed 58.97 f/s\n","783709: done 4171 episodes, mean reward 5.158, speed 59.18 f/s\n","783828: done 4172 episodes, mean reward 5.129, speed 57.49 f/s\n","784052: done 4173 episodes, mean reward 5.131, speed 59.16 f/s\n","785052: done 4174 episodes, mean reward 5.162, speed 60.16 f/s\n","785734: done 4175 episodes, mean reward 5.142, speed 60.17 f/s\n","786193: done 4176 episodes, mean reward 5.140, speed 60.01 f/s\n","786584: done 4177 episodes, mean reward 5.126, speed 59.90 f/s\n","786736: done 4178 episodes, mean reward 5.101, speed 57.96 f/s\n","787736: done 4179 episodes, mean reward 5.151, speed 60.91 f/s\n","787903: done 4180 episodes, mean reward 5.160, speed 58.43 f/s\n","788114: done 4181 episodes, mean reward 5.117, speed 59.06 f/s\n","788789: done 4182 episodes, mean reward 5.164, speed 60.42 f/s\n","788948: done 4183 episodes, mean reward 5.042, speed 56.82 f/s\n","789217: done 4184 episodes, mean reward 4.949, speed 57.64 f/s\n","789382: done 4185 episodes, mean reward 4.924, speed 58.24 f/s\n","789633: done 4186 episodes, mean reward 4.909, speed 58.10 f/s\n","EEEE tensor(-7.0740, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4896, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 30.78 sec, reward 5.149, steps 543\n","790622: done 4187 episodes, mean reward 4.938, speed 20.97 f/s\n","790776: done 4188 episodes, mean reward 4.933, speed 57.60 f/s\n","791247: done 4189 episodes, mean reward 4.941, speed 59.41 f/s\n","791739: done 4190 episodes, mean reward 4.970, speed 60.12 f/s\n","791872: done 4191 episodes, mean reward 4.873, speed 57.20 f/s\n","792012: done 4192 episodes, mean reward 4.823, speed 56.48 f/s\n","792186: done 4193 episodes, mean reward 4.816, speed 58.19 f/s\n","792354: done 4194 episodes, mean reward 4.778, speed 58.21 f/s\n","792872: done 4195 episodes, mean reward 4.710, speed 59.66 f/s\n","793064: done 4196 episodes, mean reward 4.670, speed 58.19 f/s\n","793509: done 4197 episodes, mean reward 4.645, speed 59.75 f/s\n","793686: done 4198 episodes, mean reward 4.601, speed 58.02 f/s\n","793974: done 4199 episodes, mean reward 4.506, speed 59.38 f/s\n","794274: done 4200 episodes, mean reward 4.457, speed 59.22 f/s\n","795274: done 4201 episodes, mean reward 4.458, speed 60.15 f/s\n","796301: done 4203 episodes, mean reward 4.390, speed 59.78 f/s\n","796633: done 4204 episodes, mean reward 4.402, speed 59.49 f/s\n","797148: done 4205 episodes, mean reward 4.384, speed 59.80 f/s\n","797312: done 4206 episodes, mean reward 4.363, speed 58.14 f/s\n","797822: done 4207 episodes, mean reward 4.356, speed 59.42 f/s\n","798051: done 4208 episodes, mean reward 4.293, speed 58.21 f/s\n","798493: done 4209 episodes, mean reward 4.251, speed 59.84 f/s\n","799493: done 4210 episodes, mean reward 4.326, speed 60.42 f/s\n","799947: done 4211 episodes, mean reward 4.321, speed 60.41 f/s\n","EEEE tensor(-8.5257, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4547, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 23.48 sec, reward 3.863, steps 410\n","800947: done 4212 episodes, mean reward 4.374, speed 24.87 f/s\n","801318: done 4213 episodes, mean reward 4.381, speed 59.08 f/s\n","801639: done 4214 episodes, mean reward 4.387, speed 59.67 f/s\n","802579: done 4215 episodes, mean reward 4.415, speed 60.48 f/s\n","802830: done 4216 episodes, mean reward 4.440, speed 58.88 f/s\n","803105: done 4217 episodes, mean reward 4.445, speed 59.11 f/s\n","803353: done 4218 episodes, mean reward 4.355, speed 59.52 f/s\n","804353: done 4219 episodes, mean reward 4.381, speed 60.64 f/s\n","804509: done 4220 episodes, mean reward 4.374, speed 55.58 f/s\n","805345: done 4221 episodes, mean reward 4.380, speed 57.19 f/s\n","805591: done 4222 episodes, mean reward 4.253, speed 56.94 f/s\n","805777: done 4223 episodes, mean reward 4.258, speed 50.76 f/s\n","806247: done 4224 episodes, mean reward 4.183, speed 54.44 f/s\n","806735: done 4225 episodes, mean reward 4.171, speed 56.95 f/s\n","806960: done 4226 episodes, mean reward 4.139, speed 53.54 f/s\n","807427: done 4227 episodes, mean reward 4.170, speed 56.15 f/s\n","807701: done 4228 episodes, mean reward 4.133, speed 54.38 f/s\n","807900: done 4229 episodes, mean reward 4.047, speed 56.43 f/s\n","807961: done 4230 episodes, mean reward 3.981, speed 51.59 f/s\n","808522: done 4231 episodes, mean reward 3.937, speed 56.25 f/s\n","808828: done 4232 episodes, mean reward 3.955, speed 57.00 f/s\n","809260: done 4233 episodes, mean reward 3.891, speed 57.88 f/s\n","809640: done 4234 episodes, mean reward 3.889, speed 57.13 f/s\n","809728: done 4235 episodes, mean reward 3.887, speed 53.62 f/s\n","EEEE tensor(-7.4465, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4613, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 19.08 sec, reward 2.511, steps 298\n","810212: done 4236 episodes, mean reward 3.895, speed 17.59 f/s\n","810389: done 4237 episodes, mean reward 3.849, speed 54.94 f/s\n","810818: done 4238 episodes, mean reward 3.790, speed 56.53 f/s\n","810889: done 4239 episodes, mean reward 3.774, speed 51.69 f/s\n","811140: done 4240 episodes, mean reward 3.768, speed 56.44 f/s\n","811382: done 4241 episodes, mean reward 3.746, speed 57.37 f/s\n","811833: done 4242 episodes, mean reward 3.707, speed 58.43 f/s\n","812444: done 4243 episodes, mean reward 3.714, speed 58.30 f/s\n","812544: done 4245 episodes, mean reward 3.574, speed 51.02 f/s\n","812874: done 4246 episodes, mean reward 3.525, speed 58.10 f/s\n","813834: done 4247 episodes, mean reward 3.557, speed 57.73 f/s\n","813915: done 4248 episodes, mean reward 3.537, speed 52.79 f/s\n","814042: done 4249 episodes, mean reward 3.525, speed 54.62 f/s\n","814200: done 4250 episodes, mean reward 3.509, speed 55.07 f/s\n","814852: done 4251 episodes, mean reward 3.491, speed 57.99 f/s\n","814961: done 4252 episodes, mean reward 3.475, speed 55.43 f/s\n","815308: done 4254 episodes, mean reward 3.442, speed 56.72 f/s\n","815649: done 4255 episodes, mean reward 3.422, speed 57.47 f/s\n","815884: done 4256 episodes, mean reward 3.449, speed 57.62 f/s\n","816117: done 4258 episodes, mean reward 3.407, speed 55.38 f/s\n","816339: done 4259 episodes, mean reward 3.365, speed 57.03 f/s\n","816418: done 4260 episodes, mean reward 3.328, speed 52.85 f/s\n","816796: done 4261 episodes, mean reward 3.296, speed 56.46 f/s\n","816907: done 4262 episodes, mean reward 3.229, speed 54.60 f/s\n","817029: done 4263 episodes, mean reward 3.110, speed 55.52 f/s\n","817820: done 4264 episodes, mean reward 3.151, speed 58.24 f/s\n","818620: done 4266 episodes, mean reward 3.074, speed 57.54 f/s\n","818745: done 4268 episodes, mean reward 3.060, speed 51.07 f/s\n","818938: done 4269 episodes, mean reward 3.064, speed 56.21 f/s\n","819020: done 4270 episodes, mean reward 3.050, speed 53.24 f/s\n","819263: done 4272 episodes, mean reward 3.031, speed 54.62 f/s\n","819351: done 4273 episodes, mean reward 3.009, speed 51.53 f/s\n","819407: done 4274 episodes, mean reward 2.909, speed 49.86 f/s\n","819882: done 4275 episodes, mean reward 2.858, speed 57.07 f/s\n","EEEE tensor(-7.1344, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4307, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 44.05 sec, reward 4.737, steps 725\n","820180: done 4276 episodes, mean reward 2.819, speed 6.04 f/s\n","820673: done 4277 episodes, mean reward 2.817, speed 56.89 f/s\n","821346: done 4278 episodes, mean reward 2.836, speed 56.26 f/s\n","821726: done 4279 episodes, mean reward 2.770, speed 55.51 f/s\n","821779: done 4280 episodes, mean reward 2.753, speed 49.33 f/s\n","822262: done 4281 episodes, mean reward 2.775, speed 55.94 f/s\n","822332: done 4282 episodes, mean reward 2.703, speed 51.37 f/s\n","822403: done 4283 episodes, mean reward 2.696, speed 52.23 f/s\n","822701: done 4284 episodes, mean reward 2.683, speed 55.27 f/s\n","823331: done 4285 episodes, mean reward 2.709, speed 57.76 f/s\n","823735: done 4286 episodes, mean reward 2.706, speed 57.12 f/s\n","823810: done 4287 episodes, mean reward 2.610, speed 53.26 f/s\n","823880: done 4288 episodes, mean reward 2.605, speed 52.01 f/s\n","824364: done 4289 episodes, mean reward 2.571, speed 56.74 f/s\n","824619: done 4291 episodes, mean reward 2.508, speed 55.12 f/s\n","825050: done 4293 episodes, mean reward 2.515, speed 56.03 f/s\n","825114: done 4294 episodes, mean reward 2.504, speed 50.33 f/s\n","825617: done 4295 episodes, mean reward 2.506, speed 54.96 f/s\n","825690: done 4296 episodes, mean reward 2.496, speed 50.17 f/s\n","826690: done 4297 episodes, mean reward 2.527, speed 55.66 f/s\n","827219: done 4298 episodes, mean reward 2.554, speed 57.84 f/s\n","827307: done 4299 episodes, mean reward 2.526, speed 54.38 f/s\n","827408: done 4300 episodes, mean reward 2.502, speed 53.15 f/s\n","827726: done 4301 episodes, mean reward 2.444, speed 56.87 f/s\n","827817: done 4302 episodes, mean reward 2.446, speed 54.70 f/s\n","828497: done 4303 episodes, mean reward 2.377, speed 58.09 f/s\n","828720: done 4304 episodes, mean reward 2.364, speed 56.57 f/s\n","828787: done 4305 episodes, mean reward 2.314, speed 50.87 f/s\n","828867: done 4306 episodes, mean reward 2.302, speed 53.05 f/s\n","829867: done 4307 episodes, mean reward 2.316, speed 58.06 f/s\n","829935: done 4309 episodes, mean reward 2.255, speed 47.11 f/s\n","EEEE tensor(-10.1819, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4012, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 14.30 sec, reward 1.756, steps 227\n","830298: done 4310 episodes, mean reward 2.170, speed 17.63 f/s\n","830665: done 4311 episodes, mean reward 2.146, speed 57.67 f/s\n","830828: done 4312 episodes, mean reward 2.069, speed 54.64 f/s\n","831279: done 4313 episodes, mean reward 2.070, speed 57.29 f/s\n","831769: done 4314 episodes, mean reward 2.074, speed 58.61 f/s\n","831957: done 4315 episodes, mean reward 2.023, speed 56.14 f/s\n","832071: done 4316 episodes, mean reward 1.999, speed 54.69 f/s\n","832310: done 4317 episodes, mean reward 2.000, speed 57.10 f/s\n","832715: done 4318 episodes, mean reward 1.991, speed 58.17 f/s\n","833476: done 4319 episodes, mean reward 1.961, speed 58.42 f/s\n","833610: done 4320 episodes, mean reward 1.960, speed 55.71 f/s\n","833751: done 4322 episodes, mean reward 1.914, speed 52.86 f/s\n","834196: done 4324 episodes, mean reward 1.918, speed 56.17 f/s\n","834268: done 4325 episodes, mean reward 1.861, speed 53.57 f/s\n","834342: done 4326 episodes, mean reward 1.840, speed 52.95 f/s\n","834555: done 4327 episodes, mean reward 1.799, speed 56.85 f/s\n","835002: done 4328 episodes, mean reward 1.815, speed 57.89 f/s\n","835090: done 4329 episodes, mean reward 1.803, speed 55.12 f/s\n","835163: done 4330 episodes, mean reward 1.802, speed 52.48 f/s\n","836163: done 4331 episodes, mean reward 1.843, speed 58.00 f/s\n","836939: done 4332 episodes, mean reward 1.862, speed 58.09 f/s\n","837015: done 4333 episodes, mean reward 1.848, speed 52.21 f/s\n","837271: done 4334 episodes, mean reward 1.844, speed 57.33 f/s\n","837366: done 4335 episodes, mean reward 1.843, speed 52.43 f/s\n","837847: done 4336 episodes, mean reward 1.834, speed 57.98 f/s\n","838082: done 4337 episodes, mean reward 1.841, speed 56.32 f/s\n","838197: done 4338 episodes, mean reward 1.798, speed 53.77 f/s\n","838841: done 4339 episodes, mean reward 1.847, speed 57.08 f/s\n","839548: done 4341 episodes, mean reward 1.847, speed 57.21 f/s\n","839697: done 4342 episodes, mean reward 1.819, speed 55.39 f/s\n","EEEE tensor(-8.3480, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3908, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 24.26 sec, reward 3.606, steps 402\n","840147: done 4343 episodes, mean reward 1.805, speed 13.99 f/s\n","840204: done 4344 episodes, mean reward 1.805, speed 51.65 f/s\n","840275: done 4345 episodes, mean reward 1.805, speed 54.17 f/s\n","840347: done 4346 episodes, mean reward 1.781, speed 54.38 f/s\n","841233: done 4347 episodes, mean reward 1.751, speed 59.70 f/s\n","841517: done 4348 episodes, mean reward 1.777, speed 57.73 f/s\n","841960: done 4349 episodes, mean reward 1.799, speed 56.32 f/s\n","842064: done 4350 episodes, mean reward 1.791, speed 53.05 f/s\n","842247: done 4351 episodes, mean reward 1.762, speed 56.78 f/s\n","842656: done 4353 episodes, mean reward 1.785, speed 56.08 f/s\n","842754: done 4354 episodes, mean reward 1.766, speed 54.25 f/s\n","842994: done 4355 episodes, mean reward 1.764, speed 57.36 f/s\n","843834: done 4356 episodes, mean reward 1.816, speed 58.26 f/s\n","844834: done 4357 episodes, mean reward 1.919, speed 58.72 f/s\n","845239: done 4358 episodes, mean reward 1.938, speed 57.76 f/s\n","845555: done 4359 episodes, mean reward 1.959, speed 57.55 f/s\n","845762: done 4360 episodes, mean reward 1.973, speed 56.44 f/s\n","846187: done 4361 episodes, mean reward 1.985, speed 58.43 f/s\n","846465: done 4362 episodes, mean reward 2.006, speed 58.10 f/s\n","846518: done 4364 episodes, mean reward 1.921, speed 44.59 f/s\n","846594: done 4365 episodes, mean reward 1.921, speed 53.81 f/s\n","846653: done 4366 episodes, mean reward 1.870, speed 52.44 f/s\n","846853: done 4367 episodes, mean reward 1.880, speed 57.47 f/s\n","847043: done 4368 episodes, mean reward 1.882, speed 57.22 f/s\n","847582: done 4369 episodes, mean reward 1.926, speed 59.54 f/s\n","848582: done 4370 episodes, mean reward 2.011, speed 59.67 f/s\n","849484: done 4371 episodes, mean reward 2.101, speed 58.39 f/s\n","849683: done 4372 episodes, mean reward 2.102, speed 57.02 f/s\n","849761: done 4373 episodes, mean reward 2.099, speed 52.51 f/s\n","EEEE tensor(-8.1942, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3748, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 6.91 sec, reward 0.603, steps 97\n","850761: done 4374 episodes, mean reward 2.186, speed 41.93 f/s\n","851001: done 4375 episodes, mean reward 2.195, speed 58.07 f/s\n","851247: done 4376 episodes, mean reward 2.207, speed 58.71 f/s\n","851340: done 4377 episodes, mean reward 2.181, speed 54.93 f/s\n","851581: done 4378 episodes, mean reward 2.159, speed 57.85 f/s\n","851817: done 4379 episodes, mean reward 2.151, speed 58.01 f/s\n","852329: done 4380 episodes, mean reward 2.185, speed 59.27 f/s\n","852661: done 4381 episodes, mean reward 2.183, speed 59.21 f/s\n","852966: done 4382 episodes, mean reward 2.211, speed 58.78 f/s\n","853796: done 4384 episodes, mean reward 2.274, speed 59.26 f/s\n","854208: done 4385 episodes, mean reward 2.262, speed 58.92 f/s\n","854910: done 4386 episodes, mean reward 2.308, speed 58.46 f/s\n","855337: done 4387 episodes, mean reward 2.340, speed 58.48 f/s\n","856337: done 4388 episodes, mean reward 2.411, speed 59.63 f/s\n","857337: done 4389 episodes, mean reward 2.483, speed 59.57 f/s\n","857447: done 4390 episodes, mean reward 2.488, speed 55.73 f/s\n","857638: done 4391 episodes, mean reward 2.489, speed 56.72 f/s\n","857752: done 4392 episodes, mean reward 2.488, speed 54.43 f/s\n","858096: done 4393 episodes, mean reward 2.494, speed 57.97 f/s\n","858472: done 4394 episodes, mean reward 2.531, speed 58.47 f/s\n","859072: done 4395 episodes, mean reward 2.549, speed 58.51 f/s\n","859314: done 4396 episodes, mean reward 2.562, speed 57.74 f/s\n","859763: done 4397 episodes, mean reward 2.506, speed 57.59 f/s\n","859850: done 4398 episodes, mean reward 2.469, speed 54.50 f/s\n","859985: done 4399 episodes, mean reward 2.472, speed 55.92 f/s\n","EEEE tensor(-7.5484, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3619, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 18.77 sec, reward 2.611, steps 311\n","860423: done 4400 episodes, mean reward 2.506, speed 16.74 f/s\n","860567: done 4401 episodes, mean reward 2.480, speed 56.08 f/s\n","860873: done 4403 episodes, mean reward 2.457, speed 56.14 f/s\n","860973: done 4404 episodes, mean reward 2.442, speed 54.26 f/s\n","861141: done 4405 episodes, mean reward 2.451, speed 57.16 f/s\n","861276: done 4406 episodes, mean reward 2.450, speed 55.81 f/s\n","861624: done 4407 episodes, mean reward 2.396, speed 56.99 f/s\n","861847: done 4408 episodes, mean reward 2.411, speed 57.26 f/s\n","861998: done 4409 episodes, mean reward 2.409, speed 54.08 f/s\n","862068: done 4410 episodes, mean reward 2.391, speed 51.54 f/s\n","862415: done 4411 episodes, mean reward 2.400, speed 58.19 f/s\n","862831: done 4412 episodes, mean reward 2.432, speed 58.85 f/s\n","863266: done 4413 episodes, mean reward 2.429, speed 58.72 f/s\n","863936: done 4414 episodes, mean reward 2.464, speed 59.20 f/s\n","864108: done 4415 episodes, mean reward 2.469, speed 57.07 f/s\n","865108: done 4416 episodes, mean reward 2.565, speed 59.95 f/s\n","865925: done 4417 episodes, mean reward 2.651, speed 59.94 f/s\n","866862: done 4418 episodes, mean reward 2.706, speed 59.78 f/s\n","866954: done 4419 episodes, mean reward 2.627, speed 54.67 f/s\n","867056: done 4420 episodes, mean reward 2.627, speed 55.84 f/s\n","867172: done 4421 episodes, mean reward 2.637, speed 54.61 f/s\n","867489: done 4422 episodes, mean reward 2.662, speed 58.53 f/s\n","868489: done 4423 episodes, mean reward 2.750, speed 59.49 f/s\n","868605: done 4424 episodes, mean reward 2.709, speed 55.17 f/s\n","869179: done 4425 episodes, mean reward 2.760, speed 59.30 f/s\n","EEEE tensor(-8.1579, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3249, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 24.79 sec, reward 3.848, steps 423\n","870055: done 4426 episodes, mean reward 2.841, speed 22.28 f/s\n","870470: done 4427 episodes, mean reward 2.874, speed 58.66 f/s\n","870787: done 4428 episodes, mean reward 2.868, speed 57.91 f/s\n","871515: done 4429 episodes, mean reward 2.934, speed 59.33 f/s\n","872442: done 4431 episodes, mean reward 2.944, speed 59.27 f/s\n","873442: done 4432 episodes, mean reward 3.009, speed 59.97 f/s\n","873717: done 4433 episodes, mean reward 3.025, speed 58.71 f/s\n","873953: done 4434 episodes, mean reward 3.018, speed 56.93 f/s\n","874018: done 4435 episodes, mean reward 3.017, speed 52.45 f/s\n","874120: done 4436 episodes, mean reward 2.978, speed 56.05 f/s\n","874513: done 4437 episodes, mean reward 3.005, speed 58.79 f/s\n","874853: done 4438 episodes, mean reward 3.027, speed 58.93 f/s\n","875853: done 4439 episodes, mean reward 3.042, speed 59.84 f/s\n","876083: done 4440 episodes, mean reward 3.068, speed 58.17 f/s\n","876270: done 4441 episodes, mean reward 3.053, speed 57.78 f/s\n","876486: done 4442 episodes, mean reward 3.073, speed 57.32 f/s\n","877486: done 4443 episodes, mean reward 3.126, speed 59.83 f/s\n","877614: done 4444 episodes, mean reward 3.135, speed 56.75 f/s\n","877699: done 4445 episodes, mean reward 3.141, speed 54.64 f/s\n","878011: done 4446 episodes, mean reward 3.171, speed 58.46 f/s\n","878510: done 4447 episodes, mean reward 3.156, speed 59.16 f/s\n","879011: done 4448 episodes, mean reward 3.163, speed 59.40 f/s\n","879603: done 4449 episodes, mean reward 3.185, speed 59.57 f/s\n","879902: done 4451 episodes, mean reward 3.193, speed 57.12 f/s\n","EEEE tensor(-8.4075, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3295, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 16.81 sec, reward 2.351, steps 275\n","880726: done 4452 episodes, mean reward 3.259, speed 26.89 f/s\n","881571: done 4453 episodes, mean reward 3.290, speed 59.92 f/s\n","882571: done 4454 episodes, mean reward 3.362, speed 60.31 f/s\n","882917: done 4455 episodes, mean reward 3.373, speed 58.61 f/s\n","883078: done 4456 episodes, mean reward 3.311, speed 57.49 f/s\n","883203: done 4457 episodes, mean reward 3.218, speed 55.93 f/s\n","884203: done 4458 episodes, mean reward 3.282, speed 59.98 f/s\n","885049: done 4459 episodes, mean reward 3.328, speed 59.46 f/s\n","885829: done 4460 episodes, mean reward 3.389, speed 59.76 f/s\n","885958: done 4461 episodes, mean reward 3.368, speed 56.54 f/s\n","886210: done 4462 episodes, mean reward 3.367, speed 58.59 f/s\n","886988: done 4463 episodes, mean reward 3.431, speed 59.31 f/s\n","887043: done 4464 episodes, mean reward 3.431, speed 52.22 f/s\n","887779: done 4465 episodes, mean reward 3.491, speed 58.80 f/s\n","888551: done 4466 episodes, mean reward 3.573, speed 59.97 f/s\n","888947: done 4467 episodes, mean reward 3.595, speed 58.77 f/s\n","889667: done 4468 episodes, mean reward 3.660, speed 59.53 f/s\n","889799: done 4469 episodes, mean reward 3.610, speed 55.67 f/s\n","EEEE tensor(-7.6841, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3310, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 23.70 sec, reward 3.490, steps 403\n","890251: done 4470 episodes, mean reward 3.551, speed 14.41 f/s\n","890594: done 4471 episodes, mean reward 3.487, speed 58.28 f/s\n","890715: done 4472 episodes, mean reward 3.484, speed 56.67 f/s\n","891017: done 4473 episodes, mean reward 3.507, speed 58.74 f/s\n","892017: done 4474 episodes, mean reward 3.502, speed 59.83 f/s\n","892220: done 4475 episodes, mean reward 3.497, speed 57.51 f/s\n","893220: done 4476 episodes, mean reward 3.578, speed 59.78 f/s\n","893880: done 4477 episodes, mean reward 3.649, speed 59.87 f/s\n","894070: done 4478 episodes, mean reward 3.651, speed 57.92 f/s\n","894760: done 4479 episodes, mean reward 3.695, speed 59.69 f/s\n","894985: done 4480 episodes, mean reward 3.687, speed 58.04 f/s\n","895133: done 4481 episodes, mean reward 3.665, speed 56.94 f/s\n","895230: done 4482 episodes, mean reward 3.641, speed 54.28 f/s\n","895382: done 4483 episodes, mean reward 3.653, speed 57.50 f/s\n","895925: done 4484 episodes, mean reward 3.623, speed 59.32 f/s\n","896111: done 4485 episodes, mean reward 3.620, speed 57.87 f/s\n","896353: done 4486 episodes, mean reward 3.585, speed 58.62 f/s\n","897317: done 4487 episodes, mean reward 3.635, speed 59.99 f/s\n","897896: done 4488 episodes, mean reward 3.618, speed 59.36 f/s\n","898001: done 4489 episodes, mean reward 3.539, speed 55.80 f/s\n","898594: done 4490 episodes, mean reward 3.594, speed 59.81 f/s\n","899323: done 4491 episodes, mean reward 3.653, speed 60.00 f/s\n","899690: done 4492 episodes, mean reward 3.704, speed 58.44 f/s\n","EEEE tensor(-8.8224, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3154, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 26.41 sec, reward 3.646, steps 450\n","900181: done 4493 episodes, mean reward 3.712, speed 14.16 f/s\n","901181: done 4494 episodes, mean reward 3.754, speed 59.75 f/s\n","901636: done 4496 episodes, mean reward 3.711, speed 58.28 f/s\n","902350: done 4497 episodes, mean reward 3.760, speed 59.63 f/s\n","902712: done 4498 episodes, mean reward 3.788, speed 59.01 f/s\n","903101: done 4499 episodes, mean reward 3.830, speed 58.56 f/s\n","903360: done 4500 episodes, mean reward 3.819, speed 57.82 f/s\n","903747: done 4501 episodes, mean reward 3.839, speed 59.08 f/s\n","904009: done 4502 episodes, mean reward 3.861, speed 58.21 f/s\n","904505: done 4503 episodes, mean reward 3.872, speed 59.09 f/s\n","904980: done 4505 episodes, mean reward 3.910, speed 57.85 f/s\n","905741: done 4506 episodes, mean reward 3.990, speed 60.08 f/s\n","906127: done 4507 episodes, mean reward 4.000, speed 58.29 f/s\n","906261: done 4508 episodes, mean reward 3.999, speed 56.46 f/s\n","906385: done 4509 episodes, mean reward 4.012, speed 55.80 f/s\n","906560: done 4510 episodes, mean reward 4.025, speed 57.71 f/s\n","906944: done 4511 episodes, mean reward 4.026, speed 58.77 f/s\n","907623: done 4512 episodes, mean reward 4.034, speed 59.80 f/s\n","908079: done 4513 episodes, mean reward 4.044, speed 58.98 f/s\n","908364: done 4514 episodes, mean reward 3.999, speed 58.76 f/s\n","908488: done 4515 episodes, mean reward 3.999, speed 55.75 f/s\n","908567: done 4516 episodes, mean reward 3.904, speed 54.09 f/s\n","908676: done 4517 episodes, mean reward 3.813, speed 54.95 f/s\n","908794: done 4518 episodes, mean reward 3.749, speed 56.08 f/s\n","909121: done 4519 episodes, mean reward 3.780, speed 59.24 f/s\n","909196: done 4520 episodes, mean reward 3.780, speed 53.43 f/s\n","909348: done 4521 episodes, mean reward 3.783, speed 56.63 f/s\n","909456: done 4522 episodes, mean reward 3.765, speed 55.44 f/s\n","EEEE tensor(-6.9973, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3194, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 24.14 sec, reward 3.489, steps 407\n","910456: done 4523 episodes, mean reward 3.786, speed 24.40 f/s\n","910583: done 4524 episodes, mean reward 3.793, speed 55.50 f/s\n","911276: done 4525 episodes, mean reward 3.807, speed 59.91 f/s\n","911485: done 4526 episodes, mean reward 3.743, speed 57.97 f/s\n","911598: done 4527 episodes, mean reward 3.705, speed 55.65 f/s\n","912140: done 4528 episodes, mean reward 3.715, speed 59.23 f/s\n","912529: done 4530 episodes, mean reward 3.677, speed 57.59 f/s\n","912851: done 4531 episodes, mean reward 3.615, speed 58.44 f/s\n","913079: done 4532 episodes, mean reward 3.522, speed 56.51 f/s\n","913757: done 4533 episodes, mean reward 3.552, speed 59.42 f/s\n","914708: done 4534 episodes, mean reward 3.638, speed 59.60 f/s\n","915006: done 4535 episodes, mean reward 3.664, speed 58.53 f/s\n","915856: done 4536 episodes, mean reward 3.751, speed 59.78 f/s\n","916495: done 4537 episodes, mean reward 3.779, speed 59.85 f/s\n","916817: done 4538 episodes, mean reward 3.792, speed 59.21 f/s\n","917122: done 4539 episodes, mean reward 3.763, speed 58.52 f/s\n","917283: done 4540 episodes, mean reward 3.750, speed 57.18 f/s\n","917674: done 4541 episodes, mean reward 3.776, speed 58.89 f/s\n","918123: done 4542 episodes, mean reward 3.805, speed 58.86 f/s\n","918399: done 4543 episodes, mean reward 3.739, speed 58.95 f/s\n","919022: done 4544 episodes, mean reward 3.779, speed 59.01 f/s\n","919801: done 4546 episodes, mean reward 3.816, speed 58.60 f/s\n","EEEE tensor(-8.0925, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3191, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 25.94 sec, reward 4.006, steps 440\n","920801: done 4547 episodes, mean reward 3.887, speed 23.45 f/s\n","921113: done 4548 episodes, mean reward 3.884, speed 57.88 f/s\n","921380: done 4549 episodes, mean reward 3.865, speed 58.16 f/s\n","921656: done 4550 episodes, mean reward 3.893, speed 58.67 f/s\n","921966: done 4551 episodes, mean reward 3.900, speed 57.83 f/s\n","922203: done 4552 episodes, mean reward 3.862, speed 55.77 f/s\n","922397: done 4553 episodes, mean reward 3.824, speed 57.79 f/s\n","922521: done 4554 episodes, mean reward 3.759, speed 55.42 f/s\n","922648: done 4555 episodes, mean reward 3.739, speed 56.96 f/s\n","922857: done 4557 episodes, mean reward 3.731, speed 55.50 f/s\n","923422: done 4558 episodes, mean reward 3.670, speed 59.32 f/s\n","923559: done 4559 episodes, mean reward 3.607, speed 56.69 f/s\n","923961: done 4560 episodes, mean reward 3.550, speed 58.28 f/s\n","924104: done 4561 episodes, mean reward 3.542, speed 55.27 f/s\n","924804: done 4563 episodes, mean reward 3.514, speed 58.94 f/s\n","925501: done 4565 episodes, mean reward 3.509, speed 58.64 f/s\n","926458: done 4567 episodes, mean reward 3.482, speed 59.32 f/s\n","926590: done 4568 episodes, mean reward 3.423, speed 55.34 f/s\n","927176: done 4569 episodes, mean reward 3.474, speed 59.49 f/s\n","928176: done 4570 episodes, mean reward 3.525, speed 59.44 f/s\n","929058: done 4572 episodes, mean reward 3.580, speed 59.64 f/s\n","929208: done 4573 episodes, mean reward 3.566, speed 56.15 f/s\n","929624: done 4574 episodes, mean reward 3.523, speed 59.17 f/s\n","EEEE tensor(-7.5274, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3178, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 16.66 sec, reward 2.733, steps 276\n","930066: done 4575 episodes, mean reward 3.554, speed 18.36 f/s\n","930277: done 4576 episodes, mean reward 3.466, speed 57.62 f/s\n","930954: done 4577 episodes, mean reward 3.469, speed 59.30 f/s\n","931954: done 4578 episodes, mean reward 3.541, speed 60.04 f/s\n","932066: done 4579 episodes, mean reward 3.492, speed 55.35 f/s\n","932767: done 4580 episodes, mean reward 3.535, speed 59.08 f/s\n","933767: done 4581 episodes, mean reward 3.637, speed 59.79 f/s\n","934309: done 4582 episodes, mean reward 3.692, speed 59.00 f/s\n","934709: done 4583 episodes, mean reward 3.719, speed 58.82 f/s\n","935502: done 4584 episodes, mean reward 3.766, speed 57.40 f/s\n","935652: done 4585 episodes, mean reward 3.760, speed 55.64 f/s\n","936652: done 4586 episodes, mean reward 3.765, speed 57.53 f/s\n","936773: done 4587 episodes, mean reward 3.691, speed 54.59 f/s\n","937036: done 4588 episodes, mean reward 3.658, speed 58.04 f/s\n","938036: done 4589 episodes, mean reward 3.745, speed 60.09 f/s\n","938266: done 4590 episodes, mean reward 3.715, speed 58.07 f/s\n","938993: done 4591 episodes, mean reward 3.727, speed 59.81 f/s\n","939679: done 4592 episodes, mean reward 3.748, speed 59.27 f/s\n","939893: done 4593 episodes, mean reward 3.732, speed 57.28 f/s\n","EEEE tensor(-8.2501, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3101, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 23.92 sec, reward 4.372, steps 406\n","940356: done 4594 episodes, mean reward 3.699, speed 14.57 f/s\n","941210: done 4595 episodes, mean reward 3.791, speed 60.25 f/s\n","941494: done 4596 episodes, mean reward 3.787, speed 58.89 f/s\n","941643: done 4597 episodes, mean reward 3.743, speed 56.98 f/s\n","941792: done 4598 episodes, mean reward 3.725, speed 57.01 f/s\n","942077: done 4599 episodes, mean reward 3.710, speed 58.23 f/s\n","942490: done 4600 episodes, mean reward 3.718, speed 58.95 f/s\n","943490: done 4601 episodes, mean reward 3.817, speed 59.67 f/s\n","943779: done 4602 episodes, mean reward 3.828, speed 58.28 f/s\n","944257: done 4603 episodes, mean reward 3.844, speed 58.94 f/s\n","944687: done 4604 episodes, mean reward 3.886, speed 59.50 f/s\n","945356: done 4606 episodes, mean reward 3.833, speed 59.41 f/s\n","945895: done 4607 episodes, mean reward 3.847, speed 59.40 f/s\n","946321: done 4608 episodes, mean reward 3.881, speed 59.09 f/s\n","946558: done 4609 episodes, mean reward 3.904, speed 58.35 f/s\n","946706: done 4610 episodes, mean reward 3.906, speed 57.17 f/s\n","947706: done 4611 episodes, mean reward 3.991, speed 59.84 f/s\n","948162: done 4612 episodes, mean reward 3.977, speed 58.31 f/s\n","948248: done 4613 episodes, mean reward 3.942, speed 54.59 f/s\n","948738: done 4614 episodes, mean reward 3.978, speed 59.35 f/s\n","948948: done 4615 episodes, mean reward 3.996, speed 58.21 f/s\n","949312: done 4616 episodes, mean reward 4.035, speed 58.97 f/s\n","949537: done 4617 episodes, mean reward 4.056, speed 58.29 f/s\n","949799: done 4618 episodes, mean reward 4.081, speed 58.27 f/s\n","EEEE tensor(-8.6052, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3208, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 22.00 sec, reward 3.900, steps 372\n","950125: done 4619 episodes, mean reward 4.093, speed 11.83 f/s\n","950422: done 4620 episodes, mean reward 4.128, speed 58.64 f/s\n","950726: done 4621 episodes, mean reward 4.149, speed 59.31 f/s\n","950840: done 4622 episodes, mean reward 4.150, speed 55.62 f/s\n","951840: done 4623 episodes, mean reward 4.168, speed 59.18 f/s\n","952880: done 4625 episodes, mean reward 4.179, speed 59.39 f/s\n","953098: done 4626 episodes, mean reward 4.184, speed 58.13 f/s\n","953481: done 4627 episodes, mean reward 4.231, speed 59.18 f/s\n","953656: done 4628 episodes, mean reward 4.204, speed 57.92 f/s\n","953747: done 4629 episodes, mean reward 4.210, speed 55.40 f/s\n","954392: done 4630 episodes, mean reward 4.238, speed 59.77 f/s\n","954661: done 4631 episodes, mean reward 4.225, speed 57.84 f/s\n","954968: done 4633 episodes, mean reward 4.191, speed 56.93 f/s\n","955055: done 4634 episodes, mean reward 4.099, speed 55.51 f/s\n","955289: done 4635 episodes, mean reward 4.088, speed 57.86 f/s\n","955554: done 4636 episodes, mean reward 4.028, speed 57.64 f/s\n","955840: done 4637 episodes, mean reward 3.976, speed 58.44 f/s\n","956336: done 4638 episodes, mean reward 3.986, speed 58.90 f/s\n","956796: done 4639 episodes, mean reward 3.991, speed 58.70 f/s\n","956908: done 4640 episodes, mean reward 3.983, speed 55.81 f/s\n","957325: done 4641 episodes, mean reward 3.985, speed 58.92 f/s\n","957419: done 4642 episodes, mean reward 3.940, speed 55.91 f/s\n","957946: done 4643 episodes, mean reward 3.980, speed 59.65 f/s\n","958345: done 4645 episodes, mean reward 3.978, speed 57.99 f/s\n","958464: done 4646 episodes, mean reward 3.915, speed 56.32 f/s\n","958761: done 4647 episodes, mean reward 3.819, speed 58.84 f/s\n","959089: done 4648 episodes, mean reward 3.824, speed 57.53 f/s\n","959624: done 4649 episodes, mean reward 3.849, speed 59.45 f/s\n","EEEE tensor(-7.4500, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3539, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 11.57 sec, reward 2.009, steps 183\n","960008: done 4650 episodes, mean reward 3.863, speed 21.28 f/s\n","960113: done 4651 episodes, mean reward 3.841, speed 55.31 f/s\n","960278: done 4652 episodes, mean reward 3.823, speed 55.88 f/s\n","960372: done 4653 episodes, mean reward 3.814, speed 54.27 f/s\n","960467: done 4655 episodes, mean reward 3.803, speed 51.20 f/s\n","960702: done 4656 episodes, mean reward 3.832, speed 58.59 f/s\n","960890: done 4657 episodes, mean reward 3.837, speed 57.97 f/s\n","961022: done 4658 episodes, mean reward 3.811, speed 56.49 f/s\n","961110: done 4660 episodes, mean reward 3.776, speed 50.55 f/s\n","961217: done 4661 episodes, mean reward 3.782, speed 55.75 f/s\n","961326: done 4662 episodes, mean reward 3.785, speed 55.64 f/s\n","961520: done 4663 episodes, mean reward 3.735, speed 56.91 f/s\n","961904: done 4664 episodes, mean reward 3.787, speed 59.27 f/s\n","962099: done 4665 episodes, mean reward 3.754, speed 57.02 f/s\n","962269: done 4666 episodes, mean reward 3.772, speed 57.72 f/s\n","962405: done 4667 episodes, mean reward 3.699, speed 56.65 f/s\n","962942: done 4669 episodes, mean reward 3.689, speed 58.94 f/s\n","963119: done 4671 episodes, mean reward 3.625, speed 55.47 f/s\n","963961: done 4672 episodes, mean reward 3.612, speed 59.99 f/s\n","964105: done 4674 episodes, mean reward 3.577, speed 54.40 f/s\n","964210: done 4675 episodes, mean reward 3.540, speed 55.78 f/s\n","964452: done 4676 episodes, mean reward 3.546, speed 58.55 f/s\n","964553: done 4677 episodes, mean reward 3.479, speed 55.46 f/s\n","965028: done 4678 episodes, mean reward 3.434, speed 58.90 f/s\n","965660: done 4679 episodes, mean reward 3.489, speed 59.19 f/s\n","966049: done 4681 episodes, mean reward 3.338, speed 57.82 f/s\n","966894: done 4682 episodes, mean reward 3.351, speed 60.00 f/s\n","967391: done 4683 episodes, mean reward 3.356, speed 59.72 f/s\n","967727: done 4684 episodes, mean reward 3.300, speed 59.16 f/s\n","968670: done 4685 episodes, mean reward 3.371, speed 59.74 f/s\n","968863: done 4686 episodes, mean reward 3.355, speed 56.06 f/s\n","969301: done 4687 episodes, mean reward 3.387, speed 58.30 f/s\n","969544: done 4688 episodes, mean reward 3.381, speed 57.61 f/s\n","EEEE tensor(-8.0511, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3190, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 32.98 sec, reward 5.785, steps 575\n","970148: done 4689 episodes, mean reward 3.332, speed 13.91 f/s\n","970246: done 4690 episodes, mean reward 3.310, speed 55.53 f/s\n","970608: done 4691 episodes, mean reward 3.271, speed 58.80 f/s\n","970932: done 4692 episodes, mean reward 3.222, speed 59.13 f/s\n","971189: done 4693 episodes, mean reward 3.221, speed 58.27 f/s\n","971769: done 4694 episodes, mean reward 3.237, speed 59.00 f/s\n","971954: done 4696 episodes, mean reward 3.121, speed 55.90 f/s\n","972152: done 4697 episodes, mean reward 3.136, speed 58.01 f/s\n","972238: done 4699 episodes, mean reward 3.095, speed 50.32 f/s\n","972940: done 4700 episodes, mean reward 3.125, speed 59.23 f/s\n","973103: done 4701 episodes, mean reward 3.018, speed 56.64 f/s\n","973181: done 4702 episodes, mean reward 2.990, speed 54.33 f/s\n","973300: done 4703 episodes, mean reward 2.965, speed 56.26 f/s\n","974076: done 4704 episodes, mean reward 2.995, speed 59.96 f/s\n","974337: done 4705 episodes, mean reward 3.022, speed 58.82 f/s\n","974539: done 4706 episodes, mean reward 2.964, speed 58.00 f/s\n","974956: done 4707 episodes, mean reward 2.968, speed 59.24 f/s\n","975213: done 4708 episodes, mean reward 2.938, speed 57.11 f/s\n","975411: done 4709 episodes, mean reward 2.921, speed 58.58 f/s\n","975899: done 4710 episodes, mean reward 2.922, speed 58.66 f/s\n","976459: done 4711 episodes, mean reward 2.857, speed 59.64 f/s\n","977161: done 4712 episodes, mean reward 2.881, speed 59.66 f/s\n","977978: done 4713 episodes, mean reward 2.962, speed 60.06 f/s\n","978263: done 4714 episodes, mean reward 2.923, speed 58.56 f/s\n","978323: done 4715 episodes, mean reward 2.899, speed 52.61 f/s\n","978431: done 4716 episodes, mean reward 2.859, speed 55.46 f/s\n","978637: done 4717 episodes, mean reward 2.849, speed 57.53 f/s\n","978774: done 4718 episodes, mean reward 2.826, speed 56.62 f/s\n","978926: done 4719 episodes, mean reward 2.797, speed 57.13 f/s\n","979355: done 4720 episodes, mean reward 2.806, speed 59.72 f/s\n","979539: done 4721 episodes, mean reward 2.789, speed 58.08 f/s\n","979814: done 4722 episodes, mean reward 2.812, speed 58.99 f/s\n","979953: done 4723 episodes, mean reward 2.701, speed 57.07 f/s\n","EEEE tensor(-8.3973, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3268, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 13.61 sec, reward 2.116, steps 221\n","980239: done 4724 episodes, mean reward 2.725, speed 15.49 f/s\n","980659: done 4725 episodes, mean reward 2.702, speed 59.13 f/s\n","981629: done 4726 episodes, mean reward 2.771, speed 59.26 f/s\n","982094: done 4727 episodes, mean reward 2.775, speed 58.41 f/s\n","982532: done 4728 episodes, mean reward 2.803, speed 58.80 f/s\n","982749: done 4729 episodes, mean reward 2.821, speed 58.21 f/s\n","982952: done 4730 episodes, mean reward 2.787, speed 57.41 f/s\n","983552: done 4731 episodes, mean reward 2.841, speed 59.74 f/s\n","983694: done 4732 episodes, mean reward 2.853, speed 56.49 f/s\n","983789: done 4733 episodes, mean reward 2.838, speed 54.70 f/s\n","984363: done 4734 episodes, mean reward 2.906, speed 58.72 f/s\n","984417: done 4735 episodes, mean reward 2.892, speed 51.66 f/s\n","984683: done 4736 episodes, mean reward 2.891, speed 58.28 f/s\n","984785: done 4737 episodes, mean reward 2.881, speed 56.08 f/s\n","985126: done 4739 episodes, mean reward 2.825, speed 56.96 f/s\n","985237: done 4740 episodes, mean reward 2.831, speed 54.87 f/s\n","985677: done 4741 episodes, mean reward 2.828, speed 59.38 f/s\n","985918: done 4742 episodes, mean reward 2.843, speed 58.06 f/s\n","986077: done 4743 episodes, mean reward 2.796, speed 57.12 f/s\n","986147: done 4744 episodes, mean reward 2.799, speed 52.77 f/s\n","986510: done 4745 episodes, mean reward 2.789, speed 59.15 f/s\n","986762: done 4746 episodes, mean reward 2.808, speed 57.95 f/s\n","986840: done 4747 episodes, mean reward 2.800, speed 54.41 f/s\n","986912: done 4748 episodes, mean reward 2.769, speed 54.04 f/s\n","987051: done 4749 episodes, mean reward 2.728, speed 56.78 f/s\n","987268: done 4750 episodes, mean reward 2.701, speed 57.86 f/s\n","987537: done 4751 episodes, mean reward 2.726, speed 58.82 f/s\n","987765: done 4752 episodes, mean reward 2.749, speed 58.08 f/s\n","988152: done 4753 episodes, mean reward 2.773, speed 59.02 f/s\n","988893: done 4754 episodes, mean reward 2.841, speed 59.63 f/s\n","989019: done 4755 episodes, mean reward 2.851, speed 56.48 f/s\n","989125: done 4756 episodes, mean reward 2.829, speed 54.63 f/s\n","989265: done 4757 episodes, mean reward 2.816, speed 57.56 f/s\n","989445: done 4758 episodes, mean reward 2.821, speed 57.75 f/s\n","989592: done 4759 episodes, mean reward 2.834, speed 57.07 f/s\n","EEEE tensor(-7.7091, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3453, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 18.45 sec, reward 3.219, steps 309\n","990351: done 4760 episodes, mean reward 2.905, speed 24.36 f/s\n","990560: done 4761 episodes, mean reward 2.916, speed 58.15 f/s\n","991560: done 4762 episodes, mean reward 3.027, speed 59.74 f/s\n","991767: done 4763 episodes, mean reward 3.036, speed 56.99 f/s\n","992041: done 4764 episodes, mean reward 3.017, speed 58.62 f/s\n","992360: done 4766 episodes, mean reward 3.004, speed 57.31 f/s\n","992416: done 4767 episodes, mean reward 2.995, speed 52.84 f/s\n","992605: done 4768 episodes, mean reward 3.015, speed 58.13 f/s\n","992691: done 4769 episodes, mean reward 2.964, speed 55.19 f/s\n","993437: done 4770 episodes, mean reward 3.031, speed 59.80 f/s\n","993523: done 4771 episodes, mean reward 3.025, speed 55.61 f/s\n","993619: done 4772 episodes, mean reward 2.954, speed 54.35 f/s\n","993943: done 4773 episodes, mean reward 2.990, speed 58.66 f/s\n","994173: done 4774 episodes, mean reward 2.998, speed 58.05 f/s\n","994423: done 4775 episodes, mean reward 3.014, speed 58.02 f/s\n","994526: done 4776 episodes, mean reward 3.002, speed 55.20 f/s\n","994850: done 4777 episodes, mean reward 3.028, speed 59.08 f/s\n","995178: done 4778 episodes, mean reward 3.014, speed 58.91 f/s\n","995375: done 4779 episodes, mean reward 2.978, speed 58.00 f/s\n","995593: done 4780 episodes, mean reward 3.002, speed 58.77 f/s\n","995849: done 4781 episodes, mean reward 2.996, speed 58.29 f/s\n","996135: done 4782 episodes, mean reward 2.954, speed 58.97 f/s\n","996888: done 4783 episodes, mean reward 2.960, speed 59.75 f/s\n","997116: done 4784 episodes, mean reward 2.947, speed 58.31 f/s\n","997273: done 4785 episodes, mean reward 2.872, speed 57.18 f/s\n","997486: done 4786 episodes, mean reward 2.875, speed 58.55 f/s\n","997675: done 4787 episodes, mean reward 2.849, speed 57.97 f/s\n","998121: done 4788 episodes, mean reward 2.863, speed 59.25 f/s\n","998337: done 4789 episodes, mean reward 2.842, speed 58.22 f/s\n","998628: done 4790 episodes, mean reward 2.857, speed 58.97 f/s\n","999338: done 4791 episodes, mean reward 2.880, speed 58.87 f/s\n","999582: done 4792 episodes, mean reward 2.886, speed 58.28 f/s\n","999840: done 4793 episodes, mean reward 2.891, speed 58.70 f/s\n","EEEE tensor(-7.2317, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3302, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 20.78 sec, reward 2.935, steps 347\n","1000093: done 4794 episodes, mean reward 2.852, speed 10.06 f/s\n","1000237: done 4795 episodes, mean reward 2.864, speed 56.18 f/s\n","1000476: done 4796 episodes, mean reward 2.867, speed 58.07 f/s\n","1000635: done 4797 episodes, mean reward 2.856, speed 58.14 f/s\n","1001354: done 4798 episodes, mean reward 2.917, speed 59.66 f/s\n","1001763: done 4799 episodes, mean reward 2.958, speed 59.10 f/s\n","1002763: done 4800 episodes, mean reward 2.999, speed 59.68 f/s\n","1003049: done 4801 episodes, mean reward 3.010, speed 58.51 f/s\n","1003358: done 4802 episodes, mean reward 3.029, speed 58.90 f/s\n","1003552: done 4803 episodes, mean reward 3.037, speed 58.00 f/s\n","1004139: done 4804 episodes, mean reward 3.017, speed 59.98 f/s\n","1004223: done 4805 episodes, mean reward 2.995, speed 54.77 f/s\n","1004722: done 4806 episodes, mean reward 3.028, speed 59.69 f/s\n","1005380: done 4807 episodes, mean reward 3.036, speed 59.84 f/s\n","1005886: done 4808 episodes, mean reward 3.067, speed 58.80 f/s\n","1006153: done 4809 episodes, mean reward 3.079, speed 58.78 f/s\n","1006286: done 4810 episodes, mean reward 3.069, speed 56.30 f/s\n","1006405: done 4811 episodes, mean reward 3.022, speed 56.82 f/s\n","1006982: done 4812 episodes, mean reward 3.010, speed 59.56 f/s\n","1007418: done 4813 episodes, mean reward 2.970, speed 59.25 f/s\n","1007632: done 4814 episodes, mean reward 2.959, speed 57.08 f/s\n","1008109: done 4815 episodes, mean reward 2.999, speed 59.17 f/s\n","1008219: done 4816 episodes, mean reward 3.004, speed 56.21 f/s\n","1008371: done 4817 episodes, mean reward 2.998, speed 56.87 f/s\n","1008543: done 4818 episodes, mean reward 3.000, speed 57.55 f/s\n","1008688: done 4819 episodes, mean reward 2.999, speed 56.91 f/s\n","1008930: done 4820 episodes, mean reward 2.972, speed 58.50 f/s\n","1009790: done 4821 episodes, mean reward 2.983, speed 60.09 f/s\n","EEEE tensor(-8.5023, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3205, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 14.89 sec, reward 2.185, steps 244\n","1010014: done 4822 episodes, mean reward 2.967, speed 11.94 f/s\n","1010176: done 4823 episodes, mean reward 2.965, speed 57.22 f/s\n","1010505: done 4824 episodes, mean reward 2.963, speed 58.07 f/s\n","1010636: done 4825 episodes, mean reward 2.911, speed 57.22 f/s\n","1011027: done 4826 episodes, mean reward 2.849, speed 58.17 f/s\n","1011379: done 4827 episodes, mean reward 2.819, speed 57.59 f/s\n","1011638: done 4828 episodes, mean reward 2.790, speed 56.74 f/s\n","1011984: done 4829 episodes, mean reward 2.786, speed 57.73 f/s\n","1012487: done 4830 episodes, mean reward 2.802, speed 59.16 f/s\n","1012647: done 4831 episodes, mean reward 2.739, speed 57.76 f/s\n","1012961: done 4832 episodes, mean reward 2.756, speed 58.35 f/s\n","1013715: done 4833 episodes, mean reward 2.800, speed 58.65 f/s\n","1013876: done 4834 episodes, mean reward 2.739, speed 57.21 f/s\n","1014218: done 4835 episodes, mean reward 2.760, speed 58.75 f/s\n","1014414: done 4836 episodes, mean reward 2.740, speed 57.77 f/s\n","1014687: done 4837 episodes, mean reward 2.752, speed 58.35 f/s\n","1015069: done 4838 episodes, mean reward 2.781, speed 58.52 f/s\n","1015611: done 4839 episodes, mean reward 2.811, speed 58.65 f/s\n","1015849: done 4840 episodes, mean reward 2.828, speed 57.72 f/s\n","1016320: done 4841 episodes, mean reward 2.823, speed 58.69 f/s\n","1016458: done 4842 episodes, mean reward 2.815, speed 56.60 f/s\n","1016639: done 4843 episodes, mean reward 2.813, speed 57.28 f/s\n","1017455: done 4844 episodes, mean reward 2.891, speed 58.64 f/s\n","1017656: done 4845 episodes, mean reward 2.866, speed 57.53 f/s\n","1017929: done 4846 episodes, mean reward 2.866, speed 57.54 f/s\n","1018469: done 4847 episodes, mean reward 2.893, speed 59.20 f/s\n","1019469: done 4848 episodes, mean reward 2.970, speed 59.37 f/s\n","1019542: done 4849 episodes, mean reward 2.957, speed 53.90 f/s\n","1019757: done 4850 episodes, mean reward 2.967, speed 58.20 f/s\n","1019881: done 4851 episodes, mean reward 2.944, speed 55.89 f/s\n","EEEE tensor(-8.0522, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3288, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 28.47 sec, reward 3.969, steps 473\n","1020881: done 4852 episodes, mean reward 2.989, speed 22.05 f/s\n","1021577: done 4853 episodes, mean reward 2.999, speed 58.83 f/s\n","1021858: done 4854 episodes, mean reward 2.956, speed 58.54 f/s\n","1022200: done 4855 episodes, mean reward 2.972, speed 58.72 f/s\n","1022463: done 4856 episodes, mean reward 2.988, speed 58.26 f/s\n","1022959: done 4857 episodes, mean reward 3.034, speed 59.37 f/s\n","1023083: done 4858 episodes, mean reward 3.030, speed 56.75 f/s\n","1023643: done 4859 episodes, mean reward 3.070, speed 58.73 f/s\n","1024144: done 4860 episodes, mean reward 3.039, speed 58.59 f/s\n","1024304: done 4861 episodes, mean reward 3.030, speed 57.00 f/s\n","1025021: done 4862 episodes, mean reward 2.996, speed 59.28 f/s\n","1025080: done 4863 episodes, mean reward 2.980, speed 52.10 f/s\n","1025270: done 4864 episodes, mean reward 2.963, speed 57.43 f/s\n","1025901: done 4865 episodes, mean reward 3.018, speed 59.14 f/s\n","1026218: done 4866 episodes, mean reward 3.030, speed 58.72 f/s\n","1026475: done 4867 episodes, mean reward 3.049, speed 57.86 f/s\n","1026616: done 4868 episodes, mean reward 3.037, speed 56.36 f/s\n","1026807: done 4869 episodes, mean reward 3.042, speed 57.34 f/s\n","1026934: done 4870 episodes, mean reward 2.985, speed 55.95 f/s\n","1027342: done 4871 episodes, mean reward 3.005, speed 58.84 f/s\n","1027700: done 4872 episodes, mean reward 3.035, speed 59.15 f/s\n","1028283: done 4873 episodes, mean reward 3.040, speed 59.69 f/s\n","1028644: done 4874 episodes, mean reward 3.060, speed 58.46 f/s\n","1029289: done 4875 episodes, mean reward 3.099, speed 59.13 f/s\n","1029678: done 4876 episodes, mean reward 3.128, speed 58.77 f/s\n","1029958: done 4877 episodes, mean reward 3.122, speed 58.83 f/s\n","EEEE tensor(-7.8333, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3413, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 36.65 sec, reward 6.645, steps 642\n","1030246: done 4878 episodes, mean reward 3.128, speed 6.93 f/s\n","1030457: done 4879 episodes, mean reward 3.130, speed 57.26 f/s\n","1030685: done 4880 episodes, mean reward 3.128, speed 57.70 f/s\n","1031015: done 4881 episodes, mean reward 3.141, speed 58.44 f/s\n","1031608: done 4882 episodes, mean reward 3.157, speed 58.77 f/s\n","1031998: done 4883 episodes, mean reward 3.137, speed 58.10 f/s\n","1032213: done 4884 episodes, mean reward 3.130, speed 56.99 f/s\n","1032311: done 4885 episodes, mean reward 3.123, speed 55.39 f/s\n","1032874: done 4886 episodes, mean reward 3.151, speed 59.51 f/s\n","1033688: done 4887 episodes, mean reward 3.200, speed 59.83 f/s\n","1033796: done 4888 episodes, mean reward 3.178, speed 56.46 f/s\n","1034003: done 4889 episodes, mean reward 3.169, speed 58.35 f/s\n","1034225: done 4890 episodes, mean reward 3.167, speed 58.07 f/s\n","1034385: done 4891 episodes, mean reward 3.118, speed 57.56 f/s\n","1034470: done 4892 episodes, mean reward 3.097, speed 54.57 f/s\n","1034915: done 4893 episodes, mean reward 3.106, speed 58.69 f/s\n","1035228: done 4894 episodes, mean reward 3.104, speed 57.66 f/s\n","1035423: done 4895 episodes, mean reward 3.110, speed 56.71 f/s\n","1036060: done 4896 episodes, mean reward 3.143, speed 58.28 f/s\n","1036252: done 4897 episodes, mean reward 3.147, speed 57.62 f/s\n","1036331: done 4898 episodes, mean reward 3.085, speed 53.23 f/s\n","1037331: done 4899 episodes, mean reward 3.111, speed 59.61 f/s\n","1038331: done 4900 episodes, mean reward 3.098, speed 59.69 f/s\n","1038784: done 4901 episodes, mean reward 3.113, speed 57.91 f/s\n","1039065: done 4902 episodes, mean reward 3.115, speed 58.02 f/s\n","1039444: done 4903 episodes, mean reward 3.134, speed 58.48 f/s\n","1039584: done 4904 episodes, mean reward 3.093, speed 56.47 f/s\n","EEEE tensor(-7.8759, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3565, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 15.50 sec, reward 2.210, steps 249\n","1040584: done 4905 episodes, mean reward 3.201, speed 31.01 f/s\n","1040719: done 4906 episodes, mean reward 3.166, speed 56.38 f/s\n","1040957: done 4907 episodes, mean reward 3.121, speed 57.81 f/s\n","1041153: done 4908 episodes, mean reward 3.087, speed 57.56 f/s\n","1041466: done 4909 episodes, mean reward 3.080, speed 58.25 f/s\n","1041702: done 4910 episodes, mean reward 3.085, speed 57.55 f/s\n","1042702: done 4911 episodes, mean reward 3.149, speed 58.90 f/s\n","1043364: done 4912 episodes, mean reward 3.156, speed 58.54 f/s\n","1043734: done 4913 episodes, mean reward 3.140, speed 57.90 f/s\n","1043876: done 4914 episodes, mean reward 3.137, speed 56.25 f/s\n","1044876: done 4915 episodes, mean reward 3.173, speed 58.94 f/s\n","1044963: done 4916 episodes, mean reward 3.169, speed 54.30 f/s\n","1045058: done 4917 episodes, mean reward 3.163, speed 54.64 f/s\n","1045592: done 4918 episodes, mean reward 3.184, speed 58.70 f/s\n","1046050: done 4919 episodes, mean reward 3.196, speed 58.74 f/s\n","1046317: done 4920 episodes, mean reward 3.190, speed 57.69 f/s\n","1047093: done 4921 episodes, mean reward 3.228, speed 59.11 f/s\n","1047599: done 4922 episodes, mean reward 3.245, speed 58.31 f/s\n","1048046: done 4923 episodes, mean reward 3.263, speed 58.67 f/s\n","1048208: done 4924 episodes, mean reward 3.252, speed 54.75 f/s\n","1048603: done 4925 episodes, mean reward 3.267, speed 58.06 f/s\n","1049035: done 4926 episodes, mean reward 3.264, speed 57.09 f/s\n","1049149: done 4927 episodes, mean reward 3.247, speed 53.69 f/s\n","1049290: done 4928 episodes, mean reward 3.236, speed 54.67 f/s\n","1049628: done 4929 episodes, mean reward 3.247, speed 58.64 f/s\n","1049895: done 4930 episodes, mean reward 3.231, speed 58.15 f/s\n","EEEE tensor(-7.1332, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3484, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 20.66 sec, reward 2.968, steps 350\n","1050091: done 4931 episodes, mean reward 3.230, speed 8.10 f/s\n","1050183: done 4932 episodes, mean reward 3.207, speed 55.20 f/s\n","1050958: done 4933 episodes, mean reward 3.215, speed 60.00 f/s\n","1051479: done 4934 episodes, mean reward 3.244, speed 59.61 f/s\n","1052043: done 4935 episodes, mean reward 3.259, speed 58.87 f/s\n","1052242: done 4936 episodes, mean reward 3.259, speed 57.43 f/s\n","1053242: done 4937 episodes, mean reward 3.303, speed 59.47 f/s\n","1053312: done 4938 episodes, mean reward 3.275, speed 51.93 f/s\n","1053600: done 4939 episodes, mean reward 3.241, speed 58.37 f/s\n","1053937: done 4940 episodes, mean reward 3.242, speed 58.53 f/s\n","1054175: done 4941 episodes, mean reward 3.227, speed 58.54 f/s\n","1054531: done 4942 episodes, mean reward 3.241, speed 58.00 f/s\n","1055004: done 4943 episodes, mean reward 3.258, speed 58.57 f/s\n","1055373: done 4944 episodes, mean reward 3.202, speed 58.47 f/s\n","1055636: done 4945 episodes, mean reward 3.208, speed 57.83 f/s\n","1055840: done 4946 episodes, mean reward 3.191, speed 56.99 f/s\n","1056050: done 4947 episodes, mean reward 3.177, speed 57.22 f/s\n","1056979: done 4948 episodes, mean reward 3.155, speed 59.51 f/s\n","1057217: done 4949 episodes, mean reward 3.171, speed 57.49 f/s\n","1057529: done 4950 episodes, mean reward 3.173, speed 57.55 f/s\n","1057843: done 4951 episodes, mean reward 3.182, speed 58.34 f/s\n","1058843: done 4952 episodes, mean reward 3.201, speed 59.94 f/s\n","1059044: done 4953 episodes, mean reward 3.164, speed 56.73 f/s\n","1059212: done 4954 episodes, mean reward 3.154, speed 57.52 f/s\n","1059472: done 4955 episodes, mean reward 3.142, speed 59.06 f/s\n","1059678: done 4956 episodes, mean reward 3.140, speed 58.06 f/s\n","1059950: done 4957 episodes, mean reward 3.104, speed 58.70 f/s\n","EEEE tensor(-8.7214, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3366, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 21.58 sec, reward 2.746, steps 365\n","1060075: done 4958 episodes, mean reward 3.097, speed 5.25 f/s\n","1061075: done 4959 episodes, mean reward 3.111, speed 59.41 f/s\n","1061997: done 4960 episodes, mean reward 3.098, speed 58.77 f/s\n","1062457: done 4961 episodes, mean reward 3.118, speed 59.49 f/s\n","1062696: done 4962 episodes, mean reward 3.050, speed 58.28 f/s\n","1062871: done 4963 episodes, mean reward 3.060, speed 57.78 f/s\n","1062982: done 4964 episodes, mean reward 3.053, speed 57.01 f/s\n","1063345: done 4965 episodes, mean reward 3.019, speed 58.92 f/s\n","1064345: done 4966 episodes, mean reward 3.069, speed 60.24 f/s\n","1064663: done 4967 episodes, mean reward 3.066, speed 57.91 f/s\n","1064916: done 4968 episodes, mean reward 3.081, speed 58.27 f/s\n","1065716: done 4969 episodes, mean reward 3.119, speed 58.84 f/s\n","1066319: done 4970 episodes, mean reward 3.147, speed 59.40 f/s\n","1066468: done 4971 episodes, mean reward 3.135, speed 57.32 f/s\n","1066881: done 4972 episodes, mean reward 3.133, speed 56.12 f/s\n","1067058: done 4973 episodes, mean reward 3.097, speed 53.70 f/s\n","1067162: done 4974 episodes, mean reward 3.061, speed 52.13 f/s\n","1067394: done 4975 episodes, mean reward 3.018, speed 55.48 f/s\n","1067801: done 4976 episodes, mean reward 3.008, speed 56.29 f/s\n","1068462: done 4977 episodes, mean reward 3.012, speed 54.69 f/s\n","1068550: done 4978 episodes, mean reward 2.985, speed 53.57 f/s\n","1068890: done 4979 episodes, mean reward 2.981, speed 58.97 f/s\n","1069309: done 4980 episodes, mean reward 2.986, speed 58.45 f/s\n","1069526: done 4981 episodes, mean reward 2.970, speed 58.05 f/s\n","1069597: done 4982 episodes, mean reward 2.924, speed 53.99 f/s\n","EEEE tensor(-8.5483, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3504, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 21.11 sec, reward 2.244, steps 354\n","1070149: done 4983 episodes, mean reward 2.935, speed 18.16 f/s\n","1070409: done 4984 episodes, mean reward 2.943, speed 57.05 f/s\n","1071409: done 4985 episodes, mean reward 2.989, speed 58.97 f/s\n","1071709: done 4986 episodes, mean reward 2.967, speed 59.25 f/s\n","1071979: done 4987 episodes, mean reward 2.924, speed 58.91 f/s\n","1072685: done 4988 episodes, mean reward 2.960, speed 59.65 f/s\n","1073054: done 4989 episodes, mean reward 2.970, speed 58.29 f/s\n","1073349: done 4990 episodes, mean reward 2.974, speed 58.46 f/s\n","1073541: done 4991 episodes, mean reward 2.973, speed 57.37 f/s\n","1074073: done 4992 episodes, mean reward 3.006, speed 59.25 f/s\n","1074295: done 4993 episodes, mean reward 2.983, speed 57.93 f/s\n","1074370: done 4994 episodes, mean reward 2.965, speed 53.76 f/s\n","1074917: done 4995 episodes, mean reward 2.985, speed 58.63 f/s\n","1075566: done 4996 episodes, mean reward 2.983, speed 60.11 f/s\n","1076009: done 4997 episodes, mean reward 3.000, speed 60.02 f/s\n","1076465: done 4998 episodes, mean reward 3.041, speed 59.54 f/s\n","1077090: done 4999 episodes, mean reward 3.022, speed 59.44 f/s\n","1077796: done 5000 episodes, mean reward 2.998, speed 59.84 f/s\n","1078049: done 5001 episodes, mean reward 2.975, speed 58.68 f/s\n","1078278: done 5002 episodes, mean reward 2.970, speed 57.81 f/s\n","1078420: done 5003 episodes, mean reward 2.945, speed 56.42 f/s\n","1078917: done 5004 episodes, mean reward 2.966, speed 58.43 f/s\n","1079159: done 5005 episodes, mean reward 2.867, speed 58.19 f/s\n","1079942: done 5006 episodes, mean reward 2.909, speed 59.86 f/s\n","EEEE tensor(-7.5903, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3401, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 27.84 sec, reward 3.490, steps 476\n","1080129: done 5007 episodes, mean reward 2.909, speed 6.00 f/s\n","1080600: done 5008 episodes, mean reward 2.936, speed 59.45 f/s\n","1081288: done 5009 episodes, mean reward 2.960, speed 59.29 f/s\n","1081392: done 5010 episodes, mean reward 2.950, speed 55.20 f/s\n","1081603: done 5011 episodes, mean reward 2.885, speed 55.88 f/s\n","1081881: done 5012 episodes, mean reward 2.850, speed 58.42 f/s\n","1081946: done 5013 episodes, mean reward 2.824, speed 52.66 f/s\n","1082092: done 5014 episodes, mean reward 2.820, speed 56.96 f/s\n","1082466: done 5015 episodes, mean reward 2.768, speed 58.79 f/s\n","1082950: done 5016 episodes, mean reward 2.795, speed 59.56 f/s\n","1083275: done 5017 episodes, mean reward 2.817, speed 58.83 f/s\n","1083684: done 5018 episodes, mean reward 2.818, speed 58.79 f/s\n","1084068: done 5019 episodes, mean reward 2.822, speed 59.41 f/s\n","1084278: done 5020 episodes, mean reward 2.823, speed 57.51 f/s\n","1084578: done 5021 episodes, mean reward 2.772, speed 57.57 f/s\n","1084911: done 5022 episodes, mean reward 2.755, speed 58.44 f/s\n","1085189: done 5023 episodes, mean reward 2.742, speed 58.42 f/s\n","1085428: done 5024 episodes, mean reward 2.748, speed 57.18 f/s\n","1085624: done 5025 episodes, mean reward 2.729, speed 56.67 f/s\n","1085972: done 5026 episodes, mean reward 2.718, speed 58.33 f/s\n","1086024: done 5027 episodes, mean reward 2.711, speed 50.20 f/s\n","1086239: done 5028 episodes, mean reward 2.721, speed 57.28 f/s\n","1086313: done 5029 episodes, mean reward 2.693, speed 54.17 f/s\n","1086388: done 5030 episodes, mean reward 2.678, speed 53.73 f/s\n","1086453: done 5031 episodes, mean reward 2.666, speed 53.10 f/s\n","1086650: done 5032 episodes, mean reward 2.674, speed 57.30 f/s\n","1086744: done 5033 episodes, mean reward 2.617, speed 55.29 f/s\n","1087368: done 5034 episodes, mean reward 2.622, speed 59.91 f/s\n","1087517: done 5035 episodes, mean reward 2.594, speed 57.68 f/s\n","1087624: done 5036 episodes, mean reward 2.587, speed 56.34 f/s\n","1088138: done 5037 episodes, mean reward 2.546, speed 58.75 f/s\n","1088911: done 5038 episodes, mean reward 2.600, speed 59.74 f/s\n","1089138: done 5039 episodes, mean reward 2.591, speed 57.93 f/s\n","1089369: done 5040 episodes, mean reward 2.579, speed 58.50 f/s\n","1089611: done 5041 episodes, mean reward 2.574, speed 57.61 f/s\n","1089980: done 5042 episodes, mean reward 2.579, speed 58.74 f/s\n","EEEE tensor(-8.0300, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3379, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 13.48 sec, reward 1.935, steps 218\n","1090151: done 5043 episodes, mean reward 2.563, speed 10.37 f/s\n","1090687: done 5044 episodes, mean reward 2.577, speed 58.54 f/s\n","1091187: done 5045 episodes, mean reward 2.590, speed 59.55 f/s\n","1091736: done 5046 episodes, mean reward 2.628, speed 59.76 f/s\n","1091884: done 5047 episodes, mean reward 2.621, speed 57.04 f/s\n","1092042: done 5048 episodes, mean reward 2.570, speed 56.60 f/s\n","1092399: done 5049 episodes, mean reward 2.582, speed 59.68 f/s\n","1092680: done 5050 episodes, mean reward 2.585, speed 58.48 f/s\n","1092916: done 5051 episodes, mean reward 2.590, speed 59.07 f/s\n","1093217: done 5052 episodes, mean reward 2.519, speed 58.48 f/s\n","1093508: done 5053 episodes, mean reward 2.535, speed 58.78 f/s\n","1094022: done 5054 episodes, mean reward 2.559, speed 58.74 f/s\n","1094086: done 5055 episodes, mean reward 2.546, speed 53.44 f/s\n","1094150: done 5056 episodes, mean reward 2.529, speed 52.55 f/s\n","1094893: done 5057 episodes, mean reward 2.570, speed 59.65 f/s\n","1095769: done 5058 episodes, mean reward 2.607, speed 58.36 f/s\n","1096769: done 5059 episodes, mean reward 2.616, speed 59.63 f/s\n","1096970: done 5060 episodes, mean reward 2.608, speed 57.01 f/s\n","1097794: done 5061 episodes, mean reward 2.625, speed 58.85 f/s\n","1098605: done 5062 episodes, mean reward 2.645, speed 60.01 f/s\n","1099184: done 5063 episodes, mean reward 2.671, speed 59.66 f/s\n","EEEE tensor(-7.4961, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3341, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 37.82 sec, reward 4.930, steps 663\n","1100035: done 5064 episodes, mean reward 2.723, speed 16.32 f/s\n","1100366: done 5065 episodes, mean reward 2.728, speed 58.97 f/s\n","1101103: done 5066 episodes, mean reward 2.682, speed 59.23 f/s\n","1101404: done 5067 episodes, mean reward 2.684, speed 57.91 f/s\n","1101573: done 5068 episodes, mean reward 2.676, speed 56.25 f/s\n","1102293: done 5069 episodes, mean reward 2.676, speed 58.99 f/s\n","1102889: done 5070 episodes, mean reward 2.677, speed 58.49 f/s\n","1103169: done 5071 episodes, mean reward 2.689, speed 58.91 f/s\n","1103718: done 5072 episodes, mean reward 2.707, speed 59.57 f/s\n","1104448: done 5073 episodes, mean reward 2.751, speed 59.65 f/s\n","1104590: done 5074 episodes, mean reward 2.760, speed 56.96 f/s\n","1104789: done 5075 episodes, mean reward 2.748, speed 57.88 f/s\n","1105613: done 5076 episodes, mean reward 2.775, speed 59.48 f/s\n","1105860: done 5077 episodes, mean reward 2.765, speed 58.70 f/s\n","1105988: done 5078 episodes, mean reward 2.769, speed 56.12 f/s\n","1106797: done 5079 episodes, mean reward 2.809, speed 58.58 f/s\n","1107034: done 5080 episodes, mean reward 2.805, speed 57.49 f/s\n","1108034: done 5081 episodes, mean reward 2.866, speed 59.51 f/s\n","1108335: done 5082 episodes, mean reward 2.891, speed 58.53 f/s\n","1108664: done 5083 episodes, mean reward 2.883, speed 58.78 f/s\n","1109094: done 5084 episodes, mean reward 2.886, speed 59.08 f/s\n","1109609: done 5085 episodes, mean reward 2.869, speed 59.34 f/s\n","1109781: done 5086 episodes, mean reward 2.857, speed 57.31 f/s\n","EEEE tensor(-8.2906, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2936, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 24.08 sec, reward 3.237, steps 408\n","1110781: done 5087 episodes, mean reward 2.898, speed 24.33 f/s\n","1110847: done 5088 episodes, mean reward 2.858, speed 53.66 f/s\n","1111134: done 5089 episodes, mean reward 2.852, speed 58.06 f/s\n","1111206: done 5090 episodes, mean reward 2.831, speed 53.33 f/s\n","1111275: done 5091 episodes, mean reward 2.820, speed 53.34 f/s\n","1111778: done 5092 episodes, mean reward 2.825, speed 59.08 f/s\n","1111841: done 5093 episodes, mean reward 2.811, speed 52.87 f/s\n","1112101: done 5094 episodes, mean reward 2.829, speed 57.69 f/s\n","1112288: done 5095 episodes, mean reward 2.809, speed 57.33 f/s\n","1112843: done 5096 episodes, mean reward 2.814, speed 59.46 f/s\n","1113843: done 5097 episodes, mean reward 2.871, speed 60.05 f/s\n","1114217: done 5098 episodes, mean reward 2.853, speed 58.93 f/s\n","1114353: done 5099 episodes, mean reward 2.817, speed 56.61 f/s\n","1114599: done 5100 episodes, mean reward 2.771, speed 58.29 f/s\n","1114893: done 5101 episodes, mean reward 2.764, speed 57.52 f/s\n","1115014: done 5102 episodes, mean reward 2.754, speed 56.03 f/s\n","1115281: done 5103 episodes, mean reward 2.768, speed 58.03 f/s\n","1115540: done 5104 episodes, mean reward 2.755, speed 58.69 f/s\n","1115956: done 5105 episodes, mean reward 2.783, speed 59.64 f/s\n","1116956: done 5106 episodes, mean reward 2.817, speed 59.63 f/s\n","1117144: done 5107 episodes, mean reward 2.810, speed 58.00 f/s\n","1117501: done 5108 episodes, mean reward 2.788, speed 59.05 f/s\n","1118145: done 5109 episodes, mean reward 2.790, speed 59.50 f/s\n","1118435: done 5110 episodes, mean reward 2.815, speed 58.79 f/s\n","1118903: done 5111 episodes, mean reward 2.838, speed 58.30 f/s\n","1119168: done 5112 episodes, mean reward 2.842, speed 58.99 f/s\n","1119348: done 5113 episodes, mean reward 2.853, speed 57.43 f/s\n","1119922: done 5114 episodes, mean reward 2.898, speed 58.78 f/s\n","EEEE tensor(-7.4054, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2971, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 30.75 sec, reward 4.161, steps 531\n","1120573: done 5115 episodes, mean reward 2.920, speed 15.63 f/s\n","1120867: done 5116 episodes, mean reward 2.908, speed 59.57 f/s\n","1121782: done 5117 episodes, mean reward 2.960, speed 60.13 f/s\n","1122141: done 5118 episodes, mean reward 2.943, speed 58.60 f/s\n","1122402: done 5119 episodes, mean reward 2.935, speed 57.91 f/s\n","1122909: done 5120 episodes, mean reward 2.953, speed 59.36 f/s\n","1123301: done 5121 episodes, mean reward 2.965, speed 58.56 f/s\n","1123547: done 5122 episodes, mean reward 2.973, speed 58.75 f/s\n","1124291: done 5123 episodes, mean reward 3.004, speed 59.57 f/s\n","1124782: done 5124 episodes, mean reward 3.025, speed 59.00 f/s\n","1125441: done 5125 episodes, mean reward 3.073, speed 59.95 f/s\n","1126173: done 5126 episodes, mean reward 3.109, speed 59.50 f/s\n","1126286: done 5127 episodes, mean reward 3.115, speed 56.50 f/s\n","1126631: done 5128 episodes, mean reward 3.126, speed 58.09 f/s\n","1126851: done 5129 episodes, mean reward 3.141, speed 57.54 f/s\n","1127248: done 5130 episodes, mean reward 3.168, speed 59.34 f/s\n","1127447: done 5131 episodes, mean reward 3.179, speed 56.88 f/s\n","1127720: done 5132 episodes, mean reward 3.179, speed 58.06 f/s\n","1128275: done 5133 episodes, mean reward 3.208, speed 58.73 f/s\n","1128426: done 5134 episodes, mean reward 3.167, speed 56.46 f/s\n","1128919: done 5135 episodes, mean reward 3.193, speed 59.09 f/s\n","1129297: done 5136 episodes, mean reward 3.222, speed 58.92 f/s\n","1129672: done 5137 episodes, mean reward 3.237, speed 59.36 f/s\n","EEEE tensor(-7.5947, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3003, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 28.70 sec, reward 4.177, steps 493\n","1130185: done 5138 episodes, mean reward 3.203, speed 13.72 f/s\n","1130874: done 5139 episodes, mean reward 3.241, speed 59.48 f/s\n","1131453: done 5140 episodes, mean reward 3.271, speed 59.81 f/s\n","1131531: done 5141 episodes, mean reward 3.261, speed 54.26 f/s\n","1131849: done 5142 episodes, mean reward 3.250, speed 59.11 f/s\n","1131986: done 5143 episodes, mean reward 3.240, speed 57.00 f/s\n","1132466: done 5144 episodes, mean reward 3.225, speed 58.49 f/s\n","1132638: done 5145 episodes, mean reward 3.209, speed 57.56 f/s\n","1132897: done 5146 episodes, mean reward 3.185, speed 58.63 f/s\n","1133885: done 5147 episodes, mean reward 3.246, speed 60.00 f/s\n","1133971: done 5148 episodes, mean reward 3.240, speed 54.66 f/s\n","1134572: done 5149 episodes, mean reward 3.267, speed 59.44 f/s\n","1135127: done 5150 episodes, mean reward 3.271, speed 59.28 f/s\n","1135552: done 5151 episodes, mean reward 3.286, speed 58.59 f/s\n","1136078: done 5152 episodes, mean reward 3.297, speed 59.29 f/s\n","1136615: done 5153 episodes, mean reward 3.315, speed 59.01 f/s\n","1137021: done 5154 episodes, mean reward 3.305, speed 57.80 f/s\n","1137296: done 5155 episodes, mean reward 3.326, speed 58.25 f/s\n","1137771: done 5156 episodes, mean reward 3.356, speed 58.72 f/s\n","1138278: done 5157 episodes, mean reward 3.327, speed 59.64 f/s\n","1138698: done 5158 episodes, mean reward 3.317, speed 59.47 f/s\n","1138984: done 5159 episodes, mean reward 3.257, speed 58.50 f/s\n","1139644: done 5160 episodes, mean reward 3.278, speed 59.38 f/s\n","1139745: done 5161 episodes, mean reward 3.234, speed 55.69 f/s\n","EEEE tensor(-7.0972, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2912, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 16.05 sec, reward 2.031, steps 264\n","1140102: done 5162 episodes, mean reward 3.226, speed 16.10 f/s\n","1140643: done 5163 episodes, mean reward 3.224, speed 59.74 f/s\n","1141233: done 5164 episodes, mean reward 3.194, speed 58.69 f/s\n","1141981: done 5165 episodes, mean reward 3.216, speed 59.40 f/s\n","1142116: done 5166 episodes, mean reward 3.183, speed 57.00 f/s\n","1142440: done 5167 episodes, mean reward 3.182, speed 59.08 f/s\n","1142580: done 5168 episodes, mean reward 3.174, speed 56.30 f/s\n","1143186: done 5169 episodes, mean reward 3.168, speed 59.42 f/s\n","1143260: done 5170 episodes, mean reward 3.131, speed 53.76 f/s\n","1143529: done 5171 episodes, mean reward 3.123, speed 58.97 f/s\n","1143622: done 5172 episodes, mean reward 3.076, speed 55.22 f/s\n","1143758: done 5173 episodes, mean reward 3.033, speed 55.88 f/s\n","1144153: done 5174 episodes, mean reward 3.044, speed 57.05 f/s\n","1144251: done 5175 episodes, mean reward 3.040, speed 54.20 f/s\n","1144701: done 5176 episodes, mean reward 3.016, speed 58.96 f/s\n","1145415: done 5177 episodes, mean reward 3.064, speed 60.54 f/s\n","1145614: done 5178 episodes, mean reward 3.067, speed 57.48 f/s\n","1145877: done 5179 episodes, mean reward 3.034, speed 58.63 f/s\n","1146170: done 5180 episodes, mean reward 3.034, speed 59.06 f/s\n","1146824: done 5181 episodes, mean reward 3.011, speed 60.12 f/s\n","1146958: done 5182 episodes, mean reward 2.992, speed 57.21 f/s\n","1147958: done 5183 episodes, mean reward 3.057, speed 59.92 f/s\n","1148326: done 5184 episodes, mean reward 3.065, speed 57.81 f/s\n","1148704: done 5185 episodes, mean reward 3.060, speed 58.32 f/s\n","1148914: done 5186 episodes, mean reward 3.063, speed 57.37 f/s\n","1149233: done 5187 episodes, mean reward 3.027, speed 58.54 f/s\n","1149641: done 5188 episodes, mean reward 3.049, speed 59.19 f/s\n","1149866: done 5189 episodes, mean reward 3.046, speed 58.34 f/s\n","EEEE tensor(-8.4103, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2748, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 21.31 sec, reward 2.570, steps 359\n","1150153: done 5190 episodes, mean reward 3.060, speed 10.95 f/s\n","1150462: done 5191 episodes, mean reward 3.080, speed 58.73 f/s\n","1150525: done 5192 episodes, mean reward 3.038, speed 52.15 f/s\n","1150891: done 5193 episodes, mean reward 3.067, speed 59.30 f/s\n","1151315: done 5194 episodes, mean reward 3.079, speed 59.57 f/s\n","1151433: done 5195 episodes, mean reward 3.070, speed 56.70 f/s\n","1151517: done 5196 episodes, mean reward 3.027, speed 53.09 f/s\n","1151602: done 5197 episodes, mean reward 2.939, speed 54.62 f/s\n","1152584: done 5198 episodes, mean reward 2.978, speed 59.54 f/s\n","1153176: done 5199 episodes, mean reward 3.006, speed 59.47 f/s\n","1153790: done 5200 episodes, mean reward 3.040, speed 58.85 f/s\n","1154077: done 5201 episodes, mean reward 3.048, speed 57.86 f/s\n","1154952: done 5202 episodes, mean reward 3.114, speed 59.64 f/s\n","1155673: done 5203 episodes, mean reward 3.141, speed 59.35 f/s\n","1155823: done 5204 episodes, mean reward 3.132, speed 56.88 f/s\n","1156270: done 5205 episodes, mean reward 3.128, speed 58.56 f/s\n","1156485: done 5206 episodes, mean reward 3.052, speed 57.08 f/s\n","1157091: done 5207 episodes, mean reward 3.093, speed 59.05 f/s\n","1157537: done 5208 episodes, mean reward 3.108, speed 58.44 f/s\n","1158537: done 5209 episodes, mean reward 3.133, speed 59.29 f/s\n","1158644: done 5210 episodes, mean reward 3.110, speed 54.80 f/s\n","1159209: done 5211 episodes, mean reward 3.140, speed 58.89 f/s\n","1159893: done 5212 episodes, mean reward 3.163, speed 59.23 f/s\n","EEEE tensor(-7.9875, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2863, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 22.41 sec, reward 2.512, steps 362\n","1160278: done 5213 episodes, mean reward 3.177, speed 13.25 f/s\n","1160809: done 5214 episodes, mean reward 3.171, speed 58.39 f/s\n","1161809: done 5215 episodes, mean reward 3.191, speed 59.23 f/s\n","1161970: done 5216 episodes, mean reward 3.179, speed 56.42 f/s\n","1162417: done 5217 episodes, mean reward 3.120, speed 58.51 f/s\n","1162502: done 5218 episodes, mean reward 3.104, speed 54.02 f/s\n","1163029: done 5219 episodes, mean reward 3.113, speed 59.24 f/s\n","1163758: done 5220 episodes, mean reward 3.135, speed 59.39 f/s\n","1164758: done 5221 episodes, mean reward 3.175, speed 59.70 f/s\n","1164996: done 5222 episodes, mean reward 3.171, speed 58.09 f/s\n","1165639: done 5223 episodes, mean reward 3.158, speed 58.58 f/s\n","1166162: done 5224 episodes, mean reward 3.158, speed 58.76 f/s\n","1167161: done 5225 episodes, mean reward 3.167, speed 59.96 f/s\n","1167942: done 5226 episodes, mean reward 3.156, speed 59.50 f/s\n","1168238: done 5228 episodes, mean reward 3.142, speed 57.20 f/s\n","1168591: done 5229 episodes, mean reward 3.140, speed 58.70 f/s\n","1169136: done 5230 episodes, mean reward 3.161, speed 59.48 f/s\n","EEEE tensor(-6.7313, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2987, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 21.24 sec, reward 2.912, steps 360\n","1170021: done 5231 episodes, mean reward 3.209, speed 24.45 f/s\n","1170433: done 5232 episodes, mean reward 3.233, speed 59.65 f/s\n","1170775: done 5233 episodes, mean reward 3.225, speed 59.24 f/s\n","1171150: done 5234 episodes, mean reward 3.257, speed 59.15 f/s\n","1171300: done 5235 episodes, mean reward 3.233, speed 56.88 f/s\n","1171531: done 5236 episodes, mean reward 3.216, speed 57.94 f/s\n","1172142: done 5237 episodes, mean reward 3.221, speed 59.31 f/s\n","1172374: done 5238 episodes, mean reward 3.214, speed 58.33 f/s\n","1172707: done 5239 episodes, mean reward 3.194, speed 58.78 f/s\n","1172998: done 5240 episodes, mean reward 3.175, speed 59.27 f/s\n","1173483: done 5241 episodes, mean reward 3.220, speed 59.30 f/s\n","1173644: done 5242 episodes, mean reward 3.210, speed 56.64 f/s\n","1173796: done 5243 episodes, mean reward 3.213, speed 55.93 f/s\n","1174021: done 5244 episodes, mean reward 3.209, speed 58.29 f/s\n","1174236: done 5245 episodes, mean reward 3.205, speed 56.82 f/s\n","1174761: done 5246 episodes, mean reward 3.215, speed 59.10 f/s\n","1175528: done 5247 episodes, mean reward 3.186, speed 59.33 f/s\n","1175833: done 5248 episodes, mean reward 3.211, speed 58.89 f/s\n","1175922: done 5249 episodes, mean reward 3.158, speed 55.16 f/s\n","1176117: done 5250 episodes, mean reward 3.143, speed 57.95 f/s\n","1176201: done 5251 episodes, mean reward 3.110, speed 54.96 f/s\n","1177073: done 5252 episodes, mean reward 3.134, speed 59.32 f/s\n","1177153: done 5253 episodes, mean reward 3.099, speed 54.33 f/s\n","1177404: done 5254 episodes, mean reward 3.088, speed 58.58 f/s\n","1178404: done 5255 episodes, mean reward 3.131, speed 59.40 f/s\n","1178606: done 5256 episodes, mean reward 3.117, speed 57.70 f/s\n","1179285: done 5258 episodes, mean reward 3.103, speed 58.85 f/s\n","1179523: done 5259 episodes, mean reward 3.103, speed 57.67 f/s\n","1179634: done 5260 episodes, mean reward 3.071, speed 55.63 f/s\n","1179916: done 5261 episodes, mean reward 3.089, speed 58.52 f/s\n","EEEE tensor(-8.0409, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2773, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 24.66 sec, reward 3.539, steps 419\n","1180515: done 5262 episodes, mean reward 3.113, speed 17.25 f/s\n","1180749: done 5263 episodes, mean reward 3.098, speed 58.27 f/s\n","1180891: done 5264 episodes, mean reward 3.078, speed 56.90 f/s\n","1181310: done 5265 episodes, mean reward 3.043, speed 58.65 f/s\n","1181802: done 5266 episodes, mean reward 3.084, speed 59.01 f/s\n","1182067: done 5267 episodes, mean reward 3.090, speed 58.76 f/s\n","1182953: done 5268 episodes, mean reward 3.162, speed 59.79 f/s\n","1183695: done 5269 episodes, mean reward 3.171, speed 59.53 f/s\n","1184108: done 5270 episodes, mean reward 3.198, speed 59.62 f/s\n","1185108: done 5271 episodes, mean reward 3.255, speed 59.99 f/s\n","1186108: done 5272 episodes, mean reward 3.306, speed 59.65 f/s\n","1186266: done 5273 episodes, mean reward 3.311, speed 57.58 f/s\n","1186915: done 5274 episodes, mean reward 3.346, speed 59.28 f/s\n","1187915: done 5275 episodes, mean reward 3.432, speed 59.81 f/s\n","1188899: done 5276 episodes, mean reward 3.457, speed 57.59 f/s\n","1189139: done 5277 episodes, mean reward 3.402, speed 51.56 f/s\n","1189763: done 5278 episodes, mean reward 3.422, speed 54.35 f/s\n","EEEE tensor(-8.4233, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2693, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0003, grad_fn=<ExpBackward>)\n","Test done in 26.41 sec, reward 3.886, steps 402\n","1190258: done 5279 episodes, mean reward 3.431, speed 13.97 f/s\n","1190913: done 5280 episodes, mean reward 3.460, speed 54.75 f/s\n","1191137: done 5281 episodes, mean reward 3.418, speed 55.26 f/s\n","1192137: done 5282 episodes, mean reward 3.487, speed 56.32 f/s\n","1192294: done 5283 episodes, mean reward 3.401, speed 53.69 f/s\n","1192621: done 5284 episodes, mean reward 3.390, speed 55.56 f/s\n","1193032: done 5285 episodes, mean reward 3.386, speed 51.79 f/s\n","1193290: done 5286 episodes, mean reward 3.383, speed 53.90 f/s\n","1193669: done 5287 episodes, mean reward 3.390, speed 52.46 f/s\n","1193918: done 5288 episodes, mean reward 3.388, speed 51.87 f/s\n","1194260: done 5289 episodes, mean reward 3.391, speed 52.10 f/s\n","1194692: done 5290 episodes, mean reward 3.413, speed 52.54 f/s\n","1195050: done 5291 episodes, mean reward 3.414, speed 55.37 f/s\n","1195335: done 5292 episodes, mean reward 3.437, speed 55.59 f/s\n","1195667: done 5293 episodes, mean reward 3.434, speed 56.60 f/s\n","1196127: done 5294 episodes, mean reward 3.431, speed 56.24 f/s\n","1196983: done 5295 episodes, mean reward 3.490, speed 56.31 f/s\n","1197497: done 5296 episodes, mean reward 3.515, speed 56.01 f/s\n","1197680: done 5297 episodes, mean reward 3.520, speed 54.11 f/s\n","1197884: done 5298 episodes, mean reward 3.477, speed 55.19 f/s\n","1198157: done 5299 episodes, mean reward 3.464, speed 55.10 f/s\n","1198396: done 5300 episodes, mean reward 3.425, speed 54.54 f/s\n","1198522: done 5301 episodes, mean reward 3.407, speed 52.63 f/s\n","1198745: done 5302 episodes, mean reward 3.348, speed 53.31 f/s\n","1199452: done 5303 episodes, mean reward 3.334, speed 55.68 f/s\n","1199540: done 5304 episodes, mean reward 3.327, speed 51.74 f/s\n","1199645: done 5305 episodes, mean reward 3.296, speed 51.99 f/s\n","EEEE tensor(-8.4654, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2802, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0003, grad_fn=<ExpBackward>)\n","Test done in 33.51 sec, reward 5.015, steps 542\n","1200645: done 5306 episodes, mean reward 3.375, speed 19.45 f/s\n","1200817: done 5307 episodes, mean reward 3.338, speed 51.70 f/s\n","1201335: done 5309 episodes, mean reward 3.254, speed 53.84 f/s\n","1201936: done 5310 episodes, mean reward 3.307, speed 56.02 f/s\n","1202066: done 5311 episodes, mean reward 3.251, speed 53.83 f/s\n","1202390: done 5312 episodes, mean reward 3.226, speed 55.60 f/s\n","1202695: done 5313 episodes, mean reward 3.224, speed 54.54 f/s\n","1202881: done 5314 episodes, mean reward 3.189, speed 54.79 f/s\n","1203274: done 5315 episodes, mean reward 3.143, speed 54.35 f/s\n","1204316: done 5317 episodes, mean reward 3.218, speed 56.34 f/s\n","1205028: done 5318 episodes, mean reward 3.291, speed 56.93 f/s\n","1206004: done 5319 episodes, mean reward 3.319, speed 57.46 f/s\n","1206104: done 5320 episodes, mean reward 3.269, speed 52.51 f/s\n","1207104: done 5321 episodes, mean reward 3.299, speed 57.30 f/s\n","1207617: done 5322 episodes, mean reward 3.326, speed 55.98 f/s\n","1207973: done 5323 episodes, mean reward 3.318, speed 55.53 f/s\n","1208973: done 5324 episodes, mean reward 3.382, speed 56.98 f/s\n","1209167: done 5325 episodes, mean reward 3.330, speed 54.55 f/s\n","1209430: done 5326 episodes, mean reward 3.314, speed 55.57 f/s\n","EEEE tensor(-8.4676, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2855, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0003, grad_fn=<ExpBackward>)\n","Test done in 23.74 sec, reward 3.157, steps 381\n","1210430: done 5327 episodes, mean reward 3.408, speed 24.27 f/s\n","1211319: done 5328 episodes, mean reward 3.481, speed 57.88 f/s\n","1211498: done 5329 episodes, mean reward 3.479, speed 54.07 f/s\n","1211923: done 5330 episodes, mean reward 3.482, speed 56.59 f/s\n","1212128: done 5331 episodes, mean reward 3.433, speed 55.73 f/s\n","1212698: done 5332 episodes, mean reward 3.444, speed 57.02 f/s\n","1213301: done 5333 episodes, mean reward 3.464, speed 56.87 f/s\n","1213660: done 5334 episodes, mean reward 3.443, speed 54.98 f/s\n","1214035: done 5335 episodes, mean reward 3.461, speed 56.24 f/s\n","1214765: done 5336 episodes, mean reward 3.502, speed 57.26 f/s\n","1215173: done 5337 episodes, mean reward 3.488, speed 56.48 f/s\n","1215368: done 5338 episodes, mean reward 3.488, speed 55.63 f/s\n","1215543: done 5339 episodes, mean reward 3.465, speed 55.34 f/s\n","1216125: done 5340 episodes, mean reward 3.502, speed 57.10 f/s\n","1216333: done 5341 episodes, mean reward 3.467, speed 56.03 f/s\n","1216533: done 5342 episodes, mean reward 3.462, speed 55.47 f/s\n","1216873: done 5343 episodes, mean reward 3.495, speed 56.32 f/s\n","1217393: done 5344 episodes, mean reward 3.521, speed 56.73 f/s\n","1217520: done 5345 episodes, mean reward 3.523, speed 54.23 f/s\n","1217747: done 5346 episodes, mean reward 3.510, speed 55.81 f/s\n","1218141: done 5347 episodes, mean reward 3.505, speed 55.46 f/s\n","1218844: done 5348 episodes, mean reward 3.536, speed 57.71 f/s\n","1219649: done 5349 episodes, mean reward 3.575, speed 56.88 f/s\n","EEEE tensor(-8.5215, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2692, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 33.43 sec, reward 4.173, steps 546\n","1220649: done 5350 episodes, mean reward 3.613, speed 19.65 f/s\n","1220857: done 5351 episodes, mean reward 3.619, speed 55.09 f/s\n","1221263: done 5352 episodes, mean reward 3.584, speed 55.82 f/s\n","1221932: done 5353 episodes, mean reward 3.629, speed 57.11 f/s\n","1222713: done 5354 episodes, mean reward 3.682, speed 56.75 f/s\n","1222923: done 5355 episodes, mean reward 3.631, speed 55.57 f/s\n","1223066: done 5356 episodes, mean reward 3.624, speed 54.89 f/s\n","1223586: done 5357 episodes, mean reward 3.676, speed 57.31 f/s\n","1223739: done 5358 episodes, mean reward 3.634, speed 54.99 f/s\n","1224182: done 5359 episodes, mean reward 3.643, speed 56.67 f/s\n","1224721: done 5360 episodes, mean reward 3.677, speed 56.44 f/s\n","1225024: done 5361 episodes, mean reward 3.682, speed 55.98 f/s\n","1225481: done 5362 episodes, mean reward 3.665, speed 56.15 f/s\n","1226136: done 5363 episodes, mean reward 3.730, speed 57.56 f/s\n","1226545: done 5364 episodes, mean reward 3.754, speed 55.66 f/s\n","1227173: done 5365 episodes, mean reward 3.781, speed 57.10 f/s\n","1227376: done 5366 episodes, mean reward 3.743, speed 55.77 f/s\n","1228120: done 5367 episodes, mean reward 3.779, speed 57.38 f/s\n","1228492: done 5368 episodes, mean reward 3.725, speed 56.19 f/s\n","1228641: done 5369 episodes, mean reward 3.677, speed 54.90 f/s\n","1228725: done 5370 episodes, mean reward 3.651, speed 52.98 f/s\n","1228881: done 5371 episodes, mean reward 3.590, speed 53.93 f/s\n","1229232: done 5372 episodes, mean reward 3.566, speed 55.18 f/s\n","1229734: done 5373 episodes, mean reward 3.612, speed 55.80 f/s\n","EEEE tensor(-8.0798, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2772, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 13.03 sec, reward 1.233, steps 195\n","1230604: done 5374 episodes, mean reward 3.619, speed 30.67 f/s\n","1231109: done 5375 episodes, mean reward 3.570, speed 56.94 f/s\n","1231212: done 5376 episodes, mean reward 3.523, speed 51.90 f/s\n","1231724: done 5377 episodes, mean reward 3.540, speed 55.92 f/s\n","1232724: done 5378 episodes, mean reward 3.603, speed 56.93 f/s\n","1233284: done 5379 episodes, mean reward 3.647, speed 55.98 f/s\n","1234284: done 5380 episodes, mean reward 3.669, speed 55.66 f/s\n","1234401: done 5381 episodes, mean reward 3.665, speed 51.70 f/s\n","1235095: done 5382 episodes, mean reward 3.642, speed 56.31 f/s\n","1235278: done 5383 episodes, mean reward 3.652, speed 55.06 f/s\n","1236103: done 5385 episodes, mean reward 3.658, speed 55.68 f/s\n","1236975: done 5386 episodes, mean reward 3.726, speed 56.61 f/s\n","1237035: done 5387 episodes, mean reward 3.692, speed 49.97 f/s\n","1237140: done 5388 episodes, mean reward 3.674, speed 53.74 f/s\n","1237720: done 5389 episodes, mean reward 3.714, speed 57.40 f/s\n","1238367: done 5390 episodes, mean reward 3.748, speed 55.72 f/s\n","1238465: done 5391 episodes, mean reward 3.730, speed 51.49 f/s\n","1239393: done 5392 episodes, mean reward 3.806, speed 56.40 f/s\n","1239745: done 5393 episodes, mean reward 3.816, speed 52.83 f/s\n","1239985: done 5395 episodes, mean reward 3.739, speed 51.36 f/s\n","EEEE tensor(-8.0007, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2798, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 19.26 sec, reward 3.179, steps 293\n","1240074: done 5396 episodes, mean reward 3.714, speed 4.22 f/s\n","1240402: done 5398 episodes, mean reward 3.721, speed 52.81 f/s\n","1240714: done 5399 episodes, mean reward 3.722, speed 54.24 f/s\n","1240933: done 5401 episodes, mean reward 3.718, speed 53.55 f/s\n","1241122: done 5402 episodes, mean reward 3.721, speed 54.69 f/s\n","1241527: done 5403 episodes, mean reward 3.742, speed 55.87 f/s\n","1241980: done 5404 episodes, mean reward 3.790, speed 56.13 f/s\n","1242287: done 5405 episodes, mean reward 3.809, speed 56.64 f/s\n","1242693: done 5406 episodes, mean reward 3.773, speed 56.99 f/s\n","1242971: done 5407 episodes, mean reward 3.782, speed 47.61 f/s\n","1243868: done 5408 episodes, mean reward 3.881, speed 47.70 f/s\n","1244394: done 5410 episodes, mean reward 3.844, speed 46.38 f/s\n","1245046: done 5411 episodes, mean reward 3.898, speed 47.58 f/s\n","1245267: done 5413 episodes, mean reward 3.866, speed 44.54 f/s\n","1245311: done 5414 episodes, mean reward 3.853, speed 39.80 f/s\n","1245531: done 5415 episodes, mean reward 3.837, speed 46.13 f/s\n","1245851: done 5416 episodes, mean reward 3.860, speed 46.34 f/s\n","1245974: done 5417 episodes, mean reward 3.768, speed 45.09 f/s\n","1246064: done 5418 episodes, mean reward 3.698, speed 43.39 f/s\n","1246346: done 5419 episodes, mean reward 3.668, speed 46.91 f/s\n","1246492: done 5421 episodes, mean reward 3.576, speed 43.34 f/s\n","1246670: done 5422 episodes, mean reward 3.534, speed 45.96 f/s\n","1247379: done 5423 episodes, mean reward 3.566, speed 47.73 f/s\n","1247958: done 5424 episodes, mean reward 3.496, speed 46.72 f/s\n","1248289: done 5425 episodes, mean reward 3.507, speed 45.66 f/s\n","1248457: done 5426 episodes, mean reward 3.493, speed 45.25 f/s\n","1249194: done 5427 episodes, mean reward 3.468, speed 47.41 f/s\n","1249673: done 5428 episodes, mean reward 3.403, speed 46.93 f/s\n","1249874: done 5429 episodes, mean reward 3.409, speed 46.38 f/s\n","EEEE tensor(-8.1895, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2946, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 18.80 sec, reward 2.187, steps 245\n","1250237: done 5430 episodes, mean reward 3.399, speed 13.69 f/s\n","1250335: done 5431 episodes, mean reward 3.394, speed 43.95 f/s\n","1250378: done 5432 episodes, mean reward 3.346, speed 39.93 f/s\n","1250418: done 5433 episodes, mean reward 3.301, speed 39.74 f/s\n","1251193: done 5434 episodes, mean reward 3.346, speed 47.21 f/s\n","1251408: done 5435 episodes, mean reward 3.330, speed 46.23 f/s\n","1251747: done 5436 episodes, mean reward 3.308, speed 46.60 f/s\n","1251834: done 5437 episodes, mean reward 3.281, speed 43.97 f/s\n","1252274: done 5438 episodes, mean reward 3.317, speed 47.48 f/s\n","1252471: done 5439 episodes, mean reward 3.326, speed 46.33 f/s\n","1252818: done 5440 episodes, mean reward 3.282, speed 46.59 f/s\n","1253476: done 5441 episodes, mean reward 3.327, speed 47.30 f/s\n","1253951: done 5442 episodes, mean reward 3.366, speed 47.41 f/s\n","1254155: done 5443 episodes, mean reward 3.342, speed 46.24 f/s\n","1254383: done 5444 episodes, mean reward 3.315, speed 46.37 f/s\n","1255383: done 5445 episodes, mean reward 3.374, speed 47.86 f/s\n","1255596: done 5446 episodes, mean reward 3.364, speed 46.21 f/s\n","1255979: done 5447 episodes, mean reward 3.360, speed 47.30 f/s\n","1256147: done 5448 episodes, mean reward 3.316, speed 45.44 f/s\n","1256737: done 5449 episodes, mean reward 3.348, speed 47.26 f/s\n","1257311: done 5450 episodes, mean reward 3.358, speed 47.38 f/s\n","1257534: done 5451 episodes, mean reward 3.367, speed 46.43 f/s\n","1258400: done 5452 episodes, mean reward 3.432, speed 47.84 f/s\n","1258744: done 5453 episodes, mean reward 3.410, speed 47.08 f/s\n","1259487: done 5454 episodes, mean reward 3.415, speed 47.53 f/s\n","EEEE tensor(-7.2447, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2998, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 23.83 sec, reward 2.755, steps 321\n","1260008: done 5455 episodes, mean reward 3.463, speed 14.97 f/s\n","1260133: done 5456 episodes, mean reward 3.460, speed 44.77 f/s\n","1260456: done 5457 episodes, mean reward 3.439, speed 47.23 f/s\n","1260860: done 5458 episodes, mean reward 3.484, speed 47.10 f/s\n","1260930: done 5459 episodes, mean reward 3.463, speed 42.65 f/s\n","1261930: done 5460 episodes, mean reward 3.490, speed 47.66 f/s\n","1262867: done 5461 episodes, mean reward 3.562, speed 47.90 f/s\n","1263630: done 5462 episodes, mean reward 3.615, speed 47.80 f/s\n","1264441: done 5463 episodes, mean reward 3.610, speed 47.53 f/s\n","1265118: done 5464 episodes, mean reward 3.618, speed 47.19 f/s\n","1265159: done 5465 episodes, mean reward 3.576, speed 39.61 f/s\n","1265563: done 5466 episodes, mean reward 3.614, speed 46.92 f/s\n","1266180: done 5467 episodes, mean reward 3.616, speed 47.93 f/s\n","1266682: done 5468 episodes, mean reward 3.648, speed 47.71 f/s\n","1266840: done 5469 episodes, mean reward 3.653, speed 45.91 f/s\n","1267564: done 5470 episodes, mean reward 3.724, speed 47.88 f/s\n","1267766: done 5471 episodes, mean reward 3.721, speed 46.02 f/s\n","1268267: done 5472 episodes, mean reward 3.743, speed 47.89 f/s\n","1268310: done 5473 episodes, mean reward 3.688, speed 40.27 f/s\n","1268371: done 5474 episodes, mean reward 3.622, speed 42.09 f/s\n","1269331: done 5475 episodes, mean reward 3.701, speed 48.17 f/s\n","1269498: done 5476 episodes, mean reward 3.702, speed 45.81 f/s\n","1269654: done 5477 episodes, mean reward 3.676, speed 45.50 f/s\n","1269947: done 5478 episodes, mean reward 3.583, speed 45.96 f/s\n","EEEE tensor(-8.3953, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2910, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 25.38 sec, reward 3.627, steps 344\n","1270096: done 5479 episodes, mean reward 3.516, speed 5.20 f/s\n","1271096: done 5480 episodes, mean reward 3.579, speed 48.22 f/s\n","1271447: done 5481 episodes, mean reward 3.589, speed 47.25 f/s\n","1271591: done 5482 episodes, mean reward 3.545, speed 45.39 f/s\n","1271937: done 5483 episodes, mean reward 3.555, speed 47.38 f/s\n","1272569: done 5484 episodes, mean reward 3.619, speed 47.66 f/s\n","1272844: done 5485 episodes, mean reward 3.574, speed 46.85 f/s\n","1273680: done 5486 episodes, mean reward 3.557, speed 47.38 f/s\n","1273770: done 5487 episodes, mean reward 3.563, speed 43.97 f/s\n","1274236: done 5488 episodes, mean reward 3.599, speed 47.47 f/s\n","1274327: done 5489 episodes, mean reward 3.538, speed 43.67 f/s\n","1274523: done 5490 episodes, mean reward 3.490, speed 46.34 f/s\n","1275523: done 5491 episodes, mean reward 3.608, speed 47.99 f/s\n","1275766: done 5492 episodes, mean reward 3.534, speed 46.73 f/s\n","1275981: done 5493 episodes, mean reward 3.500, speed 45.71 f/s\n","1276440: done 5494 episodes, mean reward 3.543, speed 47.84 f/s\n","1276689: done 5495 episodes, mean reward 3.538, speed 46.97 f/s\n","1277261: done 5496 episodes, mean reward 3.590, speed 47.78 f/s\n","1278045: done 5497 episodes, mean reward 3.635, speed 47.22 f/s\n","1279045: done 5498 episodes, mean reward 3.691, speed 48.08 f/s\n","1279488: done 5499 episodes, mean reward 3.685, speed 47.31 f/s\n","1279872: done 5500 episodes, mean reward 3.726, speed 47.15 f/s\n","EEEE tensor(-7.4778, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2774, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 41.67 sec, reward 4.989, steps 576\n","1280273: done 5501 episodes, mean reward 3.748, speed 7.97 f/s\n","1281256: done 5502 episodes, mean reward 3.815, speed 47.58 f/s\n","1281335: done 5503 episodes, mean reward 3.759, speed 43.95 f/s\n","1281788: done 5504 episodes, mean reward 3.736, speed 46.95 f/s\n","1281910: done 5505 episodes, mean reward 3.713, speed 44.25 f/s\n","1282084: done 5506 episodes, mean reward 3.667, speed 45.82 f/s\n","1282336: done 5507 episodes, mean reward 3.657, speed 46.00 f/s\n","1282927: done 5508 episodes, mean reward 3.613, speed 47.71 f/s\n","1283232: done 5509 episodes, mean reward 3.639, speed 46.89 f/s\n","1283417: done 5510 episodes, mean reward 3.613, speed 45.93 f/s\n","1283575: done 5511 episodes, mean reward 3.562, speed 45.79 f/s\n","1284046: done 5512 episodes, mean reward 3.592, speed 47.07 f/s\n","1284172: done 5513 episodes, mean reward 3.583, speed 45.09 f/s\n","1284844: done 5514 episodes, mean reward 3.659, speed 47.47 f/s\n","1284923: done 5515 episodes, mean reward 3.656, speed 43.26 f/s\n","1285226: done 5516 episodes, mean reward 3.655, speed 46.91 f/s\n","1285269: done 5517 episodes, mean reward 3.645, speed 39.84 f/s\n","1286211: done 5518 episodes, mean reward 3.735, speed 47.69 f/s\n","1286982: done 5519 episodes, mean reward 3.774, speed 47.79 f/s\n","1287136: done 5520 episodes, mean reward 3.780, speed 45.33 f/s\n","1288136: done 5521 episodes, mean reward 3.851, speed 47.12 f/s\n","1288513: done 5522 episodes, mean reward 3.881, speed 47.17 f/s\n","1289513: done 5523 episodes, mean reward 3.895, speed 47.33 f/s\n","1289859: done 5524 episodes, mean reward 3.894, speed 47.13 f/s\n","EEEE tensor(-8.1719, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2994, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 18.68 sec, reward 1.812, steps 245\n","1290046: done 5525 episodes, mean reward 3.876, speed 8.19 f/s\n","1291046: done 5526 episodes, mean reward 3.966, speed 47.00 f/s\n","1291340: done 5527 episodes, mean reward 3.922, speed 46.92 f/s\n","1291390: done 5528 episodes, mean reward 3.895, speed 41.82 f/s\n","1291916: done 5529 episodes, mean reward 3.925, speed 48.24 f/s\n","1292116: done 5530 episodes, mean reward 3.896, speed 46.97 f/s\n","1292436: done 5531 episodes, mean reward 3.926, speed 48.18 f/s\n","1292545: done 5532 episodes, mean reward 3.931, speed 45.94 f/s\n","1292737: done 5533 episodes, mean reward 3.940, speed 47.39 f/s\n","1293737: done 5534 episodes, mean reward 3.981, speed 50.10 f/s\n","1294716: done 5535 episodes, mean reward 4.050, speed 53.85 f/s\n","1295361: done 5536 episodes, mean reward 4.076, speed 55.58 f/s\n","1295671: done 5537 episodes, mean reward 4.102, speed 55.68 f/s\n","1295832: done 5538 episodes, mean reward 4.061, speed 54.06 f/s\n","1296131: done 5539 episodes, mean reward 4.065, speed 56.33 f/s\n","1296452: done 5540 episodes, mean reward 4.056, speed 56.56 f/s\n","1297452: done 5541 episodes, mean reward 4.060, speed 57.66 f/s\n","1297881: done 5542 episodes, mean reward 4.036, speed 56.39 f/s\n","1298515: done 5543 episodes, mean reward 4.058, speed 54.86 f/s\n","1299363: done 5544 episodes, mean reward 4.102, speed 55.90 f/s\n","1299772: done 5545 episodes, mean reward 4.066, speed 56.27 f/s\n","1299889: done 5546 episodes, mean reward 4.058, speed 53.15 f/s\n","1299959: done 5547 episodes, mean reward 4.027, speed 50.46 f/s\n","EEEE tensor(-7.9420, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3196, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 37.95 sec, reward 5.786, steps 619\n","1300637: done 5548 episodes, mean reward 4.061, speed 13.56 f/s\n","1301197: done 5549 episodes, mean reward 4.017, speed 56.96 f/s\n","1301606: done 5550 episodes, mean reward 3.977, speed 55.31 f/s\n","1301723: done 5551 episodes, mean reward 3.961, speed 53.09 f/s\n","1302016: done 5552 episodes, mean reward 3.903, speed 55.06 f/s\n","1302410: done 5553 episodes, mean reward 3.908, speed 55.99 f/s\n","1303004: done 5554 episodes, mean reward 3.885, speed 56.28 f/s\n","1303095: done 5555 episodes, mean reward 3.823, speed 53.01 f/s\n","1303938: done 5556 episodes, mean reward 3.877, speed 56.55 f/s\n","1304190: done 5557 episodes, mean reward 3.865, speed 54.36 f/s\n","1304389: done 5558 episodes, mean reward 3.823, speed 54.62 f/s\n","1304801: done 5559 episodes, mean reward 3.856, speed 56.98 f/s\n","1305028: done 5560 episodes, mean reward 3.799, speed 55.91 f/s\n","1305867: done 5561 episodes, mean reward 3.777, speed 57.38 f/s\n","1306867: done 5562 episodes, mean reward 3.769, speed 57.44 f/s\n","1307147: done 5563 episodes, mean reward 3.716, speed 56.38 f/s\n","1307230: done 5564 episodes, mean reward 3.674, speed 51.85 f/s\n","1307589: done 5565 episodes, mean reward 3.711, speed 56.48 f/s\n","1307768: done 5566 episodes, mean reward 3.680, speed 55.73 f/s\n","1307898: done 5567 episodes, mean reward 3.630, speed 54.39 f/s\n","1308015: done 5568 episodes, mean reward 3.576, speed 54.30 f/s\n","1309015: done 5569 episodes, mean reward 3.683, speed 57.95 f/s\n","1309756: done 5570 episodes, mean reward 3.682, speed 48.16 f/s\n","EEEE tensor(-8.0475, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2629, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 33.38 sec, reward 4.182, steps 459\n","1310110: done 5571 episodes, mean reward 3.704, speed 8.67 f/s\n","1310446: done 5572 episodes, mean reward 3.686, speed 47.64 f/s\n","1310973: done 5573 episodes, mean reward 3.726, speed 47.92 f/s\n","1311270: done 5574 episodes, mean reward 3.748, speed 47.42 f/s\n","1311343: done 5575 episodes, mean reward 3.629, speed 43.70 f/s\n","1311710: done 5576 episodes, mean reward 3.665, speed 48.23 f/s\n","1312213: done 5577 episodes, mean reward 3.702, speed 48.50 f/s\n","1312423: done 5578 episodes, mean reward 3.709, speed 47.42 f/s\n","1313237: done 5579 episodes, mean reward 3.781, speed 47.97 f/s\n","1314237: done 5580 episodes, mean reward 3.728, speed 47.90 f/s\n","1314358: done 5581 episodes, mean reward 3.717, speed 45.20 f/s\n","1314668: done 5582 episodes, mean reward 3.735, speed 47.11 f/s\n","1314734: done 5583 episodes, mean reward 3.709, speed 43.11 f/s\n","1315164: done 5584 episodes, mean reward 3.685, speed 47.66 f/s\n","1316164: done 5585 episodes, mean reward 3.786, speed 48.07 f/s\n","1316853: done 5586 episodes, mean reward 3.796, speed 48.40 f/s\n","1317104: done 5587 episodes, mean reward 3.799, speed 47.22 f/s\n","1317976: done 5588 episodes, mean reward 3.840, speed 48.11 f/s\n","1318065: done 5589 episodes, mean reward 3.839, speed 43.59 f/s\n","1318353: done 5590 episodes, mean reward 3.838, speed 47.66 f/s\n","1318428: done 5591 episodes, mean reward 3.717, speed 43.75 f/s\n","1318584: done 5592 episodes, mean reward 3.701, speed 45.99 f/s\n","1318966: done 5593 episodes, mean reward 3.727, speed 47.50 f/s\n","1319032: done 5594 episodes, mean reward 3.684, speed 42.60 f/s\n","1319114: done 5595 episodes, mean reward 3.670, speed 43.84 f/s\n","1319415: done 5596 episodes, mean reward 3.624, speed 47.33 f/s\n","EEEE tensor(-8.0270, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2945, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 18.59 sec, reward 1.929, steps 248\n","1320081: done 5597 episodes, mean reward 3.657, speed 20.52 f/s\n","1320382: done 5598 episodes, mean reward 3.589, speed 47.60 f/s\n","1320516: done 5599 episodes, mean reward 3.574, speed 45.55 f/s\n","1320741: done 5600 episodes, mean reward 3.550, speed 46.33 f/s\n","1320928: done 5601 episodes, mean reward 3.522, speed 46.49 f/s\n","1321293: done 5602 episodes, mean reward 3.462, speed 47.63 f/s\n","1321383: done 5603 episodes, mean reward 3.462, speed 44.88 f/s\n","1321535: done 5604 episodes, mean reward 3.447, speed 45.92 f/s\n","1321723: done 5605 episodes, mean reward 3.458, speed 46.06 f/s\n","1321790: done 5606 episodes, mean reward 3.449, speed 42.81 f/s\n","1322237: done 5607 episodes, mean reward 3.474, speed 46.99 f/s\n","1322368: done 5608 episodes, mean reward 3.425, speed 45.88 f/s\n","1322458: done 5609 episodes, mean reward 3.406, speed 44.03 f/s\n","1323124: done 5610 episodes, mean reward 3.428, speed 48.46 f/s\n","1323541: done 5611 episodes, mean reward 3.440, speed 47.65 f/s\n","1324284: done 5612 episodes, mean reward 3.486, speed 48.28 f/s\n","1324357: done 5613 episodes, mean reward 3.479, speed 43.78 f/s\n","1325357: done 5614 episodes, mean reward 3.510, speed 48.43 f/s\n","1325786: done 5615 episodes, mean reward 3.547, speed 47.82 f/s\n","1326069: done 5616 episodes, mean reward 3.546, speed 46.84 f/s\n","1326357: done 5617 episodes, mean reward 3.567, speed 47.18 f/s\n","1327001: done 5618 episodes, mean reward 3.533, speed 48.13 f/s\n","1327176: done 5619 episodes, mean reward 3.476, speed 46.34 f/s\n","1327236: done 5620 episodes, mean reward 3.472, speed 42.02 f/s\n","1327550: done 5621 episodes, mean reward 3.424, speed 47.15 f/s\n","1327924: done 5622 episodes, mean reward 3.409, speed 47.01 f/s\n","1328324: done 5623 episodes, mean reward 3.362, speed 47.27 f/s\n","1328528: done 5624 episodes, mean reward 3.345, speed 46.79 f/s\n","1328764: done 5625 episodes, mean reward 3.357, speed 46.79 f/s\n","1329263: done 5626 episodes, mean reward 3.315, speed 47.93 f/s\n","1329453: done 5627 episodes, mean reward 3.303, speed 46.30 f/s\n","EEEE tensor(-7.3789, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2846, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 27.35 sec, reward 3.116, steps 365\n","1330246: done 5628 episodes, mean reward 3.345, speed 17.97 f/s\n","1331246: done 5629 episodes, mean reward 3.371, speed 48.06 f/s\n","1332246: done 5630 episodes, mean reward 3.451, speed 47.49 f/s\n","1332655: done 5631 episodes, mean reward 3.445, speed 47.58 f/s\n","1333655: done 5632 episodes, mean reward 3.541, speed 48.35 f/s\n","1333776: done 5633 episodes, mean reward 3.539, speed 45.68 f/s\n","1334231: done 5634 episodes, mean reward 3.485, speed 47.73 f/s\n","1334415: done 5635 episodes, mean reward 3.411, speed 46.13 f/s\n","1334742: done 5636 episodes, mean reward 3.366, speed 47.12 f/s\n","1334839: done 5637 episodes, mean reward 3.340, speed 45.06 f/s\n","1335076: done 5638 episodes, mean reward 3.337, speed 46.58 f/s\n","1335456: done 5639 episodes, mean reward 3.342, speed 47.65 f/s\n","1335893: done 5640 episodes, mean reward 3.372, speed 47.08 f/s\n","1336007: done 5641 episodes, mean reward 3.318, speed 45.44 f/s\n","1336461: done 5642 episodes, mean reward 3.333, speed 47.41 f/s\n","1336960: done 5643 episodes, mean reward 3.352, speed 48.31 f/s\n","1337317: done 5644 episodes, mean reward 3.317, speed 47.55 f/s\n","1337673: done 5645 episodes, mean reward 3.309, speed 47.42 f/s\n","1337766: done 5646 episodes, mean reward 3.306, speed 44.51 f/s\n","1338132: done 5647 episodes, mean reward 3.346, speed 47.81 f/s\n","1338659: done 5648 episodes, mean reward 3.344, speed 47.51 f/s\n","1338725: done 5649 episodes, mean reward 3.314, speed 42.84 f/s\n","1338792: done 5650 episodes, mean reward 3.288, speed 42.50 f/s\n","1339318: done 5651 episodes, mean reward 3.331, speed 47.67 f/s\n","1339515: done 5652 episodes, mean reward 3.319, speed 46.51 f/s\n","EEEE tensor(-7.3639, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2698, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 33.37 sec, reward 3.268, steps 457\n","1340515: done 5653 episodes, mean reward 3.402, speed 18.46 f/s\n","1341357: done 5654 episodes, mean reward 3.427, speed 47.84 f/s\n","1341548: done 5655 episodes, mean reward 3.435, speed 46.26 f/s\n","1342548: done 5656 episodes, mean reward 3.453, speed 48.20 f/s\n","1342691: done 5657 episodes, mean reward 3.445, speed 45.88 f/s\n","1342796: done 5658 episodes, mean reward 3.439, speed 45.23 f/s\n","1343186: done 5659 episodes, mean reward 3.447, speed 47.37 f/s\n","1343651: done 5660 episodes, mean reward 3.481, speed 47.85 f/s\n","1344264: done 5661 episodes, mean reward 3.453, speed 47.97 f/s\n","1344490: done 5662 episodes, mean reward 3.391, speed 46.40 f/s\n","1344570: done 5663 episodes, mean reward 3.371, speed 43.90 f/s\n","1344923: done 5664 episodes, mean reward 3.402, speed 47.13 f/s\n","1345923: done 5665 episodes, mean reward 3.452, speed 48.16 f/s\n","1346227: done 5666 episodes, mean reward 3.460, speed 46.75 f/s\n","1346950: done 5667 episodes, mean reward 3.519, speed 48.11 f/s\n","1347950: done 5668 episodes, mean reward 3.624, speed 48.06 f/s\n","1348062: done 5669 episodes, mean reward 3.513, speed 45.38 f/s\n","1348240: done 5670 episodes, mean reward 3.447, speed 46.49 f/s\n","1348547: done 5671 episodes, mean reward 3.429, speed 47.32 f/s\n","1349254: done 5672 episodes, mean reward 3.441, speed 47.95 f/s\n","1349398: done 5673 episodes, mean reward 3.413, speed 46.12 f/s\n","EEEE tensor(-8.5810, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2545, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 19.50 sec, reward 2.067, steps 258\n","1350398: done 5674 episodes, mean reward 3.475, speed 24.80 f/s\n","1350668: done 5675 episodes, mean reward 3.494, speed 46.62 f/s\n","1351059: done 5676 episodes, mean reward 3.478, speed 47.51 f/s\n","1351368: done 5677 episodes, mean reward 3.460, speed 46.85 f/s\n","1351790: done 5678 episodes, mean reward 3.476, speed 46.79 f/s\n","1352334: done 5679 episodes, mean reward 3.445, speed 47.83 f/s\n","1352418: done 5680 episodes, mean reward 3.368, speed 43.92 f/s\n","1353131: done 5681 episodes, mean reward 3.427, speed 48.17 f/s\n","1353825: done 5682 episodes, mean reward 3.454, speed 47.37 f/s\n","1353866: done 5683 episodes, mean reward 3.450, speed 40.25 f/s\n","1354589: done 5684 episodes, mean reward 3.499, speed 47.89 f/s\n","1355509: done 5685 episodes, mean reward 3.466, speed 47.84 f/s\n","1355798: done 5686 episodes, mean reward 3.412, speed 46.98 f/s\n","1356322: done 5687 episodes, mean reward 3.443, speed 47.46 f/s\n","1356613: done 5688 episodes, mean reward 3.382, speed 46.17 f/s\n","1356912: done 5689 episodes, mean reward 3.411, speed 47.13 f/s\n","1357912: done 5690 episodes, mean reward 3.480, speed 48.14 f/s\n","1358912: done 5691 episodes, mean reward 3.553, speed 47.40 f/s\n","1359024: done 5692 episodes, mean reward 3.542, speed 44.37 f/s\n","1359202: done 5693 episodes, mean reward 3.526, speed 46.39 f/s\n","1359284: done 5695 episodes, mean reward 3.523, speed 39.95 f/s\n","1359536: done 5696 episodes, mean reward 3.542, speed 46.79 f/s\n","1359773: done 5697 episodes, mean reward 3.480, speed 46.54 f/s\n","1359874: done 5698 episodes, mean reward 3.459, speed 44.79 f/s\n","EEEE tensor(-8.2365, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2899, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 41.15 sec, reward 3.746, steps 564\n","1360367: done 5699 episodes, mean reward 3.486, speed 9.54 f/s\n","1360697: done 5700 episodes, mean reward 3.501, speed 47.30 f/s\n","1361634: done 5701 episodes, mean reward 3.570, speed 48.03 f/s\n","1361866: done 5702 episodes, mean reward 3.562, speed 46.27 f/s\n","1362197: done 5703 episodes, mean reward 3.578, speed 47.41 f/s\n","1362342: done 5704 episodes, mean reward 3.568, speed 45.17 f/s\n","1362642: done 5705 episodes, mean reward 3.574, speed 47.21 f/s\n","1363112: done 5706 episodes, mean reward 3.615, speed 47.65 f/s\n","1363225: done 5707 episodes, mean reward 3.586, speed 45.25 f/s\n","1363425: done 5708 episodes, mean reward 3.589, speed 46.37 f/s\n","1363772: done 5709 episodes, mean reward 3.616, speed 47.13 f/s\n","1364448: done 5710 episodes, mean reward 3.637, speed 47.98 f/s\n","1365037: done 5711 episodes, mean reward 3.689, speed 47.61 f/s\n","1365755: done 5712 episodes, mean reward 3.686, speed 47.25 f/s\n","1365914: done 5713 episodes, mean reward 3.698, speed 45.42 f/s\n","1366827: done 5714 episodes, mean reward 3.709, speed 47.73 f/s\n","1366994: done 5715 episodes, mean reward 3.678, speed 45.32 f/s\n","1367033: done 5716 episodes, mean reward 3.657, speed 38.89 f/s\n","1367148: done 5717 episodes, mean reward 3.644, speed 44.79 f/s\n","1367290: done 5718 episodes, mean reward 3.587, speed 45.36 f/s\n","1367649: done 5719 episodes, mean reward 3.616, speed 47.37 f/s\n","1368116: done 5720 episodes, mean reward 3.665, speed 47.51 f/s\n","1368522: done 5721 episodes, mean reward 3.658, speed 47.16 f/s\n","1368781: done 5722 episodes, mean reward 3.655, speed 46.53 f/s\n","1369171: done 5723 episodes, mean reward 3.665, speed 46.75 f/s\n","EEEE tensor(-8.5803, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2804, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 26.22 sec, reward 2.741, steps 350\n","1370144: done 5724 episodes, mean reward 3.733, speed 20.92 f/s\n","1370269: done 5725 episodes, mean reward 3.724, speed 45.02 f/s\n","1370533: done 5726 episodes, mean reward 3.690, speed 47.06 f/s\n","1371533: done 5727 episodes, mean reward 3.771, speed 47.95 f/s\n","1371902: done 5728 episodes, mean reward 3.763, speed 47.39 f/s\n","1372307: done 5729 episodes, mean reward 3.708, speed 47.25 f/s\n","1373307: done 5730 episodes, mean reward 3.664, speed 47.37 f/s\n","1373493: done 5731 episodes, mean reward 3.647, speed 46.21 f/s\n","1373781: done 5732 episodes, mean reward 3.572, speed 47.08 f/s\n","1373913: done 5733 episodes, mean reward 3.573, speed 45.60 f/s\n","1374587: done 5734 episodes, mean reward 3.572, speed 46.95 f/s\n","1374711: done 5735 episodes, mean reward 3.570, speed 45.16 f/s\n","1375217: done 5736 episodes, mean reward 3.585, speed 47.86 f/s\n","1375886: done 5737 episodes, mean reward 3.622, speed 48.10 f/s\n","1376038: done 5738 episodes, mean reward 3.626, speed 45.86 f/s\n","1376465: done 5739 episodes, mean reward 3.633, speed 47.84 f/s\n","1377465: done 5740 episodes, mean reward 3.676, speed 48.57 f/s\n","1377910: done 5741 episodes, mean reward 3.701, speed 48.33 f/s\n","1378285: done 5742 episodes, mean reward 3.691, speed 48.11 f/s\n","1378608: done 5743 episodes, mean reward 3.669, speed 48.35 f/s\n","1379002: done 5744 episodes, mean reward 3.674, speed 48.28 f/s\n","1379875: done 5745 episodes, mean reward 3.689, speed 49.40 f/s\n","1379980: done 5746 episodes, mean reward 3.692, speed 47.28 f/s\n","EEEE tensor(-8.2265, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3061, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 25.40 sec, reward 2.701, steps 366\n","1380365: done 5747 episodes, mean reward 3.684, speed 11.73 f/s\n","1381365: done 5748 episodes, mean reward 3.703, speed 54.28 f/s\n","1382365: done 5749 episodes, mean reward 3.803, speed 55.70 f/s\n","1383305: done 5750 episodes, mean reward 3.858, speed 56.00 f/s\n","1383945: done 5751 episodes, mean reward 3.864, speed 56.10 f/s\n","1384101: done 5752 episodes, mean reward 3.854, speed 52.48 f/s\n","1384493: done 5753 episodes, mean reward 3.779, speed 54.84 f/s\n","1384559: done 5754 episodes, mean reward 3.702, speed 48.89 f/s\n","1384678: done 5755 episodes, mean reward 3.698, speed 49.49 f/s\n","1384940: done 5757 episodes, mean reward 3.617, speed 51.49 f/s\n","1385465: done 5758 episodes, mean reward 3.648, speed 54.58 f/s\n","1386465: done 5759 episodes, mean reward 3.679, speed 54.97 f/s\n","1387331: done 5760 episodes, mean reward 3.732, speed 54.92 f/s\n","1388331: done 5761 episodes, mean reward 3.750, speed 55.66 f/s\n","1388866: done 5763 episodes, mean reward 3.790, speed 53.61 f/s\n","1389866: done 5764 episodes, mean reward 3.855, speed 56.00 f/s\n","EEEE tensor(-8.4935, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.2968, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 32.81 sec, reward 4.005, steps 522\n","1390123: done 5765 episodes, mean reward 3.785, speed 6.85 f/s\n","1390323: done 5766 episodes, mean reward 3.773, speed 54.67 f/s\n","1391314: done 5767 episodes, mean reward 3.803, speed 56.11 f/s\n","1391398: done 5768 episodes, mean reward 3.698, speed 51.28 f/s\n","1391938: done 5769 episodes, mean reward 3.751, speed 56.69 f/s\n","1392627: done 5770 episodes, mean reward 3.816, speed 56.53 f/s\n","1393136: done 5771 episodes, mean reward 3.844, speed 55.40 f/s\n","1393319: done 5773 episodes, mean reward 3.795, speed 51.17 f/s\n","1393459: done 5774 episodes, mean reward 3.715, speed 53.66 f/s\n","1393596: done 5775 episodes, mean reward 3.699, speed 53.69 f/s\n","1394045: done 5776 episodes, mean reward 3.729, speed 55.80 f/s\n","1394255: done 5777 episodes, mean reward 3.717, speed 54.62 f/s\n","1394594: done 5778 episodes, mean reward 3.716, speed 55.15 f/s\n","1395407: done 5779 episodes, mean reward 3.735, speed 55.21 f/s\n","1396435: done 5781 episodes, mean reward 3.737, speed 54.67 f/s\n","1397263: done 5782 episodes, mean reward 3.749, speed 56.06 f/s\n","1397963: done 5783 episodes, mean reward 3.800, speed 55.64 f/s\n","1398793: done 5784 episodes, mean reward 3.783, speed 55.68 f/s\n","1399434: done 5785 episodes, mean reward 3.768, speed 55.33 f/s\n","EEEE tensor(-8.2131, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3214, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 17.10 sec, reward 2.570, steps 261\n","1400034: done 5786 episodes, mean reward 3.798, speed 21.32 f/s\n","1400208: done 5787 episodes, mean reward 3.769, speed 53.79 f/s\n","1400832: done 5788 episodes, mean reward 3.796, speed 55.47 f/s\n","1401832: done 5789 episodes, mean reward 3.844, speed 55.67 f/s\n","1402595: done 5790 episodes, mean reward 3.831, speed 56.41 f/s\n","1402672: done 5791 episodes, mean reward 3.758, speed 50.35 f/s\n","1403655: done 5792 episodes, mean reward 3.839, speed 56.00 f/s\n","1404655: done 5793 episodes, mean reward 3.951, speed 56.08 f/s\n","1404962: done 5794 episodes, mean reward 3.983, speed 56.04 f/s\n","1405102: done 5795 episodes, mean reward 3.995, speed 53.51 f/s\n","1406102: done 5796 episodes, mean reward 4.063, speed 56.30 f/s\n","1407102: done 5797 episodes, mean reward 4.151, speed 56.16 f/s\n","1407384: done 5798 episodes, mean reward 4.168, speed 54.73 f/s\n","1408384: done 5799 episodes, mean reward 4.260, speed 55.94 f/s\n","1408734: done 5800 episodes, mean reward 4.259, speed 54.27 f/s\n","1408883: done 5801 episodes, mean reward 4.181, speed 51.79 f/s\n","1409043: done 5802 episodes, mean reward 4.171, speed 53.25 f/s\n","1409186: done 5803 episodes, mean reward 4.160, speed 52.40 f/s\n","1409257: done 5804 episodes, mean reward 4.157, speed 48.30 f/s\n","1409684: done 5805 episodes, mean reward 4.187, speed 55.72 f/s\n","EEEE tensor(-7.8301, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3383, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 33.04 sec, reward 6.178, steps 538\n","1410684: done 5806 episodes, mean reward 4.238, speed 19.74 f/s\n","1411609: done 5807 episodes, mean reward 4.309, speed 57.13 f/s\n","1411861: done 5809 episodes, mean reward 4.287, speed 53.61 f/s\n","1412861: done 5810 episodes, mean reward 4.339, speed 57.03 f/s\n","1413861: done 5811 episodes, mean reward 4.401, speed 56.98 f/s\n","1414652: done 5812 episodes, mean reward 4.385, speed 55.53 f/s\n","1414799: done 5813 episodes, mean reward 4.377, speed 53.05 f/s\n","1415302: done 5814 episodes, mean reward 4.299, speed 56.39 f/s\n","1415452: done 5815 episodes, mean reward 4.291, speed 52.58 f/s\n","1415575: done 5816 episodes, mean reward 4.301, speed 53.71 f/s\n","1415635: done 5817 episodes, mean reward 4.291, speed 50.16 f/s\n","1415714: done 5818 episodes, mean reward 4.287, speed 50.55 f/s\n","1416221: done 5819 episodes, mean reward 4.282, speed 54.68 f/s\n","1416593: done 5820 episodes, mean reward 4.260, speed 54.08 f/s\n","1416731: done 5821 episodes, mean reward 4.239, speed 53.28 f/s\n","1416792: done 5822 episodes, mean reward 4.223, speed 50.26 f/s\n","1416840: done 5823 episodes, mean reward 4.185, speed 47.03 f/s\n","1417103: done 5824 episodes, mean reward 4.122, speed 55.09 f/s\n","1417157: done 5825 episodes, mean reward 4.114, speed 47.17 f/s\n","1417352: done 5826 episodes, mean reward 4.103, speed 52.52 f/s\n","1417424: done 5827 episodes, mean reward 4.011, speed 48.68 f/s\n","1417505: done 5828 episodes, mean reward 3.979, speed 49.04 f/s\n","1417589: done 5829 episodes, mean reward 3.958, speed 50.70 f/s\n","1417644: done 5830 episodes, mean reward 3.906, speed 46.29 f/s\n","1417726: done 5831 episodes, mean reward 3.893, speed 49.46 f/s\n","1417824: done 5832 episodes, mean reward 3.873, speed 50.16 f/s\n","1417928: done 5833 episodes, mean reward 3.870, speed 51.34 f/s\n","1418020: done 5834 episodes, mean reward 3.825, speed 51.17 f/s\n","1418604: done 5835 episodes, mean reward 3.842, speed 56.75 f/s\n","1418721: done 5837 episodes, mean reward 3.772, speed 50.52 f/s\n","1418809: done 5838 episodes, mean reward 3.764, speed 52.17 f/s\n","1418912: done 5840 episodes, mean reward 3.647, speed 49.10 f/s\n","1419284: done 5841 episodes, mean reward 3.619, speed 55.09 f/s\n","1419392: done 5842 episodes, mean reward 3.594, speed 53.04 f/s\n","1419998: done 5844 episodes, mean reward 3.524, speed 49.08 f/s\n","EEEE tensor(-9.4575, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3805, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0007, grad_fn=<ExpBackward>)\n","Test done in 30.66 sec, reward 0.850, steps 396\n","1420394: done 5845 episodes, mean reward 3.489, speed 10.12 f/s\n","1420966: done 5846 episodes, mean reward 3.490, speed 46.31 f/s\n","1421118: done 5847 episodes, mean reward 3.459, speed 44.33 f/s\n","1421313: done 5848 episodes, mean reward 3.396, speed 45.39 f/s\n","1422313: done 5849 episodes, mean reward 3.310, speed 46.71 f/s\n","1422549: done 5850 episodes, mean reward 3.256, speed 45.10 f/s\n","1423549: done 5851 episodes, mean reward 3.198, speed 46.64 f/s\n","1423593: done 5852 episodes, mean reward 3.189, speed 40.33 f/s\n","1423710: done 5853 episodes, mean reward 3.150, speed 44.45 f/s\n","1424710: done 5854 episodes, mean reward 3.154, speed 47.33 f/s\n","1424810: done 5855 episodes, mean reward 3.148, speed 44.07 f/s\n","1425810: done 5856 episodes, mean reward 3.149, speed 46.52 f/s\n","1426810: done 5857 episodes, mean reward 3.140, speed 46.62 f/s\n","1427810: done 5858 episodes, mean reward 3.104, speed 46.71 f/s\n","1428810: done 5859 episodes, mean reward 3.037, speed 46.70 f/s\n","1429810: done 5860 episodes, mean reward 2.949, speed 46.85 f/s\n","EEEE tensor(-7.8106, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3991, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0006, grad_fn=<ExpBackward>)\n","Test done in 42.91 sec, reward 1.993, steps 588\n","1430810: done 5861 episodes, mean reward 2.900, speed 15.61 f/s\n","1431071: done 5862 episodes, mean reward 2.915, speed 46.09 f/s\n","1431127: done 5863 episodes, mean reward 2.854, speed 42.03 f/s\n","1431621: done 5864 episodes, mean reward 2.780, speed 46.69 f/s\n","1432460: done 5865 episodes, mean reward 2.805, speed 46.47 f/s\n","1433013: done 5866 episodes, mean reward 2.818, speed 46.89 f/s\n","1433684: done 5867 episodes, mean reward 2.753, speed 46.74 f/s\n","1434128: done 5868 episodes, mean reward 2.784, speed 46.47 f/s\n","1434357: done 5869 episodes, mean reward 2.746, speed 46.45 f/s\n","1434488: done 5870 episodes, mean reward 2.682, speed 44.97 f/s\n","1434570: done 5871 episodes, mean reward 2.639, speed 43.60 f/s\n","1435570: done 5872 episodes, mean reward 2.691, speed 47.58 f/s\n","1436570: done 5873 episodes, mean reward 2.717, speed 46.91 f/s\n","1437570: done 5874 episodes, mean reward 2.736, speed 47.57 f/s\n","1438570: done 5875 episodes, mean reward 2.778, speed 47.14 f/s\n","1439570: done 5876 episodes, mean reward 2.754, speed 47.74 f/s\n","EEEE tensor(-7.8207, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3896, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 37.82 sec, reward 2.321, steps 512\n","1440570: done 5877 episodes, mean reward 2.786, speed 16.94 f/s\n","1441570: done 5878 episodes, mean reward 2.794, speed 47.49 f/s\n","1441967: done 5879 episodes, mean reward 2.747, speed 47.00 f/s\n","1442766: done 5880 episodes, mean reward 2.785, speed 47.62 f/s\n","1443766: done 5881 episodes, mean reward 2.770, speed 47.66 f/s\n","1444766: done 5882 episodes, mean reward 2.776, speed 47.87 f/s\n","1445253: done 5883 episodes, mean reward 2.759, speed 47.76 f/s\n","1446253: done 5884 episodes, mean reward 2.747, speed 47.56 f/s\n","1447068: done 5885 episodes, mean reward 2.773, speed 47.76 f/s\n","1447187: done 5886 episodes, mean reward 2.717, speed 45.25 f/s\n","1448187: done 5887 episodes, mean reward 2.805, speed 47.72 f/s\n","1449187: done 5888 episodes, mean reward 2.858, speed 47.96 f/s\n","EEEE tensor(-6.5193, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3931, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 53.26 sec, reward 8.768, steps 743\n","1450187: done 5889 episodes, mean reward 2.852, speed 13.47 f/s\n","1450637: done 5890 episodes, mean reward 2.783, speed 46.92 f/s\n","1451091: done 5891 episodes, mean reward 2.810, speed 47.32 f/s\n","1452091: done 5892 episodes, mean reward 2.848, speed 47.76 f/s\n","1452207: done 5893 episodes, mean reward 2.725, speed 44.42 f/s\n","1452342: done 5894 episodes, mean reward 2.695, speed 45.28 f/s\n","1452805: done 5895 episodes, mean reward 2.679, speed 46.49 f/s\n","1453805: done 5896 episodes, mean reward 2.687, speed 47.32 f/s\n","1454805: done 5897 episodes, mean reward 2.737, speed 47.74 f/s\n","1455373: done 5898 episodes, mean reward 2.779, speed 47.12 f/s\n","1455991: done 5899 episodes, mean reward 2.732, speed 47.95 f/s\n","1456260: done 5900 episodes, mean reward 2.730, speed 47.42 f/s\n","1456547: done 5901 episodes, mean reward 2.757, speed 48.22 f/s\n","1457547: done 5902 episodes, mean reward 2.892, speed 49.77 f/s\n","1458310: done 5903 episodes, mean reward 2.990, speed 50.75 f/s\n","1458624: done 5904 episodes, mean reward 3.016, speed 53.26 f/s\n","1459266: done 5905 episodes, mean reward 3.033, speed 56.31 f/s\n","1459672: done 5906 episodes, mean reward 2.990, speed 56.77 f/s\n","1459804: done 5907 episodes, mean reward 2.924, speed 54.09 f/s\n","EEEE tensor(-8.0461, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3669, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 21.16 sec, reward 3.644, steps 339\n","1460164: done 5908 episodes, mean reward 2.969, speed 13.06 f/s\n","1460237: done 5909 episodes, mean reward 2.951, speed 46.67 f/s\n","1460623: done 5910 episodes, mean reward 2.884, speed 55.92 f/s\n","1460775: done 5911 episodes, mean reward 2.759, speed 53.39 f/s\n","1461143: done 5912 episodes, mean reward 2.750, speed 55.82 f/s\n","1462143: done 5913 episodes, mean reward 2.878, speed 56.62 f/s\n","1462376: done 5915 episodes, mean reward 2.854, speed 51.46 f/s\n","1463088: done 5916 episodes, mean reward 2.920, speed 56.17 f/s\n","1463318: done 5917 episodes, mean reward 2.942, speed 54.63 f/s\n","1463404: done 5919 episodes, mean reward 2.905, speed 47.37 f/s\n","1463686: done 5920 episodes, mean reward 2.896, speed 54.58 f/s\n","1464196: done 5921 episodes, mean reward 2.957, speed 55.26 f/s\n","1464409: done 5922 episodes, mean reward 2.965, speed 54.20 f/s\n","1464858: done 5923 episodes, mean reward 3.015, speed 54.86 f/s\n","1465322: done 5924 episodes, mean reward 3.041, speed 55.37 f/s\n","1465606: done 5925 episodes, mean reward 3.068, speed 54.26 f/s\n","1466606: done 5926 episodes, mean reward 3.188, speed 56.20 f/s\n","1466875: done 5927 episodes, mean reward 3.214, speed 54.34 f/s\n","1466922: done 5928 episodes, mean reward 3.211, speed 46.64 f/s\n","1466969: done 5929 episodes, mean reward 3.210, speed 46.96 f/s\n","1467055: done 5931 episodes, mean reward 3.210, speed 46.64 f/s\n","1467239: done 5932 episodes, mean reward 3.216, speed 54.70 f/s\n","1467285: done 5933 episodes, mean reward 3.212, speed 45.95 f/s\n","1467332: done 5934 episodes, mean reward 3.210, speed 46.78 f/s\n","1467384: done 5935 episodes, mean reward 3.186, speed 48.10 f/s\n","1467492: done 5936 episodes, mean reward 3.191, speed 52.80 f/s\n","1467985: done 5937 episodes, mean reward 3.230, speed 55.58 f/s\n","1468243: done 5938 episodes, mean reward 3.256, speed 54.79 f/s\n","1468613: done 5939 episodes, mean reward 3.294, speed 55.80 f/s\n","1469613: done 5940 episodes, mean reward 3.372, speed 56.19 f/s\n","1469694: done 5941 episodes, mean reward 3.371, speed 51.75 f/s\n","1469821: done 5943 episodes, mean reward 3.371, speed 50.02 f/s\n","1469903: done 5944 episodes, mean reward 3.375, speed 52.27 f/s\n","EEEE tensor(-7.4445, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.3986, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 25.53 sec, reward 3.373, steps 408\n","1470192: done 5945 episodes, mean reward 3.383, speed 9.39 f/s\n","1470567: done 5946 episodes, mean reward 3.390, speed 54.45 f/s\n","1471056: done 5947 episodes, mean reward 3.435, speed 55.65 f/s\n","1471108: done 5948 episodes, mean reward 3.434, speed 49.20 f/s\n","1471300: done 5950 episodes, mean reward 3.425, speed 52.42 f/s\n","1471911: done 5951 episodes, mean reward 3.488, speed 56.44 f/s\n","1471984: done 5952 episodes, mean reward 3.489, speed 51.03 f/s\n","1472603: done 5953 episodes, mean reward 3.533, speed 55.70 f/s\n","1472900: done 5954 episodes, mean reward 3.557, speed 55.10 f/s\n","1473533: done 5955 episodes, mean reward 3.638, speed 56.42 f/s\n","1473587: done 5956 episodes, mean reward 3.639, speed 48.36 f/s\n","1474064: done 5957 episodes, mean reward 3.689, speed 55.92 f/s\n","1474112: done 5958 episodes, mean reward 3.686, speed 47.77 f/s\n","1474701: done 5959 episodes, mean reward 3.746, speed 56.12 f/s\n","1474982: done 5960 episodes, mean reward 3.754, speed 55.28 f/s\n","1475199: done 5961 episodes, mean reward 3.745, speed 55.77 f/s\n","1475339: done 5962 episodes, mean reward 3.733, speed 53.97 f/s\n","1475794: done 5963 episodes, mean reward 3.785, speed 55.62 f/s\n","1475943: done 5965 episodes, mean reward 3.726, speed 50.96 f/s\n","1476943: done 5966 episodes, mean reward 3.812, speed 57.22 f/s\n","1477463: done 5967 episodes, mean reward 3.828, speed 56.59 f/s\n","1477714: done 5968 episodes, mean reward 3.818, speed 56.08 f/s\n","1478217: done 5969 episodes, mean reward 3.858, speed 56.34 f/s\n","1478710: done 5970 episodes, mean reward 3.907, speed 56.51 f/s\n","1479238: done 5971 episodes, mean reward 3.963, speed 56.40 f/s\n","1479448: done 5972 episodes, mean reward 3.930, speed 55.46 f/s\n","EEEE tensor(-7.2609, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4172, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 25.48 sec, reward 4.977, steps 408\n","1480448: done 5973 episodes, mean reward 4.020, speed 23.14 f/s\n","1481285: done 5974 episodes, mean reward 4.089, speed 55.13 f/s\n","1481441: done 5975 episodes, mean reward 4.051, speed 53.79 f/s\n","1481543: done 5976 episodes, mean reward 4.020, speed 52.14 f/s\n","1482000: done 5977 episodes, mean reward 4.027, speed 55.39 f/s\n","1483000: done 5978 episodes, mean reward 4.148, speed 56.07 f/s\n","1483163: done 5979 episodes, mean reward 4.136, speed 52.95 f/s\n","1484163: done 5980 episodes, mean reward 4.213, speed 56.23 f/s\n","1485163: done 5981 episodes, mean reward 4.265, speed 56.05 f/s\n","1485336: done 5982 episodes, mean reward 4.207, speed 53.78 f/s\n","1485534: done 5983 episodes, mean reward 4.192, speed 55.28 f/s\n","1486333: done 5984 episodes, mean reward 4.220, speed 56.47 f/s\n","1486539: done 5985 episodes, mean reward 4.146, speed 55.22 f/s\n","1487539: done 5986 episodes, mean reward 4.279, speed 56.35 f/s\n","1488123: done 5987 episodes, mean reward 4.241, speed 55.30 f/s\n","1489123: done 5988 episodes, mean reward 4.295, speed 56.50 f/s\n","EEEE tensor(-7.1119, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4416, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 49.31 sec, reward 10.767, steps 825\n","1490123: done 5989 episodes, mean reward 4.364, speed 14.89 f/s\n","1491123: done 5990 episodes, mean reward 4.509, speed 55.66 f/s\n","1491173: done 5991 episodes, mean reward 4.480, speed 47.39 f/s\n","1492173: done 5992 episodes, mean reward 4.484, speed 56.46 f/s\n","1493076: done 5993 episodes, mean reward 4.602, speed 55.28 f/s\n","1494076: done 5994 episodes, mean reward 4.745, speed 57.15 f/s\n","1494202: done 5995 episodes, mean reward 4.756, speed 53.47 f/s\n","1494384: done 5996 episodes, mean reward 4.661, speed 54.93 f/s\n","1495384: done 5997 episodes, mean reward 4.638, speed 51.31 f/s\n","1496384: done 5998 episodes, mean reward 4.716, speed 47.88 f/s\n","1497269: done 5999 episodes, mean reward 4.746, speed 47.61 f/s\n","1498269: done 6000 episodes, mean reward 4.825, speed 47.47 f/s\n","1499269: done 6001 episodes, mean reward 4.941, speed 47.61 f/s\n","1499848: done 6002 episodes, mean reward 4.860, speed 47.29 f/s\n","EEEE tensor(-8.1526, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4538, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 30.88 sec, reward 5.278, steps 424\n","1500848: done 6003 episodes, mean reward 4.870, speed 19.31 f/s\n","1500991: done 6004 episodes, mean reward 4.852, speed 45.35 f/s\n","1501322: done 6005 episodes, mean reward 4.813, speed 46.86 f/s\n","1501629: done 6006 episodes, mean reward 4.791, speed 46.92 f/s\n","1501728: done 6007 episodes, mean reward 4.784, speed 44.56 f/s\n","1501800: done 6008 episodes, mean reward 4.742, speed 43.04 f/s\n","1502800: done 6009 episodes, mean reward 4.863, speed 47.85 f/s\n","1503670: done 6010 episodes, mean reward 4.919, speed 47.75 f/s\n","1503878: done 6011 episodes, mean reward 4.926, speed 46.12 f/s\n","1504777: done 6012 episodes, mean reward 4.997, speed 47.61 f/s\n","1505777: done 6013 episodes, mean reward 4.968, speed 47.48 f/s\n","1506483: done 6014 episodes, mean reward 5.063, speed 47.54 f/s\n","1507397: done 6015 episodes, mean reward 5.151, speed 47.50 f/s\n","1507508: done 6016 episodes, mean reward 5.081, speed 44.42 f/s\n","1507587: done 6017 episodes, mean reward 5.063, speed 42.88 f/s\n","1507754: done 6018 episodes, mean reward 5.073, speed 45.49 f/s\n","1508113: done 6019 episodes, mean reward 5.110, speed 46.92 f/s\n","1508276: done 6020 episodes, mean reward 5.099, speed 45.47 f/s\n","1509276: done 6021 episodes, mean reward 5.127, speed 47.49 f/s\n","EEEE tensor(-7.9355, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4333, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 26.89 sec, reward 4.294, steps 365\n","1510276: done 6022 episodes, mean reward 5.237, speed 20.92 f/s\n","1510404: done 6023 episodes, mean reward 5.194, speed 45.10 f/s\n","1511404: done 6024 episodes, mean reward 5.270, speed 47.46 f/s\n","1511655: done 6025 episodes, mean reward 5.270, speed 46.64 f/s\n","1512655: done 6026 episodes, mean reward 5.244, speed 47.55 f/s\n","1513655: done 6027 episodes, mean reward 5.322, speed 47.45 f/s\n","1514655: done 6028 episodes, mean reward 5.433, speed 47.72 f/s\n","1515655: done 6029 episodes, mean reward 5.568, speed 47.63 f/s\n","1516655: done 6030 episodes, mean reward 5.683, speed 47.80 f/s\n","1517655: done 6031 episodes, mean reward 5.793, speed 47.79 f/s\n","1518655: done 6032 episodes, mean reward 5.885, speed 47.66 f/s\n","1519655: done 6033 episodes, mean reward 5.984, speed 47.68 f/s\n","1519789: done 6035 episodes, mean reward 5.987, speed 41.94 f/s\n","1519860: done 6036 episodes, mean reward 5.985, speed 40.91 f/s\n","EEEE tensor(-9.2351, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4570, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 31.23 sec, reward 4.797, steps 434\n","1520069: done 6038 episodes, mean reward 5.932, speed 5.82 f/s\n","1521069: done 6039 episodes, mean reward 6.004, speed 47.74 f/s\n","1521249: done 6040 episodes, mean reward 5.944, speed 46.03 f/s\n","1521326: done 6042 episodes, mean reward 5.941, speed 39.37 f/s\n","1522326: done 6043 episodes, mean reward 6.064, speed 48.00 f/s\n","1522543: done 6044 episodes, mean reward 6.084, speed 46.44 f/s\n","1522801: done 6045 episodes, mean reward 6.094, speed 46.09 f/s\n","1522844: done 6046 episodes, mean reward 6.079, speed 39.49 f/s\n","1523844: done 6047 episodes, mean reward 6.154, speed 47.87 f/s\n","1523916: done 6048 episodes, mean reward 6.154, speed 42.90 f/s\n","1523982: done 6049 episodes, mean reward 6.155, speed 42.01 f/s\n","1524476: done 6050 episodes, mean reward 6.185, speed 47.25 f/s\n","1524718: done 6051 episodes, mean reward 6.133, speed 46.38 f/s\n","1525718: done 6052 episodes, mean reward 6.229, speed 47.65 f/s\n","1526754: done 6054 episodes, mean reward 6.237, speed 47.57 f/s\n","1527790: done 6056 episodes, mean reward 6.264, speed 46.89 f/s\n","1528790: done 6057 episodes, mean reward 6.320, speed 47.96 f/s\n","1528960: done 6059 episodes, mean reward 6.263, speed 43.72 f/s\n","1529821: done 6060 episodes, mean reward 6.342, speed 47.59 f/s\n","EEEE tensor(-8.9373, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4983, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 38.44 sec, reward 5.598, steps 537\n","1530821: done 6061 episodes, mean reward 6.420, speed 16.82 f/s\n","1530970: done 6062 episodes, mean reward 6.429, speed 45.49 f/s\n","1531046: done 6063 episodes, mean reward 6.379, speed 42.67 f/s\n","1531215: done 6064 episodes, mean reward 6.395, speed 45.68 f/s\n","1531258: done 6065 episodes, mean reward 6.390, speed 39.79 f/s\n","1531402: done 6066 episodes, mean reward 6.288, speed 45.15 f/s\n","1532402: done 6067 episodes, mean reward 6.356, speed 48.05 f/s\n","1533402: done 6068 episodes, mean reward 6.435, speed 47.80 f/s\n","1534402: done 6069 episodes, mean reward 6.485, speed 47.85 f/s\n","1535402: done 6070 episodes, mean reward 6.534, speed 47.76 f/s\n","1535609: done 6071 episodes, mean reward 6.492, speed 45.00 f/s\n","1536075: done 6072 episodes, mean reward 6.522, speed 47.01 f/s\n","1536146: done 6074 episodes, mean reward 6.303, speed 39.41 f/s\n","1536259: done 6075 episodes, mean reward 6.295, speed 44.07 f/s\n","1537099: done 6076 episodes, mean reward 6.406, speed 47.59 f/s\n","1538099: done 6077 episodes, mean reward 6.494, speed 47.94 f/s\n","1539099: done 6078 episodes, mean reward 6.478, speed 48.88 f/s\n","EEEE tensor(-7.8632, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5077, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 32.42 sec, reward 5.835, steps 510\n","1540099: done 6079 episodes, mean reward 6.598, speed 19.23 f/s\n","1540746: done 6080 episodes, mean reward 6.538, speed 56.53 f/s\n","1541313: done 6081 episodes, mean reward 6.477, speed 57.01 f/s\n","1542313: done 6082 episodes, mean reward 6.563, speed 56.90 f/s\n","1543313: done 6083 episodes, mean reward 6.637, speed 57.70 f/s\n","1543721: done 6084 episodes, mean reward 6.569, speed 56.73 f/s\n","1543943: done 6085 episodes, mean reward 6.573, speed 56.13 f/s\n","1544218: done 6086 episodes, mean reward 6.465, speed 57.13 f/s\n","1545255: done 6088 episodes, mean reward 6.338, speed 57.35 f/s\n","1546255: done 6089 episodes, mean reward 6.282, speed 57.90 f/s\n","1546578: done 6090 episodes, mean reward 6.162, speed 57.06 f/s\n","1547443: done 6091 episodes, mean reward 6.227, speed 57.16 f/s\n","1547601: done 6092 episodes, mean reward 6.110, speed 55.52 f/s\n","1547672: done 6093 episodes, mean reward 5.993, speed 52.31 f/s\n","1548654: done 6094 episodes, mean reward 5.962, speed 58.26 f/s\n","1549654: done 6095 episodes, mean reward 6.051, speed 57.88 f/s\n","EEEE tensor(-8.0280, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5072, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 36.46 sec, reward 6.573, steps 612\n","1550347: done 6096 episodes, mean reward 6.096, speed 14.31 f/s\n","1550731: done 6097 episodes, mean reward 6.001, speed 57.68 f/s\n","1550946: done 6098 episodes, mean reward 5.876, speed 56.12 f/s\n","1551946: done 6099 episodes, mean reward 5.880, speed 58.26 f/s\n","1552946: done 6100 episodes, mean reward 5.853, speed 57.14 f/s\n","1553709: done 6101 episodes, mean reward 5.767, speed 56.94 f/s\n","1554380: done 6102 episodes, mean reward 5.764, speed 57.55 f/s\n","1554533: done 6103 episodes, mean reward 5.648, speed 54.67 f/s\n","1555533: done 6104 episodes, mean reward 5.749, speed 58.01 f/s\n","1556533: done 6105 episodes, mean reward 5.796, speed 57.99 f/s\n","1557533: done 6106 episodes, mean reward 5.857, speed 57.69 f/s\n","1557936: done 6107 episodes, mean reward 5.885, speed 57.41 f/s\n","1558478: done 6108 episodes, mean reward 5.913, speed 57.36 f/s\n","1558607: done 6109 episodes, mean reward 5.793, speed 54.22 f/s\n","1559399: done 6110 episodes, mean reward 5.778, speed 58.00 f/s\n","1559543: done 6111 episodes, mean reward 5.772, speed 54.98 f/s\n","1559767: done 6112 episodes, mean reward 5.675, speed 56.20 f/s\n","EEEE tensor(-8.8524, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5031, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 35.08 sec, reward 6.062, steps 587\n","1560027: done 6113 episodes, mean reward 5.595, speed 6.55 f/s\n","1560266: done 6114 episodes, mean reward 5.522, speed 56.06 f/s\n","1560835: done 6115 episodes, mean reward 5.473, speed 56.94 f/s\n","1561042: done 6116 episodes, mean reward 5.474, speed 53.05 f/s\n","1562042: done 6117 episodes, mean reward 5.589, speed 58.40 f/s\n","1563042: done 6118 episodes, mean reward 5.676, speed 58.31 f/s\n","1563731: done 6119 episodes, mean reward 5.702, speed 57.93 f/s\n","1564731: done 6120 episodes, mean reward 5.775, speed 58.59 f/s\n","1564984: done 6121 episodes, mean reward 5.703, speed 56.70 f/s\n","1565062: done 6122 episodes, mean reward 5.585, speed 51.94 f/s\n","1566062: done 6123 episodes, mean reward 5.702, speed 58.20 f/s\n","1566719: done 6124 episodes, mean reward 5.652, speed 58.11 f/s\n","1567719: done 6125 episodes, mean reward 5.743, speed 58.09 f/s\n","1567978: done 6126 episodes, mean reward 5.662, speed 56.41 f/s\n","1568978: done 6127 episodes, mean reward 5.648, speed 58.26 f/s\n","1569693: done 6128 episodes, mean reward 5.583, speed 57.31 f/s\n","EEEE tensor(-8.3242, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5300, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 41.10 sec, reward 6.041, steps 670\n","1570693: done 6129 episodes, mean reward 5.552, speed 17.04 f/s\n","1571613: done 6130 episodes, mean reward 5.533, speed 57.22 f/s\n","1572156: done 6131 episodes, mean reward 5.477, speed 55.90 f/s\n","1572563: done 6132 episodes, mean reward 5.397, speed 56.07 f/s\n","1572803: done 6133 episodes, mean reward 5.314, speed 56.04 f/s\n","1573262: done 6134 episodes, mean reward 5.353, speed 57.22 f/s\n","1574262: done 6135 episodes, mean reward 5.479, speed 57.48 f/s\n","1575262: done 6136 episodes, mean reward 5.605, speed 58.75 f/s\n","1576262: done 6137 episodes, mean reward 5.723, speed 59.78 f/s\n","1577262: done 6138 episodes, mean reward 5.819, speed 59.48 f/s\n","1577745: done 6139 episodes, mean reward 5.751, speed 59.23 f/s\n","1578745: done 6140 episodes, mean reward 5.762, speed 58.62 f/s\n","1578927: done 6141 episodes, mean reward 5.772, speed 57.47 f/s\n","1579927: done 6142 episodes, mean reward 5.892, speed 60.16 f/s\n","EEEE tensor(-7.4442, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5013, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0005, grad_fn=<ExpBackward>)\n","Test done in 32.12 sec, reward 6.325, steps 558\n","1580756: done 6144 episodes, mean reward 5.841, speed 18.01 f/s\n","1581756: done 6145 episodes, mean reward 5.955, speed 59.89 f/s\n","1582642: done 6146 episodes, mean reward 6.052, speed 60.18 f/s\n","1582980: done 6147 episodes, mean reward 5.960, speed 58.71 f/s\n","1583980: done 6148 episodes, mean reward 6.065, speed 59.93 f/s\n","1584980: done 6149 episodes, mean reward 6.200, speed 59.63 f/s\n","1585658: done 6150 episodes, mean reward 6.254, speed 60.28 f/s\n","1585978: done 6151 episodes, mean reward 6.275, speed 58.79 f/s\n","1586326: done 6152 episodes, mean reward 6.218, speed 59.08 f/s\n","1587326: done 6153 episodes, mean reward 6.352, speed 60.10 f/s\n","1587483: done 6154 episodes, mean reward 6.278, speed 57.44 f/s\n","1588352: done 6155 episodes, mean reward 6.385, speed 60.14 f/s\n","1588440: done 6156 episodes, mean reward 6.280, speed 54.13 f/s\n","1589064: done 6157 episodes, mean reward 6.243, speed 59.39 f/s\n","EEEE tensor(-6.5980, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5125, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 32.23 sec, reward 5.606, steps 559\n","1590064: done 6158 episodes, mean reward 6.373, speed 20.41 f/s\n","1590200: done 6160 episodes, mean reward 6.270, speed 53.69 f/s\n","1590624: done 6161 episodes, mean reward 6.221, speed 58.41 f/s\n","1591216: done 6162 episodes, mean reward 6.269, speed 58.17 f/s\n","1592216: done 6163 episodes, mean reward 6.374, speed 59.58 f/s\n","1592389: done 6164 episodes, mean reward 6.362, speed 57.20 f/s\n","1592567: done 6165 episodes, mean reward 6.376, speed 57.82 f/s\n","1593567: done 6166 episodes, mean reward 6.446, speed 59.62 f/s\n","1594567: done 6167 episodes, mean reward 6.440, speed 60.13 f/s\n","1594891: done 6168 episodes, mean reward 6.360, speed 59.04 f/s\n","1595807: done 6169 episodes, mean reward 6.351, speed 59.94 f/s\n","1596807: done 6170 episodes, mean reward 6.341, speed 59.64 f/s\n","1597258: done 6171 episodes, mean reward 6.368, speed 58.58 f/s\n","1598097: done 6172 episodes, mean reward 6.378, speed 59.57 f/s\n","1598455: done 6173 episodes, mean reward 6.419, speed 59.18 f/s\n","1599334: done 6174 episodes, mean reward 6.519, speed 59.49 f/s\n","EEEE tensor(-7.7953, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5232, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 31.77 sec, reward 5.787, steps 548\n","1600334: done 6175 episodes, mean reward 6.603, speed 20.62 f/s\n","1601334: done 6176 episodes, mean reward 6.580, speed 59.82 f/s\n","1602164: done 6177 episodes, mean reward 6.508, speed 59.13 f/s\n","1603164: done 6178 episodes, mean reward 6.459, speed 59.97 f/s\n","1604164: done 6179 episodes, mean reward 6.446, speed 59.97 f/s\n","1604846: done 6180 episodes, mean reward 6.439, speed 58.59 f/s\n","1605678: done 6181 episodes, mean reward 6.480, speed 60.00 f/s\n","1606603: done 6182 episodes, mean reward 6.467, speed 59.68 f/s\n","1606819: done 6183 episodes, mean reward 6.393, speed 58.83 f/s\n","1607217: done 6184 episodes, mean reward 6.403, speed 58.14 f/s\n","1607500: done 6185 episodes, mean reward 6.396, speed 57.84 f/s\n","1607827: done 6187 episodes, mean reward 6.400, speed 55.20 f/s\n","1607903: done 6188 episodes, mean reward 6.313, speed 53.28 f/s\n","1608050: done 6189 episodes, mean reward 6.238, speed 57.00 f/s\n","1608514: done 6190 episodes, mean reward 6.233, speed 58.44 f/s\n","1608588: done 6191 episodes, mean reward 6.167, speed 53.45 f/s\n","1608884: done 6192 episodes, mean reward 6.178, speed 58.69 f/s\n","1609041: done 6193 episodes, mean reward 6.177, speed 56.06 f/s\n","1609194: done 6194 episodes, mean reward 6.070, speed 56.86 f/s\n","1609754: done 6195 episodes, mean reward 6.036, speed 58.70 f/s\n","EEEE tensor(-7.3237, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5086, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 26.02 sec, reward 3.521, steps 439\n","1610754: done 6196 episodes, mean reward 6.117, speed 23.36 f/s\n","1611550: done 6197 episodes, mean reward 6.143, speed 59.60 f/s\n","1611662: done 6198 episodes, mean reward 6.134, speed 56.19 f/s\n","1612031: done 6199 episodes, mean reward 6.040, speed 58.71 f/s\n","1612652: done 6200 episodes, mean reward 6.008, speed 58.74 f/s\n","1613146: done 6201 episodes, mean reward 5.976, speed 59.14 f/s\n","1614146: done 6202 episodes, mean reward 5.971, speed 59.56 f/s\n","1614324: done 6203 episodes, mean reward 5.978, speed 57.36 f/s\n","1614749: done 6205 episodes, mean reward 5.805, speed 57.51 f/s\n","1615195: done 6206 episodes, mean reward 5.759, speed 58.85 f/s\n","1615500: done 6207 episodes, mean reward 5.738, speed 57.29 f/s\n","1616191: done 6208 episodes, mean reward 5.776, speed 59.43 f/s\n","1616477: done 6209 episodes, mean reward 5.791, speed 58.13 f/s\n","1616845: done 6210 episodes, mean reward 5.718, speed 58.56 f/s\n","1617456: done 6211 episodes, mean reward 5.731, speed 58.69 f/s\n","1617799: done 6212 episodes, mean reward 5.725, speed 58.27 f/s\n","1617912: done 6213 episodes, mean reward 5.702, speed 55.87 f/s\n","1618432: done 6215 episodes, mean reward 5.649, speed 57.96 f/s\n","1619431: done 6216 episodes, mean reward 5.769, speed 59.87 f/s\n","1619870: done 6217 episodes, mean reward 5.665, speed 58.44 f/s\n","EEEE tensor(-7.3787, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.5189, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 19.88 sec, reward 1.946, steps 334\n","1620135: done 6219 episodes, mean reward 5.520, speed 10.77 f/s\n","1620227: done 6220 episodes, mean reward 5.441, speed 54.75 f/s\n","1620401: done 6221 episodes, mean reward 5.429, speed 57.27 f/s\n","1620677: done 6222 episodes, mean reward 5.444, speed 58.29 f/s\n","1620911: done 6223 episodes, mean reward 5.340, speed 56.85 f/s\n","1620969: done 6224 episodes, mean reward 5.273, speed 51.44 f/s\n","1621702: done 6225 episodes, mean reward 5.184, speed 59.04 f/s\n","1622544: done 6226 episodes, mean reward 5.206, speed 59.50 f/s\n","1622991: done 6228 episodes, mean reward 5.096, speed 57.03 f/s\n","1623249: done 6229 episodes, mean reward 5.010, speed 57.55 f/s\n","1624249: done 6230 episodes, mean reward 4.997, speed 59.95 f/s\n","1624415: done 6231 episodes, mean reward 4.950, speed 56.64 f/s\n","1625415: done 6232 episodes, mean reward 5.006, speed 59.77 f/s\n","1625921: done 6233 episodes, mean reward 5.027, speed 58.92 f/s\n","1626187: done 6234 episodes, mean reward 5.011, speed 58.70 f/s\n","1626802: done 6235 episodes, mean reward 4.924, speed 59.34 f/s\n","1627643: done 6236 episodes, mean reward 4.843, speed 58.99 f/s\n","1628643: done 6237 episodes, mean reward 4.819, speed 59.72 f/s\n","1629416: done 6238 episodes, mean reward 4.781, speed 59.86 f/s\n","1629954: done 6239 episodes, mean reward 4.767, speed 59.12 f/s\n","EEEE tensor(-7.4218, grad_fn=<MeanBackward0>)\n","QQQQQQQQQQQQ tensor(-0.4978, grad_fn=<NegBackward>)\n","AAAAAAAAAAAAAAAAAAAA tensor(0.0004, grad_fn=<ExpBackward>)\n","Test done in 23.06 sec, reward 3.138, steps 386\n","1630080: done 6240 episodes, mean reward 4.739, speed 4.98 f/s\n","1630736: done 6241 episodes, mean reward 4.786, speed 59.51 f/s\n","1631119: done 6242 episodes, mean reward 4.695, speed 59.00 f/s\n","1631333: done 6243 episodes, mean reward 4.704, speed 57.52 f/s\n","1631561: done 6244 episodes, mean reward 4.616, speed 58.58 f/s\n","1631681: done 6245 episodes, mean reward 4.482, speed 56.56 f/s\n","1631919: done 6246 episodes, mean reward 4.398, speed 58.37 f/s\n","1632919: done 6247 episodes, mean reward 4.422, speed 59.35 f/s\n","1633700: done 6248 episodes, mean reward 4.395, speed 59.17 f/s\n","1634700: done 6249 episodes, mean reward 4.338, speed 59.25 f/s\n","1635013: done 6250 episodes, mean reward 4.260, speed 59.05 f/s\n","1635496: done 6251 episodes, mean reward 4.268, speed 59.67 f/s\n","1635579: done 6252 episodes, mean reward 4.228, speed 54.41 f/s\n","1635649: done 6253 episodes, mean reward 4.097, speed 53.41 f/s\n","1635725: done 6254 episodes, mean reward 4.088, speed 54.16 f/s\n","1636244: done 6255 episodes, mean reward 4.015, speed 59.52 f/s\n","1637244: done 6256 episodes, mean reward 4.112, speed 59.58 f/s\n","1637454: done 6257 episodes, mean reward 4.055, speed 56.44 f/s\n"]}]},{"cell_type":"code","source":["save_path_act = os.path.join(save_path, 'act_net.pth')\n","save_path_crt = os.path.join(save_path, 'crt_net.pth')\n","save_path_twinq = os.path.join(save_path, 'twinq_net.pth')\n","\n","torch.save(act_net.state_dict(), save_path_act)\n","torch.save(crt_net.state_dict(), save_path_crt)\n","torch.save(twinq_net.state_dict(), save_path_twinq)"],"metadata":{"id":"qSivOqW3_ifp","colab":{"base_uri":"https://localhost:8080/","height":249},"executionInfo":{"status":"error","timestamp":1654736492389,"user_tz":-480,"elapsed":368,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}},"outputId":"94718044-eb38-483a-b586-b01637715b23"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7f2624f5241d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_path_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'act_net.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msave_path_crt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'crt_net.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msave_path_twinq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'twinq_net.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path_act\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}]},{"cell_type":"code","source":["XXXX = torch.load('mount/My Drive/Colab Notebooks/minitaur_/05_22060616_SAC/best_+10.847_450000.dat')"],"metadata":{"id":"LwfUH6kDCEod","executionInfo":{"status":"ok","timestamp":1654737601603,"user_tz":-480,"elapsed":306,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# video recorder import\n","from gym.wrappers.monitoring.video_recorder import VideoRecorder\n","\n","\n","# video -> html function\n","from base64 import b64encode\n","def render_mp4(videopath: str) -> str:\n","  \"\"\"\n","  Gets a string containing a b4-encoded version of the MP4 video\n","  at the specified path.\n","  \"\"\"\n","  mp4 = open(videopath, 'rb').read()\n","  base64_encoded_mp4 = b64encode(mp4).decode()\n","  return f'<video width=400 controls><source src=\"data:video/mp4;' \\\n","         f'base64,{base64_encoded_mp4}\" type=\"video/mp4\"></video>'\n","\n","\n","# setup env & download model\n","\n","env = gym.make(\"MinitaurBulletEnv-v0\")\n","\n","net = ModelActor(env.observation_space.shape[0], env.action_space.shape[0])\n","net.load_state_dict(XXXX)\n","\n","\n","# video record\n","\n","minitaur_training = \"minitaur_training.mp4\"\n","video = VideoRecorder(env, minitaur_training)\n","\n","steps = 0\n","rewards = 0\n","\n","state = env.reset()\n","done = False\n","while not done:\n","  env.render()\n","  video.capture_frame()\n","\n","  state = torch.tensor(state, dtype=torch.float)\n","  # action, _ = net(state)\n","  action = net.base(state)\n","  action = net.mu(action)\n","  action = torch.tanh(action)\n","\n","  action = action.squeeze(dim=0).data.cpu().numpy()\n","  action = np.clip(action, -1, 1)\n","  next_state, reward, done, info = env.step(action)\n","\n","  state = next_state\n","  steps += 1\n","  rewards += reward\n","\n","  pass\n","\n","env.render()\n","video.capture_frame()\n","\n","video.close()\n","env.close()\n","\n","\n","# video play\n","\n","print('steps:', steps)\n","print('rewards:', rewards)\n","from IPython.display import HTML\n","html = render_mp4(minitaur_training)\n","HTML(html)"],"metadata":{"id":"p-fAZdkrAZ2t","colab":{"base_uri":"https://localhost:8080/","height":412,"output_embedded_package_id":"1Yn-cbuevcbedUKtDC0srV5kgH7iEp-dH"},"executionInfo":{"status":"ok","timestamp":1654739359115,"user_tz":-480,"elapsed":333690,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}},"outputId":"79c35aa7-6c81-4d8d-a887-bcaff9ced07c"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["CYCLE = 100\n","\n","# setup env & download model\n","\n","env = gym.make(\"MinitaurBulletEnv-v0\")\n","\n","net = ModelActor(env.observation_space.shape[0], env.action_space.shape[0])\n","net.load_state_dict(XXXX)\n","\n","\n","# simulate\n","\n","rewords_by_episodes = []\n","steps_by_episodes = []\n","\n","for i in range(CYCLE):\n","  \n","  rewords = 0\n","  steps = 0\n","\n","  state = env.reset()\n","  done = False\n","  while not done:\n","\n","    state = torch.tensor(state, dtype=torch.float)\n","    # action, _ = net(state)\n","    action = net.base(state)\n","    action = net.mu(action)\n","    action = torch.tanh(action)\n","    \n","    action = action.squeeze(dim=0).data.cpu().numpy()\n","    action = np.clip(action, -1, 1)\n","    next_state, reword, done, info = env.step(action)\n","\n","    state = next_state\n","    rewords += reword\n","    steps += 1\n","\n","    pass\n","\n","  rewords_by_episodes.append(rewords)\n","  steps_by_episodes.append(steps)\n","\n","  pass\n","\n","env.close()\n","\n","\n","# plot\n","\n","import matplotlib.pyplot as plt\n","\n","fig, ax = plt.subplots(2)\n","ax[0].plot(rewords_by_episodes)\n","ax[1].plot(steps_by_episodes)"],"metadata":{"id":"2b3B14H_A3Yr","colab":{"base_uri":"https://localhost:8080/","height":338},"executionInfo":{"status":"ok","timestamp":1654738910539,"user_tz":-480,"elapsed":573753,"user":{"displayName":"Yuxin Li","userId":"03599128569783170414"}},"outputId":"e6a187b1-db32-4e23-9124-9c264a0398b9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["urdf_root=/usr/local/lib/python3.7/dist-packages/pybullet_data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n","  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"]},{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f9e9e5db190>]"]},"metadata":{},"execution_count":8},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}